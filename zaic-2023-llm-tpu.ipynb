{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30589,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### TPU","metadata":{}},{"cell_type":"code","source":"!pip3 install huggingface-hub","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:06:34.647219Z","iopub.execute_input":"2024-01-18T11:06:34.647479Z","iopub.status.idle":"2024-01-18T11:06:38.634529Z","shell.execute_reply.started":"2024-01-18T11:06:34.647449Z","shell.execute_reply":"2024-01-18T11:06:38.633702Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/site-packages (0.17.3)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (4.8.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (3.13.1)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (2023.10.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (23.2)\nRequirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/site-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub) (2023.7.22)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->huggingface-hub) (2.0.7)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip3 install transformers datasets sentencepiece langchain peft trl -q\n!pip install torch~=2.1.0 --index-url https://download.pytorch.org/whl/cpu -q #Updating torch since we need the latest version\n!pip install torch_xla[tpu]~=2.1.0 -f https://storage.googleapis.com/libtpu-releases/index.html -q\n!pip uninstall tensorflow -y #If we don't do this, TF will take over TPU and cause permission error for PT\n!cp /kaggle/input/utils-xla/spmd_util.py . #From this repo: https://github.com/HeegyuKim/torch-xla-SPMD","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:06:38.636138Z","iopub.execute_input":"2024-01-18T11:06:38.636432Z","iopub.status.idle":"2024-01-18T11:07:43.260637Z","shell.execute_reply.started":"2024-01-18T11:06:38.636391Z","shell.execute_reply":"2024-01-18T11:07:43.259871Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nFound existing installation: tensorflow 2.14.0\nUninstalling tensorflow-2.14.0:\n  Successfully uninstalled tensorflow-2.14.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mcp: cannot stat '/kaggle/input/utils-xla/spmd_util.py': No such file or directory\n","output_type":"stream"}]},{"cell_type":"code","source":"# !git clone https://github.com/HeegyuKim/torch-xla-SPMD","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:43.261899Z","iopub.execute_input":"2024-01-18T11:07:43.262208Z","iopub.status.idle":"2024-01-18T11:07:43.266155Z","shell.execute_reply.started":"2024-01-18T11:07:43.262175Z","shell.execute_reply":"2024-01-18T11:07:43.265504Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# !cp /kaggle/working/torch-xla-SPMD/spmd_util.py . #From this repo: https://github.com/HeegyuKim/torch-xla-SPMD","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:43.267612Z","iopub.execute_input":"2024-01-18T11:07:43.267839Z","iopub.status.idle":"2024-01-18T11:07:43.718188Z","shell.execute_reply.started":"2024-01-18T11:07:43.267814Z","shell.execute_reply":"2024-01-18T11:07:43.717512Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:43.719058Z","iopub.execute_input":"2024-01-18T11:07:43.719283Z","iopub.status.idle":"2024-01-18T11:07:47.297949Z","shell.execute_reply.started":"2024-01-18T11:07:43.719259Z","shell.execute_reply":"2024-01-18T11:07:47.297111Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (1.26.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers_stream_generator einops","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:47.299326Z","iopub.execute_input":"2024-01-18T11:07:47.299619Z","iopub.status.idle":"2024-01-18T11:07:52.448098Z","shell.execute_reply.started":"2024-01-18T11:07:47.299588Z","shell.execute_reply":"2024-01-18T11:07:52.447308Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting transformers_stream_generator\n  Downloading transformers-stream-generator-0.0.4.tar.gz (12 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops\n  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/site-packages (from transformers_stream_generator) (4.35.0)\nRequirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.4.0)\nRequirement already satisfied: tokenizers<0.15,>=0.14 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.14.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.10.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.66.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.13.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (23.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.17.3)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.26.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.26.1->transformers_stream_generator) (4.8.0)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers>=4.26.1->transformers_stream_generator) (2023.10.0)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2.0.7)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.7.22)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4)\nBuilding wheels for collected packages: transformers_stream_generator\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12315 sha256=336d98e7c191e48fa4b7fdf913c1226c0fc07d911fc42b42eaaa5cb0f2517819\n  Stored in directory: /root/.cache/pip/wheels/47/1d/3c/92d88493ed40c0d9be60a391eb76c9a56e9f9b7542cb789401\nSuccessfully built transformers_stream_generator\nInstalling collected packages: einops, transformers_stream_generator\nSuccessfully installed einops-0.7.0 transformers_stream_generator-0.0.4\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:52.449277Z","iopub.execute_input":"2024-01-18T11:07:52.449540Z","iopub.status.idle":"2024-01-18T11:07:56.448282Z","shell.execute_reply.started":"2024-01-18T11:07:52.449506Z","shell.execute_reply":"2024-01-18T11:07:56.447517Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/site-packages (from tiktoken) (2023.10.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2.0.7)\nInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.5.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### GPU","metadata":{}},{"cell_type":"code","source":"!pip3 install huggingface-hub","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:48:10.198660Z","iopub.execute_input":"2024-01-19T07:48:10.199639Z","iopub.status.idle":"2024-01-19T07:48:22.964713Z","shell.execute_reply.started":"2024-01-19T07:48:10.199593Z","shell.execute_reply":"2024-01-19T07:48:22.963614Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (0.17.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (3.12.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2023.10.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.66.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (4.5.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub) (21.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub) (2023.7.22)\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install --upgrade openai\n!pip install --upgrade pydantic","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:48:22.967059Z","iopub.execute_input":"2024-01-19T07:48:22.967436Z","iopub.status.idle":"2024-01-19T07:49:02.810964Z","shell.execute_reply.started":"2024-01-19T07:48:22.967400Z","shell.execute_reply":"2024-01-19T07:49:02.809807Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting openai\n  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/f1/d8/590a68d390501faf48f4e57b098076df02afd003ac880f50d3b0704f7773/openai-1.8.0-py3-none-any.whl.metadata\n  Downloading openai-1.8.0-py3-none-any.whl.metadata (18 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai) (3.7.1)\nCollecting distro<2,>=1.7.0 (from openai)\n  Obtaining dependency information for distro<2,>=1.7.0 from https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl.metadata\n  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\nCollecting httpx<1,>=0.23.0 (from openai)\n  Obtaining dependency information for httpx<1,>=0.23.0 from https://files.pythonhosted.org/packages/39/9b/4937d841aee9c2c8102d9a4eeb800c7dad25386caabb4a1bf5010df81a57/httpx-0.26.0-py3-none-any.whl.metadata\n  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from openai) (1.10.12)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai) (1.3.0)\nRequirement already satisfied: tqdm>4 in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nCollecting typing-extensions<5,>=4.7 (from openai)\n  Obtaining dependency information for typing-extensions<5,>=4.7 from https://files.pythonhosted.org/packages/b7/f4/6a90020cd2d93349b442bfcb657d0dc91eee65491600b2cb1d388bc98e6b/typing_extensions-4.9.0-py3-none-any.whl.metadata\n  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.1.3)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nCollecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n  Obtaining dependency information for httpcore==1.* from https://files.pythonhosted.org/packages/56/ba/78b0a99c4da0ff8b0f59defa2f13ca4668189b134bd9840b6202a93d9a0f/httpcore-1.0.2-py3-none-any.whl.metadata\n  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\nDownloading openai-1.8.0-py3-none-any.whl (222 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.3/222.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\nDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\nInstalling collected packages: typing-extensions, httpcore, distro, httpx, openai\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.5.0\n    Uninstalling typing_extensions-4.5.0:\n      Successfully uninstalled typing_extensions-4.5.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.7 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.11.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\njupyterlab 4.0.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.0 requires jupyterlab<5.0.0a0,>=4.0.6, but you have jupyterlab 4.0.5 which is incompatible.\npymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.24.3 which is incompatible.\npymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.3 which is incompatible.\ntensorflow 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflow-probability 0.21.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\ntensorflowjs 4.13.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed distro-1.9.0 httpcore-1.0.2 httpx-0.26.0 openai-1.8.0 typing-extensions-4.7.1\nRequirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (1.10.12)\nCollecting pydantic\n  Obtaining dependency information for pydantic from https://files.pythonhosted.org/packages/dd/b7/9aea7ee6c01fe3f3c03b8ca3c7797c866df5fecece9d6cb27caa138db2e2/pydantic-2.5.3-py3-none-any.whl.metadata\n  Downloading pydantic-2.5.3-py3-none-any.whl.metadata (65 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m705.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic) (0.6.0)\nCollecting pydantic-core==2.14.6 (from pydantic)\n  Obtaining dependency information for pydantic-core==2.14.6 from https://files.pythonhosted.org/packages/90/28/3c6843e6b203999be2660d3f114be196f2182dcac533dc764ad320c9184d/pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic) (4.7.1)\nDownloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading pydantic_core-2.14.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pydantic-core, pydantic\n  Attempting uninstall: pydantic-core\n    Found existing installation: pydantic_core 2.10.1\n    Uninstalling pydantic_core-2.10.1:\n      Successfully uninstalled pydantic_core-2.10.1\n  Attempting uninstall: pydantic\n    Found existing installation: pydantic 1.10.12\n    Uninstalling pydantic-1.10.12:\n      Successfully uninstalled pydantic-1.10.12\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nydata-profiling 4.5.1 requires numpy<1.24,>=1.16.0, but you have numpy 1.24.3 which is incompatible.\nydata-profiling 4.5.1 requires pydantic<2,>=1.8.1, but you have pydantic 2.5.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pydantic-2.4.2 pydantic-core-2.14.6\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:49:02.812702Z","iopub.execute_input":"2024-01-19T07:49:02.812979Z","iopub.status.idle":"2024-01-19T07:50:20.631387Z","shell.execute_reply.started":"2024-01-19T07:49:02.812954Z","shell.execute_reply":"2024-01-19T07:50:20.630329Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install numpy","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:50:20.633709Z","iopub.execute_input":"2024-01-19T07:50:20.634073Z","iopub.status.idle":"2024-01-19T07:50:32.133524Z","shell.execute_reply.started":"2024-01-19T07:50:20.634033Z","shell.execute_reply":"2024-01-19T07:50:32.132575Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.24.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install transformers_stream_generator einops","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:50:32.134872Z","iopub.execute_input":"2024-01-19T07:50:32.135188Z","iopub.status.idle":"2024-01-19T07:50:46.712949Z","shell.execute_reply.started":"2024-01-19T07:50:32.135160Z","shell.execute_reply":"2024-01-19T07:50:46.711863Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting transformers_stream_generator\n  Downloading transformers-stream-generator-0.0.4.tar.gz (12 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting einops\n  Obtaining dependency information for einops from https://files.pythonhosted.org/packages/29/0b/2d1c0ebfd092e25935b86509a9a817159212d82aa43d7fb07eca4eeff2c2/einops-0.7.0-py3-none-any.whl.metadata\n  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: transformers>=4.26.1 in /opt/conda/lib/python3.10/site-packages (from transformers_stream_generator) (4.36.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.20.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (1.24.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (2023.8.8)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.15.0)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (0.4.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.1->transformers_stream_generator) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.26.1->transformers_stream_generator) (2023.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers>=4.26.1->transformers_stream_generator) (4.7.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.26.1->transformers_stream_generator) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.26.1->transformers_stream_generator) (2023.7.22)\nDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m767.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers_stream_generator\n  Building wheel for transformers_stream_generator (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers_stream_generator: filename=transformers_stream_generator-0.0.4-py3-none-any.whl size=12315 sha256=3cd4452583867912fb84ee4eaa0f71fd88014eaeeb4a355fc18278c4eda6b146\n  Stored in directory: /root/.cache/pip/wheels/47/1d/3c/92d88493ed40c0d9be60a391eb76c9a56e9f9b7542cb789401\nSuccessfully built transformers_stream_generator\nInstalling collected packages: einops, transformers_stream_generator\nSuccessfully installed einops-0.7.0 transformers_stream_generator-0.0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:50:46.714514Z","iopub.execute_input":"2024-01-19T07:50:46.714901Z","iopub.status.idle":"2024-01-19T07:50:58.883136Z","shell.execute_reply.started":"2024-01-19T07:50:46.714862Z","shell.execute_reply":"2024-01-19T07:50:58.881999Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Obtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/bf/56/a8910841d1f501cf8affeb06a0335a518888505c60ec9f2a2a6393190e48/tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.8.8)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\nDownloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.5.2\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"markdown","source":"### Import TPU","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport datasets\nimport torch.optim as optim\nimport torch_xla.debug.profiler as xp\nimport torch_xla.core.xla_model as xm\nimport torch_xla.distributed.xla_multiprocessing as xmp #We also import mp modules if we wanna use that for some reason\nimport torch_xla.distributed.parallel_loader as pl\nimport torch_xla.test.test_utils as test_utils\nimport torch\nimport torch.nn as nn\nimport re\nimport torch_xla.experimental.xla_sharding as xs\nimport torch_xla.core.xla_model as xm\nfrom trl import DataCollatorForCompletionOnlyLM\nfrom transformers import (\n    GPTNeoXConfig, T5Config, LlamaConfig, AutoTokenizer, AutoModelForCausalLM, DataCollatorWithPadding, AutoConfig\n) # You can use any of models with those configs (even flan T5 xxl!). Other models are not supported.\n\nfrom transformers import logging as hf_logging\nimport torch.nn.functional as F\nimport torch_xla.runtime as xr\n\nxr.use_spmd()\n\nimport torch_xla.experimental.xla_sharding as xs # \"experimental\" prefix always means you're gonna have a good time LMAO\nfrom torch_xla.experimental.xla_sharded_tensor import XLAShardedTensor\nfrom torch_xla.experimental.xla_sharding import Mesh\n\nfrom peft import LoraConfig, TaskType, get_peft_model # If we wanna use peft. Quantazation requiers GPU though.\n# from spmd_util import partition_module                # You could experiment with using already quantazed models like 4bit/Llama-2-7b-Chat-GPTQ if you're feeling funny\nfrom langchain.prompts import PromptTemplate          # Please share your experiements if you find something :)\nfrom datasets import Dataset, load_dataset, concatenate_datasets\nfrom dataclasses import dataclass\nfrom tqdm import tqdm\n\n!export USE_TORCH=True #If we don't do this, transformers will seemingly bork the session upon import. Really weird error.\nos.environ[\"PJRT_DEVICE\"] = \"TPU\"\nos.environ.pop('TPU_PROCESS_ADDRESSES')\nos.environ.pop('CLOUD_TPU_TASK_ID')\nhf_logging.set_verbosity_error() # It can still display warnings which is a bit annoying but whatever","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:07:56.449749Z","iopub.execute_input":"2024-01-18T11:07:56.450008Z","iopub.status.idle":"2024-01-18T11:08:07.423965Z","shell.execute_reply.started":"2024-01-18T11:07:56.449979Z","shell.execute_reply":"2024-01-18T11:08:07.422699Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport re\nimport torch_xla.experimental.xla_sharding as xs\nimport torch_xla.core.xla_model as xm\nfrom transformers import (\n    GPTNeoXConfig, T5Config, LlamaConfig, MistralConfig\n)\n\n# ends with $ to prevent sharding lora parameters\nGPTNEOX_RULES = (\n    # embeddings\n    (\"gpt_neox\\\\.embed_in\", (\"mp\", \"fsdp\")),\n    # atention\n    (\"attention\\\\.query_key_value$\", (\"fsdp\", \"mp\")),\n    (\"attention\\\\.dense$\", (\"mp\", \"fsdp\")),\n    # mlp\n    (\"mlp\\\\.dense_h_to_4h$\", (\"fsdp\", \"mp\")),\n    (\"mlp\\\\.dense_4h_to_h$\", (\"mp\", \"fsdp\")),\n    # output\n    (\"embed_out\", (\"fsdp\", \"mp\")),\n)\n\nT5_RULES = (\n    # embeddings\n    (\"shared$\", (\"mp\", \"fsdp\")),\n    (\"embed_tokens$\", (\"mp\", \"fsdp\")),\n    \n    # attention\n    (\"q$\", (\"fsdp\", \"mp\")),\n    (\"k$\", (\"fsdp\", \"mp\")),\n    (\"v$\", (\"fsdp\", \"mp\")),\n    (\"o$\", (\"mp\", \"fsdp\")),\n\n    # mlp\n    (\"w$\", (\"fsdp\", \"mp\")),\n    (\"wi_0$\", (\"fsdp\", \"mp\")),\n    (\"wi_1$\", (\"fsdp\", \"mp\")),\n    (\"wo$\", (\"mp\", \"fsdp\")),\n\n    # seq2seq lm head\n    (\"lm_head\", (\"fsdp\", \"mp\")),\n)\n\nLLAMA_RULES = (\n    (\"model\\\\.embed_tokens\", (\"mp\", \"fsdp\")),\n    (\"self_attn\\\\.(q_proj|k_proj|v_proj)\", (\"fsdp\", \"mp\")),\n    (\"self_attn\\\\.o_proj\", (\"mp\", \"fsdp\")),\n    (\"mlp\\\\.gate_proj\", (\"fsdp\", \"mp\")),\n    (\"mlp\\\\.down_proj\", (\"mp\", \"fsdp\")),\n    (\"mlp\\\\.up_proj\", (\"fsdp\", \"mp\")),\n    (\"lm_head\", (\"fsdp\", \"mp\")),\n    )\n\nQWEN_RULES = (\n    #\n    (\"wte\", (\"mp\", \"fsdp\")),\n    \n    # atention\n    (\"attn\\\\.c_attn\", (\"fsdp\", \"mp\")),\n    (\"attn\\\\.c_proj\", (\"fsdp\", \"mp\")),\n    \n    # mlp\n    (\"mlp\\\\.w1\", (\"fsdp\", \"mp\")),\n    (\"mlp\\\\.w2\", (\"fsdp\", \"mp\")),\n    (\"mlp\\\\.c_proj\", (\"mp\", \"fsdp\")),\n    \n    # seq2seq lm head\n    (\"lm_head\", (\"fsdp\", \"mp\")),\n)\n    \nALL_RULES = [\n    (GPTNeoXConfig, GPTNEOX_RULES),\n    (T5Config, T5_RULES),\n    (LlamaConfig, LLAMA_RULES),\n    (MistralConfig, LLAMA_RULES)\n]\n\ndef find_rule(model):\n    for config, rule in ALL_RULES:\n        if model.config.__class__ == config:\n            return rule\n    raise Exception(\"unsupported model to partitioning\")\n\nstrkey2id = {\n    \"dp\": 0,\n    \"fsdp\": 1,\n    \"mp\": 2\n}\n\ndef partition_module(model, mesh, device=xm.xla_device(), verbose=False):\n    partition_specs = find_rule(model)\n    rule = [(k, tuple([strkey2id[x] for x in v])) for k, v in partition_specs]\n        \n    # print(rule)\n\n    for name, module in model.named_modules():\n        module.to(device)\n        # print(name, module.__class__.__name__)\n        if isinstance(module, (nn.Embedding, nn.Linear)):\n            for rule_pattern, spec in rule:\n                if re.findall(rule_pattern, name):\n                    if verbose:\n                        print(\"match\", rule_pattern, name)\n                    \n                    xs.mark_sharding(module.weight, mesh, spec)\n                    break\n        \ndef partition_module_dp(model, mesh, device=xm.xla_device(), verbose=False):\n    spec = (1, 2)\n\n    for name, module in model.named_modules():\n        module.to(device)\n        if isinstance(module, (nn.Embedding, nn.Linear)):\n            xs.mark_sharding(module.weight, mesh, spec)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:08:07.425744Z","iopub.execute_input":"2024-01-18T11:08:07.426629Z","iopub.status.idle":"2024-01-18T11:08:07.444316Z","shell.execute_reply.started":"2024-01-18T11:08:07.426589Z","shell.execute_reply":"2024-01-18T11:08:07.443501Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"### Import GPU","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, logging #, BitsAndBytesConfig,HfArgumentParser,TrainingArguments\n# from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch\n# wandb\nfrom datasets import load_dataset\n# from trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:50:58.884414Z","iopub.execute_input":"2024-01-19T07:50:58.884707Z","iopub.status.idle":"2024-01-19T07:51:17.183652Z","shell.execute_reply.started":"2024-01-19T07:50:58.884680Z","shell.execute_reply":"2024-01-19T07:51:17.182827Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Import kaggle","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nsecret_gemini = user_secrets.get_secret(\"GEMINI_API_KEY\")\n# secret_wandb = user_secrets.get_secret(\"wandb\")","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:55.925142Z","iopub.execute_input":"2024-01-19T07:51:55.926651Z","iopub.status.idle":"2024-01-19T07:51:56.277855Z","shell.execute_reply.started":"2024-01-19T07:51:55.926610Z","shell.execute_reply":"2024-01-19T07:51:56.277057Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:56.279838Z","iopub.execute_input":"2024-01-19T07:51:56.280533Z","iopub.status.idle":"2024-01-19T07:51:57.866348Z","shell.execute_reply.started":"2024-01-19T07:51:56.280496Z","shell.execute_reply":"2024-01-19T07:51:57.865195Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# base_model = \"meta-math/MetaMath-Mistral-7B\"\n# base_model = \"EleutherAI/gpt-neo-2.7B\"\n# base_model = \"gpt2-xl\"\n# base_model = \"gpt2-large\"\n# base_model = \"gpt2\"\nbase_model = \"openchat/openchat-3.5-1210\"\n# base_model = \"bigscience/bloom-7b1\"\n# base_model = \"Qwen/Qwen-14B\"\n# base_model = \"xDAN-AI/xDAN-L1-Chat-RL-v1\"\nnew_model = \"BK-BigAI-Math\"\nmodel_hotamath_path = \"/kaggle/working/BK-BigAI-Math\"","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:57.867811Z","iopub.execute_input":"2024-01-19T07:51:57.868120Z","iopub.status.idle":"2024-01-19T07:51:57.873262Z","shell.execute_reply.started":"2024-01-19T07:51:57.868094Z","shell.execute_reply":"2024-01-19T07:51:57.872300Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"## Download dataset","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:57.875467Z","iopub.execute_input":"2024-01-19T07:51:57.875735Z","iopub.status.idle":"2024-01-19T07:51:58.857358Z","shell.execute_reply.started":"2024-01-19T07:51:57.875712Z","shell.execute_reply":"2024-01-19T07:51:58.856116Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/test.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/train.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:58.858855Z","iopub.execute_input":"2024-01-19T07:51:58.859202Z","iopub.status.idle":"2024-01-19T07:51:59.469133Z","shell.execute_reply.started":"2024-01-19T07:51:58.859174Z","shell.execute_reply":"2024-01-19T07:51:59.468265Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"test.zip:   0%|          | 0.00/9.10k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c75f1d52994ab9ba1fd275213734d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.zip:   0%|          | 0.00/84.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee664ef73414147ac950e2a19b277fe"}},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"'dataset/Elementary Maths Solving/train.zip'"},"metadata":{}}]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:51:59.470504Z","iopub.execute_input":"2024-01-19T07:51:59.471187Z","iopub.status.idle":"2024-01-19T07:52:02.214880Z","shell.execute_reply.started":"2024-01-19T07:51:59.471149Z","shell.execute_reply":"2024-01-19T07:52:02.213737Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nunzip is already the newest version (6.0-26ubuntu3.1).\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"!mkdir datasetRaw\n!unzip -q -o \"dataset/Elementary Maths Solving/test.zip\" -d \"datasetRaw\"\n!unzip -q -o \"dataset/Elementary Maths Solving/train.zip\" -d \"datasetRaw\"","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:02.216567Z","iopub.execute_input":"2024-01-19T07:52:02.216941Z","iopub.status.idle":"2024-01-19T07:52:05.142268Z","shell.execute_reply.started":"2024-01-19T07:52:02.216905Z","shell.execute_reply":"2024-01-19T07:52:05.140973Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nimport numpy\nfrom math import *","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:05.144089Z","iopub.execute_input":"2024-01-19T07:52:05.144900Z","iopub.status.idle":"2024-01-19T07:52:05.149898Z","shell.execute_reply.started":"2024-01-19T07:52:05.144858Z","shell.execute_reply":"2024-01-19T07:52:05.148676Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:05.151430Z","iopub.execute_input":"2024-01-19T07:52:05.151800Z","iopub.status.idle":"2024-01-19T07:52:05.160085Z","shell.execute_reply.started":"2024-01-19T07:52:05.151766Z","shell.execute_reply":"2024-01-19T07:52:05.159235Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"hf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/math_train_full_verified.json\", revision=\"main\", repo_type=\"dataset\", local_dir=\"datasetRaw\", local_dir_use_symlinks=False)\nos.system('mv \"/kaggle/working/datasetRaw/Elementary Maths Solving/math_train_full_verified.json\" \"/kaggle/working/datasetRaw/\"')\nwith open(\"/kaggle/working/datasetRaw/math_train_full_verified.json\", \"r\") as f:\n    train_data_full_verified = json.loads(f.read())['data']\n    \nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/train_data_mathqa_verified.json\", revision=\"main\", repo_type=\"dataset\", local_dir=\"datasetRaw\", local_dir_use_symlinks=False)\nos.system('mv \"/kaggle/working/datasetRaw/Elementary Maths Solving/train_data_mathqa_verified.json\" \"/kaggle/working/datasetRaw/\"')\nwith open(\"/kaggle/working/datasetRaw/train_data_mathqa_verified.json\", \"r\") as f:\n    train_data_mathqa_verified = json.loads(f.read())['data']\n    \nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/train_data_mathqa_vi.json\", revision=\"main\", repo_type=\"dataset\", local_dir=\"datasetRaw\", local_dir_use_symlinks=False)\nos.system('mv \"/kaggle/working/datasetRaw/Elementary Maths Solving/train_data_mathqa_vi.json\" \"/kaggle/working/datasetRaw/\"')\nwith open(\"/kaggle/working/datasetRaw/train_data_mathqa_vi.json\", \"r\") as f:\n    train_data_mathqa_vi = json.loads(f.read())['data']\n    \nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/math_train_formula.json\", revision=\"main\", repo_type=\"dataset\", local_dir=\"datasetRaw\", local_dir_use_symlinks=False)\nos.system('mv \"/kaggle/working/datasetRaw/Elementary Maths Solving/math_train_formula.json\" \"/kaggle/working/datasetRaw/\"')\nwith open(\"/kaggle/working/datasetRaw/math_train_formula.json\", \"r\") as f:\n    train_data_math_formula = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:05.165241Z","iopub.execute_input":"2024-01-19T07:52:05.165512Z","iopub.status.idle":"2024-01-19T07:52:07.258927Z","shell.execute_reply.started":"2024-01-19T07:52:05.165490Z","shell.execute_reply":"2024-01-19T07:52:07.258069Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"(…)hs Solving/math_train_full_verified.json:   0%|          | 0.00/2.15M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2adf3b9808634817ae720dec29b83854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_data_mathqa_verified.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3829973ece644ce29e4680f07f70437a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train_data_mathqa_vi.json:   0%|          | 0.00/26.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fc15a76e197048c492c239bb55871f78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)ry Maths Solving/math_train_formula.json:   0%|          | 0.00/310k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"063f229dfec941a09804c68b6e7a3390"}},"metadata":{}}]},{"cell_type":"code","source":"import random","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.260206Z","iopub.execute_input":"2024-01-19T07:52:07.260578Z","iopub.status.idle":"2024-01-19T07:52:07.265293Z","shell.execute_reply.started":"2024-01-19T07:52:07.260542Z","shell.execute_reply":"2024-01-19T07:52:07.264353Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_data = [\n    *train_data_full_verified,\n    *train_data_mathqa_verified,\n    *train_data_mathqa_vi,\n    *train_data_math_formula\n]\nrandom.shuffle(train_data)\ntest_data = None","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.266441Z","iopub.execute_input":"2024-01-19T07:52:07.267450Z","iopub.status.idle":"2024-01-19T07:52:07.331302Z","shell.execute_reply.started":"2024-01-19T07:52:07.267415Z","shell.execute_reply":"2024-01-19T07:52:07.330518Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train_data_math_formula[-3]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.332442Z","iopub.execute_input":"2024-01-19T07:52:07.332773Z","iopub.status.idle":"2024-01-19T07:52:07.339958Z","shell.execute_reply.started":"2024-01-19T07:52:07.332740Z","shell.execute_reply":"2024-01-19T07:52:07.339038Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'id': 'autodataset-997',\n 'question': 'Số lớn nhất trong các số sau 429.812, -535.761, 225.93, -330.718, -593.943 là:',\n 'choices': ['A. -330.718',\n  'B. -535.761',\n  'C. 225.93',\n  'D. -593.943',\n  'E. 429.812'],\n 'answer': 'E. 429.812',\n 'formula': 'max([429.812, -535.761, 225.93, -330.718, -593.943])'}"},"metadata":{}}]},{"cell_type":"code","source":"print(len(train_data))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.341463Z","iopub.execute_input":"2024-01-19T07:52:07.341816Z","iopub.status.idle":"2024-01-19T07:52:07.350291Z","shell.execute_reply.started":"2024-01-19T07:52:07.341782Z","shell.execute_reply":"2024-01-19T07:52:07.349408Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"63590\n","output_type":"stream"}]},{"cell_type":"code","source":"# with open(os.path.join(\"datasetRaw\", \"train\", \"/kaggle/working/datasetRaw/math_train.json\"), \"r\") as f:\n# with open(os.path.join(\"datasetRaw\", \"train\", \"/kaggle/working/datasetRaw/math_train_short.json\"), \"r\") as f:\n#     train_data = json.loads(f.read()) #['data']\ntrain_data = [train_data[i] for i in range(len(train_data)) if ((\"ok\" not in train_data[i]) or train_data[i][\"ok\"]) and (\"answer\" in train_data[i] and train_data[i][\"answer\"] != None)]\nwith open(os.path.join(\"datasetRaw\", \"test\", \"/kaggle/working/datasetRaw/math_test.json\"), \"r\") as f:\n    test_data = json.loads(f.read())['data']","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.351612Z","iopub.execute_input":"2024-01-19T07:52:07.351926Z","iopub.status.idle":"2024-01-19T07:52:07.425414Z","shell.execute_reply.started":"2024-01-19T07:52:07.351897Z","shell.execute_reply":"2024-01-19T07:52:07.424445Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(len(train_data), len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.426536Z","iopub.execute_input":"2024-01-19T07:52:07.426809Z","iopub.status.idle":"2024-01-19T07:52:07.432068Z","shell.execute_reply.started":"2024-01-19T07:52:07.426785Z","shell.execute_reply":"2024-01-19T07:52:07.431162Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"51691 189\n","output_type":"stream"}]},{"cell_type":"code","source":"# train_data.extend(temp_data[:200])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.433214Z","iopub.execute_input":"2024-01-19T07:52:07.433500Z","iopub.status.idle":"2024-01-19T07:52:07.440580Z","shell.execute_reply.started":"2024-01-19T07:52:07.433476Z","shell.execute_reply":"2024-01-19T07:52:07.439564Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"print(len([i for i in range(len(train_data)) if (\"answer\" not in train_data[i] or train_data[i][\"answer\"] == None)]))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.441793Z","iopub.execute_input":"2024-01-19T07:52:07.442102Z","iopub.status.idle":"2024-01-19T07:52:07.483059Z","shell.execute_reply.started":"2024-01-19T07:52:07.442077Z","shell.execute_reply":"2024-01-19T07:52:07.482060Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"0\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data[312]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.484256Z","iopub.execute_input":"2024-01-19T07:52:07.484519Z","iopub.status.idle":"2024-01-19T07:52:07.490359Z","shell.execute_reply.started":"2024-01-19T07:52:07.484496Z","shell.execute_reply":"2024-01-19T07:52:07.489370Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'question': 'in a certain accounting class of 90 students , 70 % of the students took the final exam on the assigned day while the rest of the students took the exam on a make - up date . if the students on the assigned day had an average score of 60 % , and the students on the make - up date had an average score of 70 % , what was the average score for the entire class ?',\n 'choices': ['a. 63 %', 'b. 64 %', 'c. 65 %', 'd. 66 %', 'e. 67 %'],\n 'explanation': '\"70 % of the class scored 60 % and 30 % of the class scored 70 % . the difference between 60 % and 70 % is 10 % . the average will be 60 % + 0.3 ( 10 % ) = 63 % . the answer is a .\"',\n 'formula': '(((70 * 60) + (70 * (90 - 70))) / 90)',\n 'answer': 'a. 63 %',\n 'ok': True}"},"metadata":{}}]},{"cell_type":"code","source":"test_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.491613Z","iopub.execute_input":"2024-01-19T07:52:07.492103Z","iopub.status.idle":"2024-01-19T07:52:07.501584Z","shell.execute_reply.started":"2024-01-19T07:52:07.492058Z","shell.execute_reply":"2024-01-19T07:52:07.500688Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'id': '01-0203',\n 'question': 'Một cửa hàng đã bán 30% số hàng hiện có và thu được 15 000 000 đồng. Hỏi nếu bán hết hàng thì cửa hàng thu được bao nhiêu tiền?',\n 'choices': ['A. 4 500 000 đồng',\n  'B. 45 000 000 đồng',\n  'C. 50 000 000 đồng',\n  'D. 450 000 000 đồng']}"},"metadata":{}}]},{"cell_type":"code","source":"MAX_TOKEN_MODEL = 1024","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.502688Z","iopub.execute_input":"2024-01-19T07:52:07.502991Z","iopub.status.idle":"2024-01-19T07:52:07.511066Z","shell.execute_reply.started":"2024-01-19T07:52:07.502952Z","shell.execute_reply":"2024-01-19T07:52:07.510192Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"DEFAULT_PAD_TOKEN = \"<|pad_0|>\" # \"[PAD]\" \"<|pad_0|>\"\nDEFAULT_EOS_TOKEN = \"<|end_of_turn|>\" # \"<|end_of_turn|>\" # \"</s>\" \"<|endoftext|>\" \"<|end_of_turn|>\"\nDEFAULT_BOS_TOKEN = \"<s>\" # \"<s>\" \"<|endoftext|>\"\nDEFAULT_UNK_TOKEN = \"<unk>\" # \"<unk>\" \"<|endoftext|>\"\nDEFAULT_BOI_TOKEN = \"[INST]\" # \"Human:\" # \"[INST]\" \"<|human|>\" \"<|end_of_turn|>\"\nDEFAULT_EOI_TOKEN = \"[/INST]\" # \"Assistant:\" # \"[/INST]\" \"<|human|>\" \"<|end_of_turn|>\"\nPROMPT_DICT = {\n    \"prompt_formula\": (\n        \"GPT4 Correct User: write Explanation and Expression\\n\"\n        \"Below is a question. paired with the choices, one of the choices is the correct answer to the question. \"\n        \"Write a explanation for solution and a python expression that provide useful information to find true answer of question. \"\n        \"Note: expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n        \"## Explanation:\\n{explanation}\\n\\n\"\n        \"## Expression:\\n{formula}\"\n        \"\" + DEFAULT_EOS_TOKEN  \n    ),\n    \"prompt_formula_run\": (\n        \"GPT4 Correct User: write Explanation and Expression\\n\"\n        \"Below is a question. paired with the choices, one of the choices is the correct answer to the question. \"\n        \"Write a explanation for solution and a python expression that provide useful information to find true answer of question. \"\n        \"Note: expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n#         \"## Explanation:\\n\"\n#         \"### Expression:\\n{{expression}}\"\n    ),\n     \"prompt_formula_run_previous\": (\n        \"GPT4 Correct User: write Explanation and Expression\\n\"\n        \"Below is a question. paired with the choices, one of the choices is the correct answer to the question. \"\n        \"Write a explanation for solution and a python expression that provide useful information to find true answer of question. \"\n        \"Note: expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\\n\\n\"\n        \"## Previous expression explanation:\\n{explanation}\\n\\n\"\n        \"## Previous expression:\\n{formula} = {outformula}\\n\"\n        \"Note: If expression result not match one of the choices then must change it\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n#         \"## Explanation:\\n\"\n#         \"### Expression:\\n{{expression}}\"\n    ),\n    \"prompt_input\": (\n        \"GPT4 Correct User: write Answer\\n\"\n        \"Below is a question. with the choices, one of the choices is the correct answer to the question, \"\n        \"expression and eval expression result that provide useful information to find true answer. \"\n        \"Write a explanation to solve question and write a choice is true answer to question.\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\\n\\n\"\n        \"## Expression caculate answer:\\n{formula} = {outformula}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n        \"## Explanation:\\n{explanation}\\n\\n\"\n        \"## Answer:\\n{answer}\"\n        \"\" + DEFAULT_EOS_TOKEN\n    ),\n    \"prompt_input_run\": (\n        \"GPT4 Correct User: write Answer\\n\"\n        \"Below is a question. with the choices, one of the choices is the correct answer to the question, \"\n        \"expression and eval expression result that provide useful information to find true answer. \"\n        \"Write a explanation to solve question and write a choice is true answer to question.\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\\n\\n\"\n        \"## Expression explanation:\\n{explanation}\\n\\n\"\n        \"## Expression caculate answer:\\n{formula} = {outformula}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n#         \"## Explanation:\\n\"\n#         \"## Answer:\\n\"\n    ),\n    \n    \"prompt_full\": (\n#         \"You are a helpful assistant named DAN. You are an expert in worldly knowledge, skilled in employing a probing questioning strategy, and you carefully consider each step before providing answers. \\n\\n\"\n#         \"\" + DEFAULT_BOI_TOKEN + \"\\n\"\n#         \"### Instruction:\\n\"\n        \"GPT4 Correct User:\\n\"\n        \"Below is the math question. paired with the choices, one of the choices is the correct answer to the question. \"\n        \"Let's thing step by step, write a explanation to find solution and write a choice is true answer to question.\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n#         \"### Response:\\n\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n        \"## Explanation:\\n{explanation}\\n\\n\"\n        \"## Answer:\\n{answer}\"\n        \"\" + DEFAULT_EOS_TOKEN\n    ),\n    \n    \"prompt_full_run\": (\n#         \"You are a helpful assistant named DAN. You are an expert in worldly knowledge, skilled in employing a probing questioning strategy, and you carefully consider each step before providing answers. \\n\\n\"\n#         \"\" + DEFAULT_BOI_TOKEN + \"\\n\"\n#         \"### Instruction:\\n\"\n        \"GPT4 Correct User:\\n\"\n        \"Below is the math question. paired with the choices, one of the choices is the correct answer to the question. \"\n        \"Let's thing step by step, write a explanation to find solution and write a choice is true answer to question.\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Choices:\\n{choices}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n#         \"### Response:\\n\\n\"\n        \"GPT4 Correct Assistant:\\n\"\n    ),\n    \n    ## Implement LLM\n    \"prompt_formula_i\": (\n        \"Math Correct User: write Explanation and Expression\\n\"\n        \"Write a explanation for solution and a python expression that caculate true answer of question. \"\n        \"Expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"\" + DEFAULT_EOI_TOKEN + \"\"\n        \"Math Correct Assistant:\\n\"\n        \"## Explanation:\\n{explanation}\\n\\n\"\n        \"## Expression:\\n{formula}\"\n        \"\" + DEFAULT_EOS_TOKEN  \n    ),\n    \"prompt_formula_run_i\": (\n        \"Math Correct User: write Explanation and Expression\\n\"\n        \"Write a explanation for solution and a python expression that caculate true answer of question. \"\n        \"Expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"\" + DEFAULT_EOI_TOKEN + \"\"\n        \"Math Correct Assistant:\"\n    ),\n     \"prompt_formula_run_previous_i\": (\n        \"Math Correct User: write Explanation and fix Expression\\n\"\n        \"Write a explanation for solution and a python expression that caculate true answer of question. \"\n        \"Expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\"\n        \"\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Previous expression:\\n{formula} = {outformula}\\n\"\n        \"If expression result is an error or caculate wrong answer then must fix it\"\n        \"\" + DEFAULT_EOI_TOKEN + \"\"\n        \"Math Correct Assistant:\"\n#         \"## Explanation:\\n\"\n#         \"### Expression:\\n{{expression}}\"\n    ),\n    \"prompt_input_i\": (\n        \"Math Correct User: write true Answer and explantion\\n\"\n        \"Write a explanation to solve question and write true answer to question.\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Expression caculate answer:\\n{formula} = {outformula}\"\n        \"\" + DEFAULT_EOI_TOKEN + \"\"\n        \"Math Correct Assistant:\\n\"\n        \"## Explanation:\\n{explanation}\\n\\n\"\n        \"## Answer:\\n{answer}\"\n        \"\" + DEFAULT_EOS_TOKEN\n    ),\n    \"prompt_input_run_i\": (\n        \"Math Correct User: write true Answer and explantion\\n\"\n        \"Write a explanation to solve question and write true answer to question.\\n\\n\"\n        \"## Question:\\n{question}\\n\\n\"\n        \"## Expression caculate answer:\\n{formula} = {outformula}\"\n        \"\" + DEFAULT_EOI_TOKEN + \"\"\n        \"Math Correct Assistant:\"\n    ),\n    \n#     \"prompt_full\": (\n#         \"Below is the math question. paired with the choices, one of the choices is the correct answer to the question. \"\n#         \"Write a explanation for solution and write a choice is true answer to question.\"\n#         \"\\n\\n\"\n#         \"## Question:\\n{question}\\n\\n\"\n#         \"## Choices:\\n{choices}\"\n#         \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n#         \"## Explanation:\\n{explanation}\\n\\n\"\n#         \"## Answer:\\n{answer}\"\n#         \" \" + DEFAULT_EOS_TOKEN  \n#     ),\n    \n#     \"prompt_full_run\": (\n#         \"Below is the math question. paired with the choices, one of the choices is the correct answer to the question. \"\n#         \"Write a explanation for solution and write a choice is true answer to question. Let's think step by step.\"\n#         \"\\n\\n\"\n#         \"## Question:\\n{question}\\n\\n\"\n#         \"## Choices:\\n{choices}\\n\\n\"\n# #         \"\\n\" + DEFAULT_EOI_TOKEN + \"\\n\"\n# #         \"## Explanation:\\n\"\n#     ),\n    \n#     \"prompt_input_run_noexp\": (\n#         DEFAULT_BOI_TOKEN + \" Below is an instruction that describes a task. paired with the choices, one of the choices is the correct answer to the request. \"\n#         \"Write a response that appropriately completes the request.\\n\\n\"\n#         \"### Instruction:\\n{instruction}\\n\\n### Choices:\\n{choices}\\n\\n\"\n#         \"### Explanation:\\n No explantion.\\n\"\n#     ),\n#     \"prompt_input_run_check\": (\n#         DEFAULT_BOI_TOKEN + \" \"\n#         \"Below is an instruction that describes a task, paired with the choices, one of the choices is the correct answer to the request. \"\n#         \"Check if answer below false then response true answer else repeat the answer\\n\\n\"\n#         \"### Instruction:\\n{instruction}\\n\\n### Choices:\\n{choices}\\n\\n\"\n#         \"### Answer:\\n{answer}\\n\\n\"\n#         \"### Response:\"\n#     )\n}","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.512399Z","iopub.execute_input":"2024-01-19T07:52:07.512718Z","iopub.status.idle":"2024-01-19T07:52:07.531224Z","shell.execute_reply.started":"2024-01-19T07:52:07.512694Z","shell.execute_reply":"2024-01-19T07:52:07.530341Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"timeGlobal = 0\ndef startTime():\n    global timeGlobal\n    timeGlobal = time.time()\ndef getTime():\n    return (time.time() - timeGlobal)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.532331Z","iopub.execute_input":"2024-01-19T07:52:07.532973Z","iopub.status.idle":"2024-01-19T07:52:07.545349Z","shell.execute_reply.started":"2024-01-19T07:52:07.532947Z","shell.execute_reply":"2024-01-19T07:52:07.544475Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def ApplyPromptTemplate(data_arg, typeP = \"prompt_formula\"):\n    return PROMPT_DICT[typeP].format(**data_arg)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.546417Z","iopub.execute_input":"2024-01-19T07:52:07.547002Z","iopub.status.idle":"2024-01-19T07:52:07.556243Z","shell.execute_reply.started":"2024-01-19T07:52:07.546977Z","shell.execute_reply":"2024-01-19T07:52:07.555320Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess data","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nimport random","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.557463Z","iopub.execute_input":"2024-01-19T07:52:07.557948Z","iopub.status.idle":"2024-01-19T07:52:07.565563Z","shell.execute_reply.started":"2024-01-19T07:52:07.557923Z","shell.execute_reply":"2024-01-19T07:52:07.564634Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"num_train_dataset = len(train_data)\nvalition_radio = 0.1\ntokenized_train_dataset_raw = train_data","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.566489Z","iopub.execute_input":"2024-01-19T07:52:07.566739Z","iopub.status.idle":"2024-01-19T07:52:07.575844Z","shell.execute_reply.started":"2024-01-19T07:52:07.566717Z","shell.execute_reply":"2024-01-19T07:52:07.574898Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# tokenized_val_dataset_raw = random.sample(train_data, int(valition_radio * num_train_dataset))\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/valid.json\", revision=\"main\", repo_type=\"dataset\", local_dir=\"datasetRaw\", local_dir_use_symlinks=False)\nos.system('mv \"/kaggle/working/datasetRaw/Elementary Maths Solving/valid.json\" \"/kaggle/working/datasetRaw/\"')\nwith open(\"/kaggle/working/datasetRaw/valid.json\", \"r\") as f:\n    tokenized_val_dataset_raw = json.loads(f.read())","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.576954Z","iopub.execute_input":"2024-01-19T07:52:07.577272Z","iopub.status.idle":"2024-01-19T07:52:07.732484Z","shell.execute_reply.started":"2024-01-19T07:52:07.577238Z","shell.execute_reply":"2024-01-19T07:52:07.731637Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Elementary Maths Solving/valid.json:   0%|          | 0.00/25.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f86cee66e714ca087fe679811b6d9a5"}},"metadata":{}}]},{"cell_type":"code","source":"# datasetStruct = {\"input\":[], \"output\":[]}\ndataset = {\"text\":[]}\nnum_train_dataset = len(tokenized_train_dataset_raw)\nfor i in range(num_train_dataset):\n    ttdro = tokenized_train_dataset_raw[i]\n    \n#     if \"explanation\" not in ttdro.keys():\n#         continue\n    if \"answer\" not in ttdro.keys():\n        continue\n    \n#     dataset[\"text\"].append(ApplyPromptTemplate({\n#         \"question\": ttdro[\"question\"],\n#         \"choices\": \"\\n\".join(ttdro[\"choices\"]),\n#         \"explanation\": ttdro[\"explanation\"],\n#         \"answer\": ttdro[\"answer\"],\n#     }, typeP=\"prompt_full\"))\n    if \"formula\" not in ttdro.keys():\n        continue\n        \n    if \"explanation\" not in ttdro.keys():\n        try:\n            ttdro[\"explanation\"] = \"{0} = {1}\".format(ttdro[\"formula\"], eval(ttdro[\"formula\"]))\n        except:\n            pass\n        \n    dataset[\"text\"].append(ApplyPromptTemplate({\n        \"question\": ttdro[\"question\"],\n        \"choices\": \"\\n\".join(ttdro[\"choices\"]),\n        \"explanation\": ttdro[\"explanation\"],\n        \"formula\": ttdro[\"formula\"],\n    }, typeP=\"prompt_formula_i\"))\n    \n    try:\n        outformula = eval(ttdro[\"formula\"])\n    except Exception as e:\n        outformula = \"Invalid formula\"\n    \n    dataset[\"text\"].append(ApplyPromptTemplate({\n        \"question\": ttdro[\"question\"],\n        \"choices\": \"\\n\".join(ttdro[\"choices\"]),\n        \"explanation\": ttdro[\"explanation\"],\n        \"formula\": ttdro[\"formula\"],\n        \"outformula\": outformula,\n        \"answer\": ttdro[\"answer\"],\n    }, typeP=\"prompt_input_i\"))\n    \n#     input_content = \"{0}\".format(\n#         # DEFAULT_BOI_TOKEN,\n#         ApplyPromptTemplate(ttdro['question'], ttdro['choices']),\n#     )\n    # --------------------\n# #     datasetStruct[\"input\"].append(input_content)\n    \n#     output_content = \"{0}{1}\\n\\n{2} {3}\".format(\n#         DEFAULT_EOI_TOKEN,\n#         \"### Explanation:\\n{0}\".format(ttdro['explanation']),\n#         \"### Formula:\\n{0}\".format(ttdro['formula']),\n#         DEFAULT_EOS_TOKEN,\n#     )\n# #     datasetStruct[\"output\"].append(output_content)\n    \n#     dataset[\"text\"].append(input_content + output_content)\n    \n    # No explantion\n#     output_content = \"\\n{0} \\n\\n{1}\\n\\n{2} {3}\".format(\n#             DEFAULT_EOI_TOKEN,\n#             \"### Explanation:\\nNo explanation\",\n#             \"### Answer:\\n{0}\".format(ttdro['answer']),\n#             DEFAULT_EOS_TOKEN,\n#         )\n#     datasetStruct[\"output\"].append(output_content)\n    \n#     dataset[\"text\"].append(input_content + output_content)\n#     <s>[INST][/INST] </s>","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:07.736842Z","iopub.execute_input":"2024-01-19T07:52:07.737172Z","iopub.status.idle":"2024-01-19T07:52:09.376509Z","shell.execute_reply.started":"2024-01-19T07:52:07.737139Z","shell.execute_reply":"2024-01-19T07:52:09.375377Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"print(tokenized_train_dataset_raw[216])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:09.378001Z","iopub.execute_input":"2024-01-19T07:52:09.378373Z","iopub.status.idle":"2024-01-19T07:52:09.383917Z","shell.execute_reply.started":"2024-01-19T07:52:09.378344Z","shell.execute_reply":"2024-01-19T07:52:09.382899Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"{'ok': True, 'id': '1670', 'question': 'Trong các phân số sau phân số nào lớn hơn 1:', 'choices': ['A. $\\\\frac{4}{7}$', 'B. $\\\\frac{8}{5}$', 'C. $\\\\frac{5}{5}$', 'D. $\\\\frac{3}{4}$'], 'explanation': 'Phân số lớn hơn 1 thì tử số lớn hơn mẫu số. Phân số lớn hơn 1 là: $\\\\frac{8}{5}$', 'answer': 'B. $\\\\frac{8}{5}$', 'formula': 'max(4/7, 8/5, 5/5, 3/4)'}\n","output_type":"stream"}]},{"cell_type":"code","source":"i_test = 432\nprint(dataset[\"text\"][i_test])\nprint(dataset[\"text\"][i_test + 1])\n# print(datasetStruct[\"input\"][33])\n# print(datasetStruct[\"output\"][33])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:09.385173Z","iopub.execute_input":"2024-01-19T07:52:09.385495Z","iopub.status.idle":"2024-01-19T07:52:09.400539Z","shell.execute_reply.started":"2024-01-19T07:52:09.385468Z","shell.execute_reply":"2024-01-19T07:52:09.399522Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stdout","text":"Math Correct User: write Explanation and Expression\nWrite a explanation for solution and a python expression that caculate true answer of question. Expression must be runable python expression, must in one line and only using library math, numpy, datetime, itertools\n\n## Question:\nTrong các phân số sau phân số nào lớn hơn 1:\n\n[/INST]Math Correct Assistant:\n## Explanation:\nPhân số lớn hơn 1 thì tử số lớn hơn mẫu số. Phân số lớn hơn 1 là: $\\frac{8}{5}$\n\n## Expression:\nmax(4/7, 8/5, 5/5, 3/4)<|end_of_turn|>\nMath Correct User: write true Answer and explantion\nWrite a explanation to solve question and write true answer to question.\n\n## Question:\nTrong các phân số sau phân số nào lớn hơn 1:\n\n## Expression caculate answer:\nmax(4/7, 8/5, 5/5, 3/4) = 1.6[/INST]Math Correct Assistant:\n## Explanation:\nPhân số lớn hơn 1 thì tử số lớn hơn mẫu số. Phân số lớn hơn 1 là: $\\frac{8}{5}$\n\n## Answer:\nB. $\\frac{8}{5}$<|end_of_turn|>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(dataset[\"text\"]))\n# print(len(datasetStruct[\"input\"]))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:09.401843Z","iopub.execute_input":"2024-01-19T07:52:09.402238Z","iopub.status.idle":"2024-01-19T07:52:09.411483Z","shell.execute_reply.started":"2024-01-19T07:52:09.402192Z","shell.execute_reply":"2024-01-19T07:52:09.410503Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"103382\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"markdown","source":"### Config","metadata":{}},{"cell_type":"code","source":"FLAGS = {'MAX_INPUT': MAX_TOKEN_MODEL,\n         'LOGGING_STEPS': 100,\n         'NUM_EPOCHS': 2,\n         'BATCH_SIZE': 8, #Making batch_size lower then 8 will result in slower training, but will take more memory. Fortunately, we have 128GBs. Setting higher batch_size doesn't seem to improve time.\n          'NUM_STEPS': len(dataset[\"text\"])} ","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:08:13.595465Z","iopub.execute_input":"2024-01-18T11:08:13.595711Z","iopub.status.idle":"2024-01-18T11:08:13.613448Z","shell.execute_reply.started":"2024-01-18T11:08:13.595685Z","shell.execute_reply":"2024-01-18T11:08:13.612763Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"### Load model","metadata":{}},{"cell_type":"code","source":"# bnb_config = BitsAndBytesConfig(  \n#     load_in_4bit= True,\n#     bnb_4bit_quant_type= \"nf4\",\n#     bnb_4bit_compute_dtype= torch.bfloat16,\n#     bnb_4bit_use_double_quant= False,\n# )\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n#         model_hotamath_path,\n#     load_in_4bit=True,\n#     load_in_8bit= True,\n#     quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n#     torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:08:13.614318Z","iopub.execute_input":"2024-01-18T11:08:13.614590Z","iopub.status.idle":"2024-01-18T11:09:25.243085Z","shell.execute_reply.started":"2024-01-18T11:08:13.614563Z","shell.execute_reply":"2024-01-18T11:09:25.242423Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stderr","text":"Downloading config.json: 100%|██████████| 623/623 [00:00<00:00, 3.42MB/s]\nDownloading (…)fetensors.index.json: 100%|██████████| 23.9k/23.9k [00:00<00:00, 50.2MB/s]\nDownloading shards:   0%|          | 0/3 [00:00<?, ?it/s]\nDownloading (…)of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]\u001b[A\nDownloading (…)of-00003.safetensors:   1%|          | 31.5M/4.94G [00:00<00:22, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   1%|▏         | 62.9M/4.94G [00:00<00:22, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   2%|▏         | 94.4M/4.94G [00:00<00:21, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 126M/4.94G [00:00<00:21, 222MB/s] \u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 157M/4.94G [00:00<00:21, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   4%|▍         | 189M/4.94G [00:00<00:21, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   4%|▍         | 220M/4.94G [00:00<00:21, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   5%|▌         | 252M/4.94G [00:01<00:21, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   6%|▌         | 283M/4.94G [00:01<00:21, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   6%|▋         | 315M/4.94G [00:01<00:20, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   7%|▋         | 346M/4.94G [00:01<00:20, 223MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 377M/4.94G [00:01<00:20, 223MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 409M/4.94G [00:01<00:20, 223MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   9%|▉         | 440M/4.94G [00:01<00:20, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|▉         | 472M/4.94G [00:02<00:20, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|█         | 503M/4.94G [00:02<00:20, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  11%|█         | 535M/4.94G [00:02<00:19, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  11%|█▏        | 566M/4.94G [00:02<00:19, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  12%|█▏        | 598M/4.94G [00:02<00:19, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  13%|█▎        | 629M/4.94G [00:02<00:19, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  13%|█▎        | 661M/4.94G [00:02<00:19, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  14%|█▍        | 692M/4.94G [00:03<00:19, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▍        | 724M/4.94G [00:03<00:19, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▌        | 755M/4.94G [00:03<00:18, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  16%|█▌        | 786M/4.94G [00:03<00:18, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 818M/4.94G [00:03<00:18, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 849M/4.94G [00:03<00:18, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  18%|█▊        | 881M/4.94G [00:03<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  18%|█▊        | 912M/4.94G [00:04<00:18, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  19%|█▉        | 944M/4.94G [00:04<00:18, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  20%|█▉        | 975M/4.94G [00:04<00:18, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  20%|██        | 1.01G/4.94G [00:04<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  21%|██        | 1.04G/4.94G [00:04<00:18, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  22%|██▏       | 1.07G/4.94G [00:04<00:17, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  22%|██▏       | 1.10G/4.94G [00:05<00:17, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  23%|██▎       | 1.13G/4.94G [00:05<00:17, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  24%|██▎       | 1.16G/4.94G [00:05<00:17, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  24%|██▍       | 1.20G/4.94G [00:05<00:17, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  25%|██▍       | 1.23G/4.94G [00:05<00:17, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  25%|██▌       | 1.26G/4.94G [00:05<00:17, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  26%|██▌       | 1.29G/4.94G [00:05<00:16, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  27%|██▋       | 1.32G/4.94G [00:06<00:16, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  27%|██▋       | 1.35G/4.94G [00:06<00:16, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  28%|██▊       | 1.38G/4.94G [00:06<00:16, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  29%|██▊       | 1.42G/4.94G [00:06<00:16, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  29%|██▉       | 1.45G/4.94G [00:06<00:16, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  30%|██▉       | 1.48G/4.94G [00:06<00:15, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  31%|███       | 1.51G/4.94G [00:06<00:15, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  31%|███       | 1.54G/4.94G [00:07<00:15, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  32%|███▏      | 1.57G/4.94G [00:07<00:15, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  32%|███▏      | 1.60G/4.94G [00:07<00:15, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  33%|███▎      | 1.64G/4.94G [00:07<00:15, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  34%|███▎      | 1.67G/4.94G [00:07<00:15, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  34%|███▍      | 1.70G/4.94G [00:07<00:14, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  35%|███▌      | 1.73G/4.94G [00:07<00:14, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  36%|███▌      | 1.76G/4.94G [00:08<00:14, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  36%|███▋      | 1.79G/4.94G [00:08<00:14, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  37%|███▋      | 1.82G/4.94G [00:08<00:14, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  38%|███▊      | 1.86G/4.94G [00:08<00:14, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  38%|███▊      | 1.89G/4.94G [00:08<00:14, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  39%|███▉      | 1.92G/4.94G [00:08<00:14, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  39%|███▉      | 1.95G/4.94G [00:08<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  40%|████      | 1.98G/4.94G [00:09<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  41%|████      | 2.01G/4.94G [00:09<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  41%|████▏     | 2.04G/4.94G [00:09<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  42%|████▏     | 2.08G/4.94G [00:09<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  43%|████▎     | 2.11G/4.94G [00:09<00:13, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  43%|████▎     | 2.14G/4.94G [00:09<00:13, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▍     | 2.17G/4.94G [00:09<00:12, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  45%|████▍     | 2.20G/4.94G [00:10<00:12, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  45%|████▌     | 2.23G/4.94G [00:10<00:12, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▌     | 2.26G/4.94G [00:10<00:12, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▋     | 2.30G/4.94G [00:10<00:12, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  47%|████▋     | 2.33G/4.94G [00:10<00:12, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.36G/4.94G [00:10<00:12, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.39G/4.94G [00:11<00:11, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  49%|████▉     | 2.42G/4.94G [00:11<00:11, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  50%|████▉     | 2.45G/4.94G [00:11<00:11, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  50%|█████     | 2.49G/4.94G [00:11<00:11, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████     | 2.52G/4.94G [00:11<00:11, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  52%|█████▏    | 2.55G/4.94G [00:11<00:11, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  52%|█████▏    | 2.58G/4.94G [00:11<00:11, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.61G/4.94G [00:12<00:10, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.64G/4.94G [00:12<00:10, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  54%|█████▍    | 2.67G/4.94G [00:12<00:10, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▍    | 2.71G/4.94G [00:12<00:15, 149MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▌    | 2.74G/4.94G [00:12<00:13, 164MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▌    | 2.77G/4.94G [00:13<00:12, 176MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▋    | 2.79G/4.94G [00:13<00:11, 182MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  57%|█████▋    | 2.81G/4.94G [00:13<00:11, 188MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  57%|█████▋    | 2.84G/4.94G [00:13<00:10, 196MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.86G/4.94G [00:13<00:10, 199MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.88G/4.94G [00:13<00:10, 201MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  59%|█████▉    | 2.92G/4.94G [00:13<00:09, 206MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|█████▉    | 2.95G/4.94G [00:13<00:09, 209MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|██████    | 2.98G/4.94G [00:13<00:09, 210MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  61%|██████    | 3.01G/4.94G [00:14<00:09, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  62%|██████▏   | 3.04G/4.94G [00:14<00:08, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  62%|██████▏   | 3.07G/4.94G [00:14<00:08, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  63%|██████▎   | 3.10G/4.94G [00:14<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  63%|██████▎   | 3.14G/4.94G [00:14<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  64%|██████▍   | 3.17G/4.94G [00:14<00:08, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  65%|██████▍   | 3.20G/4.94G [00:15<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  65%|██████▌   | 3.23G/4.94G [00:15<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  66%|██████▌   | 3.26G/4.94G [00:15<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  67%|██████▋   | 3.29G/4.94G [00:15<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  67%|██████▋   | 3.32G/4.94G [00:15<00:07, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  68%|██████▊   | 3.36G/4.94G [00:15<00:07, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  69%|██████▊   | 3.39G/4.94G [00:15<00:07, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  69%|██████▉   | 3.42G/4.94G [00:16<00:07, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  70%|██████▉   | 3.45G/4.94G [00:16<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  70%|███████   | 3.48G/4.94G [00:16<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  71%|███████   | 3.51G/4.94G [00:16<00:06, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  72%|███████▏  | 3.54G/4.94G [00:16<00:06, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  72%|███████▏  | 3.58G/4.94G [00:16<00:06, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  73%|███████▎  | 3.61G/4.94G [00:16<00:06, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  74%|███████▎  | 3.64G/4.94G [00:17<00:06, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  74%|███████▍  | 3.67G/4.94G [00:17<00:05, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  75%|███████▍  | 3.70G/4.94G [00:17<00:05, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  76%|███████▌  | 3.73G/4.94G [00:17<00:05, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  76%|███████▌  | 3.76G/4.94G [00:17<00:05, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  77%|███████▋  | 3.80G/4.94G [00:17<00:05, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  77%|███████▋  | 3.83G/4.94G [00:17<00:05, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  78%|███████▊  | 3.86G/4.94G [00:18<00:05, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  79%|███████▊  | 3.89G/4.94G [00:18<00:04, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  79%|███████▉  | 3.92G/4.94G [00:18<00:04, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  80%|███████▉  | 3.95G/4.94G [00:18<00:04, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  81%|████████  | 3.98G/4.94G [00:18<00:04, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  81%|████████  | 4.02G/4.94G [00:18<00:04, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  82%|████████▏ | 4.05G/4.94G [00:18<00:04, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  83%|████████▎ | 4.08G/4.94G [00:19<00:04, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  83%|████████▎ | 4.11G/4.94G [00:19<00:03, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  84%|████████▍ | 4.14G/4.94G [00:19<00:03, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  84%|████████▍ | 4.17G/4.94G [00:19<00:03, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  85%|████████▌ | 4.20G/4.94G [00:19<00:03, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  86%|████████▌ | 4.24G/4.94G [00:19<00:03, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  86%|████████▋ | 4.27G/4.94G [00:20<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  87%|████████▋ | 4.30G/4.94G [00:20<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  88%|████████▊ | 4.33G/4.94G [00:20<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  88%|████████▊ | 4.36G/4.94G [00:20<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  89%|████████▉ | 4.39G/4.94G [00:20<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  90%|████████▉ | 4.42G/4.94G [00:20<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  90%|█████████ | 4.46G/4.94G [00:20<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  91%|█████████ | 4.49G/4.94G [00:21<00:02, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  91%|█████████▏| 4.52G/4.94G [00:21<00:02, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  92%|█████████▏| 4.55G/4.94G [00:21<00:01, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  93%|█████████▎| 4.58G/4.94G [00:21<00:01, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  93%|█████████▎| 4.61G/4.94G [00:21<00:01, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  94%|█████████▍| 4.65G/4.94G [00:21<00:01, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  95%|█████████▍| 4.68G/4.94G [00:21<00:01, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  95%|█████████▌| 4.71G/4.94G [00:22<00:01, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  96%|█████████▌| 4.74G/4.94G [00:22<00:00, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  97%|█████████▋| 4.77G/4.94G [00:22<00:00, 210MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  97%|█████████▋| 4.80G/4.94G [00:22<00:00, 210MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  98%|█████████▊| 4.83G/4.94G [00:22<00:00, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  98%|█████████▊| 4.87G/4.94G [00:22<00:00, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  99%|█████████▉| 4.90G/4.94G [00:22<00:00, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors: 100%|██████████| 4.94G/4.94G [00:23<00:00, 213MB/s]\u001b[A\nDownloading shards:  33%|███▎      | 1/3 [00:23<00:46, 23.32s/it]\nDownloading (…)of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]\u001b[A\nDownloading (…)of-00003.safetensors:   1%|          | 31.5M/5.00G [00:00<00:24, 202MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   1%|          | 52.4M/5.00G [00:00<00:24, 203MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   2%|▏         | 83.9M/5.00G [00:00<00:23, 210MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   2%|▏         | 105M/5.00G [00:00<00:23, 209MB/s] \u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 136M/5.00G [00:00<00:23, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 168M/5.00G [00:00<00:22, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   4%|▍         | 199M/5.00G [00:00<00:22, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   5%|▍         | 231M/5.00G [00:01<00:22, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   5%|▌         | 262M/5.00G [00:01<00:22, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   6%|▌         | 294M/5.00G [00:01<00:22, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   7%|▋         | 325M/5.00G [00:01<00:21, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   7%|▋         | 357M/5.00G [00:01<00:21, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 388M/5.00G [00:01<00:21, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 419M/5.00G [00:01<00:21, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   9%|▉         | 451M/5.00G [00:02<00:21, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|▉         | 482M/5.00G [00:02<00:21, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|█         | 514M/5.00G [00:02<00:20, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  11%|█         | 545M/5.00G [00:02<00:20, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  12%|█▏        | 577M/5.00G [00:02<00:20, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  12%|█▏        | 608M/5.00G [00:02<00:20, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  13%|█▎        | 640M/5.00G [00:02<00:20, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  13%|█▎        | 671M/5.00G [00:03<00:20, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  14%|█▍        | 703M/5.00G [00:03<00:20, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▍        | 734M/5.00G [00:03<00:19, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▌        | 765M/5.00G [00:03<00:19, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  16%|█▌        | 797M/5.00G [00:03<00:19, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 828M/5.00G [00:03<00:19, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 860M/5.00G [00:04<00:19, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  18%|█▊        | 891M/5.00G [00:04<00:19, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  18%|█▊        | 923M/5.00G [00:04<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  19%|█▉        | 954M/5.00G [00:04<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  20%|█▉        | 986M/5.00G [00:04<00:18, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  20%|██        | 1.02G/5.00G [00:04<00:18, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  21%|██        | 1.05G/5.00G [00:05<00:26, 150MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  22%|██▏       | 1.08G/5.00G [00:05<00:23, 164MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  22%|██▏       | 1.11G/5.00G [00:05<00:22, 177MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  23%|██▎       | 1.14G/5.00G [00:05<00:20, 186MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  23%|██▎       | 1.17G/5.00G [00:05<00:19, 193MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  24%|██▍       | 1.21G/5.00G [00:05<00:19, 199MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  25%|██▍       | 1.23G/5.00G [00:05<00:18, 201MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  25%|██▌       | 1.26G/5.00G [00:06<00:18, 204MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  26%|██▌       | 1.29G/5.00G [00:06<00:17, 207MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  26%|██▋       | 1.32G/5.00G [00:06<00:17, 209MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  27%|██▋       | 1.35G/5.00G [00:06<00:17, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  28%|██▊       | 1.38G/5.00G [00:06<00:17, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  28%|██▊       | 1.42G/5.00G [00:06<00:16, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  29%|██▉       | 1.45G/5.00G [00:06<00:16, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  30%|██▉       | 1.48G/5.00G [00:07<00:16, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  30%|███       | 1.51G/5.00G [00:07<00:16, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  31%|███       | 1.54G/5.00G [00:07<00:16, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  31%|███▏      | 1.57G/5.00G [00:07<00:16, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  32%|███▏      | 1.60G/5.00G [00:07<00:15, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  33%|███▎      | 1.64G/5.00G [00:07<00:15, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  33%|███▎      | 1.67G/5.00G [00:08<00:15, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  34%|███▍      | 1.70G/5.00G [00:08<00:15, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  35%|███▍      | 1.73G/5.00G [00:08<00:15, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  35%|███▌      | 1.76G/5.00G [00:08<00:15, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  36%|███▌      | 1.79G/5.00G [00:08<00:15, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  36%|███▋      | 1.82G/5.00G [00:08<00:15, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  37%|███▋      | 1.86G/5.00G [00:08<00:14, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  38%|███▊      | 1.89G/5.00G [00:09<00:14, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  38%|███▊      | 1.92G/5.00G [00:09<00:14, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  39%|███▉      | 1.95G/5.00G [00:09<00:14, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  40%|███▉      | 1.98G/5.00G [00:09<00:13, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  40%|████      | 2.01G/5.00G [00:09<00:13, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  41%|████      | 2.04G/5.00G [00:09<00:13, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  42%|████▏     | 2.08G/5.00G [00:09<00:13, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  42%|████▏     | 2.11G/5.00G [00:10<00:13, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  43%|████▎     | 2.14G/5.00G [00:10<00:14, 203MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  43%|████▎     | 2.16G/5.00G [00:10<00:14, 197MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▎     | 2.18G/5.00G [00:10<00:15, 184MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▍     | 2.20G/5.00G [00:10<00:15, 178MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▍     | 2.22G/5.00G [00:10<00:16, 165MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  45%|████▍     | 2.24G/5.00G [00:10<00:18, 148MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  45%|████▌     | 2.26G/5.00G [00:11<00:19, 140MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▌     | 2.29G/5.00G [00:11<00:18, 145MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▌     | 2.31G/5.00G [00:11<00:17, 156MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  47%|████▋     | 2.33G/5.00G [00:11<00:16, 160MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  47%|████▋     | 2.36G/5.00G [00:11<00:14, 177MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.39G/5.00G [00:11<00:13, 190MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.41G/5.00G [00:11<00:15, 163MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  49%|████▊     | 2.43G/5.00G [00:12<00:15, 164MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  49%|████▉     | 2.46G/5.00G [00:12<00:14, 180MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  50%|████▉     | 2.49G/5.00G [00:12<00:14, 179MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  50%|█████     | 2.51G/5.00G [00:12<00:14, 171MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████     | 2.53G/5.00G [00:12<00:15, 157MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████     | 2.55G/5.00G [00:12<00:15, 157MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████▏    | 2.57G/5.00G [00:12<00:15, 158MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  52%|█████▏    | 2.59G/5.00G [00:13<00:15, 153MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  52%|█████▏    | 2.61G/5.00G [00:13<00:16, 143MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.63G/5.00G [00:13<00:15, 158MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.66G/5.00G [00:13<00:13, 175MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  54%|█████▎    | 2.68G/5.00G [00:13<00:14, 162MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  54%|█████▍    | 2.72G/5.00G [00:13<00:13, 164MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▍    | 2.74G/5.00G [00:13<00:13, 163MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▌    | 2.76G/5.00G [00:14<00:14, 153MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▌    | 2.78G/5.00G [00:14<00:15, 146MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▌    | 2.80G/5.00G [00:14<00:13, 159MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▋    | 2.82G/5.00G [00:14<00:14, 154MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  57%|█████▋    | 2.84G/5.00G [00:14<00:13, 166MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  57%|█████▋    | 2.86G/5.00G [00:14<00:13, 161MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.88G/5.00G [00:14<00:14, 148MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.90G/5.00G [00:15<00:15, 139MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  59%|█████▊    | 2.93G/5.00G [00:15<00:15, 135MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  59%|█████▉    | 2.96G/5.00G [00:15<00:12, 159MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|█████▉    | 2.99G/5.00G [00:15<00:11, 176MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|██████    | 3.01G/5.00G [00:15<00:10, 182MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  61%|██████    | 3.04G/5.00G [00:15<00:10, 192MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  61%|██████▏   | 3.07G/5.00G [00:15<00:09, 198MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  62%|██████▏   | 3.10G/5.00G [00:16<00:09, 203MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  63%|██████▎   | 3.14G/5.00G [00:16<00:08, 207MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  63%|██████▎   | 3.17G/5.00G [00:16<00:08, 209MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  64%|██████▍   | 3.20G/5.00G [00:16<00:08, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  65%|██████▍   | 3.23G/5.00G [00:16<00:08, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  65%|██████▌   | 3.26G/5.00G [00:16<00:08, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  66%|██████▌   | 3.29G/5.00G [00:16<00:07, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  66%|██████▋   | 3.32G/5.00G [00:17<00:07, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  67%|██████▋   | 3.36G/5.00G [00:17<00:07, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  68%|██████▊   | 3.39G/5.00G [00:17<00:07, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  68%|██████▊   | 3.42G/5.00G [00:17<00:07, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  69%|██████▉   | 3.45G/5.00G [00:17<00:07, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  70%|██████▉   | 3.48G/5.00G [00:17<00:06, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  70%|███████   | 3.51G/5.00G [00:17<00:06, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  71%|███████   | 3.54G/5.00G [00:18<00:06, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  72%|███████▏  | 3.58G/5.00G [00:18<00:06, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  72%|███████▏  | 3.61G/5.00G [00:18<00:06, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  73%|███████▎  | 3.64G/5.00G [00:18<00:06, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  73%|███████▎  | 3.67G/5.00G [00:18<00:06, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  74%|███████▍  | 3.70G/5.00G [00:18<00:05, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  75%|███████▍  | 3.73G/5.00G [00:18<00:05, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  75%|███████▌  | 3.76G/5.00G [00:19<00:05, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  76%|███████▌  | 3.80G/5.00G [00:19<00:05, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  77%|███████▋  | 3.83G/5.00G [00:19<00:05, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  77%|███████▋  | 3.86G/5.00G [00:19<00:05, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  78%|███████▊  | 3.89G/5.00G [00:19<00:05, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  78%|███████▊  | 3.92G/5.00G [00:19<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  79%|███████▉  | 3.95G/5.00G [00:19<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  80%|███████▉  | 3.98G/5.00G [00:20<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  80%|████████  | 4.02G/5.00G [00:20<00:04, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  81%|████████  | 4.05G/5.00G [00:20<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  82%|████████▏ | 4.08G/5.00G [00:20<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  82%|████████▏ | 4.11G/5.00G [00:20<00:04, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  83%|████████▎ | 4.14G/5.00G [00:20<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  83%|████████▎ | 4.17G/5.00G [00:20<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  84%|████████▍ | 4.20G/5.00G [00:21<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  85%|████████▍ | 4.24G/5.00G [00:21<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  85%|████████▌ | 4.27G/5.00G [00:21<00:03, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  86%|████████▌ | 4.30G/5.00G [00:21<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  87%|████████▋ | 4.33G/5.00G [00:21<00:03, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  87%|████████▋ | 4.36G/5.00G [00:21<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  88%|████████▊ | 4.39G/5.00G [00:21<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  89%|████████▊ | 4.42G/5.00G [00:22<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  89%|████████▉ | 4.46G/5.00G [00:22<00:02, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  90%|████████▉ | 4.49G/5.00G [00:22<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  90%|█████████ | 4.52G/5.00G [00:22<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  91%|█████████ | 4.55G/5.00G [00:22<00:02, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  92%|█████████▏| 4.58G/5.00G [00:22<00:01, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  92%|█████████▏| 4.61G/5.00G [00:22<00:01, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  93%|█████████▎| 4.65G/5.00G [00:23<00:01, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  94%|█████████▎| 4.68G/5.00G [00:23<00:01, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  94%|█████████▍| 4.71G/5.00G [00:23<00:01, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  95%|█████████▍| 4.74G/5.00G [00:23<00:01, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  95%|█████████▌| 4.77G/5.00G [00:23<00:01, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  96%|█████████▌| 4.80G/5.00G [00:23<00:00, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  97%|█████████▋| 4.83G/5.00G [00:24<00:00, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  97%|█████████▋| 4.87G/5.00G [00:24<00:00, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  98%|█████████▊| 4.90G/5.00G [00:24<00:00, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  99%|█████████▊| 4.93G/5.00G [00:24<00:00, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  99%|█████████▉| 4.96G/5.00G [00:24<00:00, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors: 100%|██████████| 5.00G/5.00G [00:24<00:00, 202MB/s]\u001b[A\nDownloading shards:  67%|██████▋   | 2/3 [00:48<00:24, 24.25s/it]\nDownloading (…)of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]\u001b[A\nDownloading (…)of-00003.safetensors:   0%|          | 10.5M/4.54G [00:00<01:50, 41.2MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   1%|          | 41.9M/4.54G [00:00<00:37, 121MB/s] \u001b[A\nDownloading (…)of-00003.safetensors:   1%|▏         | 62.9M/4.54G [00:00<00:30, 147MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   2%|▏         | 94.4M/4.54G [00:00<00:25, 174MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 126M/4.54G [00:00<00:23, 188MB/s] \u001b[A\nDownloading (…)of-00003.safetensors:   3%|▎         | 157M/4.54G [00:00<00:22, 196MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   4%|▍         | 189M/4.54G [00:01<00:21, 203MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   5%|▍         | 220M/4.54G [00:01<00:20, 209MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   6%|▌         | 252M/4.54G [00:01<00:20, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   6%|▌         | 283M/4.54G [00:01<00:19, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   7%|▋         | 315M/4.54G [00:01<00:19, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 346M/4.54G [00:01<00:19, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   8%|▊         | 377M/4.54G [00:01<00:19, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:   9%|▉         | 409M/4.54G [00:02<00:18, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|▉         | 440M/4.54G [00:02<00:18, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  10%|█         | 472M/4.54G [00:02<00:18, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  11%|█         | 503M/4.54G [00:02<00:18, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  12%|█▏        | 535M/4.54G [00:02<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  12%|█▏        | 566M/4.54G [00:02<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  13%|█▎        | 598M/4.54G [00:02<00:18, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  14%|█▍        | 629M/4.54G [00:03<00:18, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▍        | 661M/4.54G [00:03<00:17, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  15%|█▌        | 692M/4.54G [00:03<00:17, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  16%|█▌        | 724M/4.54G [00:03<00:17, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 755M/4.54G [00:03<00:17, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  17%|█▋        | 786M/4.54G [00:03<00:17, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  18%|█▊        | 818M/4.54G [00:03<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  19%|█▊        | 849M/4.54G [00:04<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  19%|█▉        | 881M/4.54G [00:04<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  20%|██        | 912M/4.54G [00:04<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  21%|██        | 944M/4.54G [00:04<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  21%|██▏       | 975M/4.54G [00:04<00:16, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  22%|██▏       | 1.01G/4.54G [00:04<00:16, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  23%|██▎       | 1.04G/4.54G [00:04<00:15, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  24%|██▎       | 1.07G/4.54G [00:05<00:15, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  24%|██▍       | 1.10G/4.54G [00:05<00:15, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  25%|██▍       | 1.13G/4.54G [00:05<00:15, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  26%|██▌       | 1.16G/4.54G [00:05<00:15, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  26%|██▋       | 1.20G/4.54G [00:05<00:15, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  27%|██▋       | 1.23G/4.54G [00:05<00:15, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  28%|██▊       | 1.26G/4.54G [00:05<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  28%|██▊       | 1.29G/4.54G [00:06<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  29%|██▉       | 1.32G/4.54G [00:06<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  30%|██▉       | 1.35G/4.54G [00:06<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  30%|███       | 1.38G/4.54G [00:06<00:14, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  31%|███       | 1.42G/4.54G [00:06<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  32%|███▏      | 1.45G/4.54G [00:06<00:14, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  33%|███▎      | 1.48G/4.54G [00:06<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  33%|███▎      | 1.51G/4.54G [00:07<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  34%|███▍      | 1.54G/4.54G [00:07<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  35%|███▍      | 1.57G/4.54G [00:07<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  35%|███▌      | 1.60G/4.54G [00:07<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  36%|███▌      | 1.64G/4.54G [00:07<00:13, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  37%|███▋      | 1.67G/4.54G [00:07<00:13, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  37%|███▋      | 1.70G/4.54G [00:07<00:12, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  38%|███▊      | 1.73G/4.54G [00:08<00:12, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  39%|███▉      | 1.76G/4.54G [00:08<00:12, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  39%|███▉      | 1.79G/4.54G [00:08<00:12, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  40%|████      | 1.82G/4.54G [00:08<00:12, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  41%|████      | 1.86G/4.54G [00:08<00:12, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  42%|████▏     | 1.89G/4.54G [00:08<00:12, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  42%|████▏     | 1.92G/4.54G [00:08<00:11, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  43%|████▎     | 1.95G/4.54G [00:09<00:11, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▎     | 1.98G/4.54G [00:09<00:11, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  44%|████▍     | 2.01G/4.54G [00:09<00:11, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  45%|████▌     | 2.04G/4.54G [00:09<00:11, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▌     | 2.08G/4.54G [00:09<00:11, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  46%|████▋     | 2.11G/4.54G [00:09<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  47%|████▋     | 2.14G/4.54G [00:09<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.17G/4.54G [00:10<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  48%|████▊     | 2.20G/4.54G [00:10<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  49%|████▉     | 2.23G/4.54G [00:10<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  50%|████▉     | 2.26G/4.54G [00:10<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████     | 2.30G/4.54G [00:10<00:10, 222MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  51%|█████▏    | 2.33G/4.54G [00:10<00:10, 221MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  52%|█████▏    | 2.36G/4.54G [00:10<00:09, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.39G/4.54G [00:11<00:09, 219MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  53%|█████▎    | 2.42G/4.54G [00:11<00:09, 220MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  54%|█████▍    | 2.45G/4.54G [00:11<00:09, 218MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▍    | 2.49G/4.54G [00:11<00:09, 217MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  55%|█████▌    | 2.52G/4.54G [00:11<00:09, 216MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  56%|█████▌    | 2.55G/4.54G [00:11<00:09, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  57%|█████▋    | 2.58G/4.54G [00:11<00:09, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.61G/4.54G [00:12<00:08, 215MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  58%|█████▊    | 2.64G/4.54G [00:12<00:08, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  59%|█████▉    | 2.67G/4.54G [00:12<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|█████▉    | 2.71G/4.54G [00:12<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  60%|██████    | 2.74G/4.54G [00:12<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  61%|██████    | 2.77G/4.54G [00:12<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  62%|██████▏   | 2.80G/4.54G [00:13<00:08, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  62%|██████▏   | 2.83G/4.54G [00:13<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  63%|██████▎   | 2.86G/4.54G [00:13<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  64%|██████▎   | 2.89G/4.54G [00:13<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  64%|██████▍   | 2.93G/4.54G [00:13<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  65%|██████▌   | 2.96G/4.54G [00:13<00:07, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  66%|██████▌   | 2.99G/4.54G [00:13<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  67%|██████▋   | 3.02G/4.54G [00:14<00:07, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  67%|██████▋   | 3.05G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  68%|██████▊   | 3.08G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  69%|██████▊   | 3.11G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  69%|██████▉   | 3.15G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  70%|██████▉   | 3.18G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  71%|███████   | 3.21G/4.54G [00:14<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  71%|███████▏  | 3.24G/4.54G [00:15<00:06, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  72%|███████▏  | 3.27G/4.54G [00:15<00:05, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  73%|███████▎  | 3.30G/4.54G [00:15<00:05, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  73%|███████▎  | 3.33G/4.54G [00:15<00:05, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  74%|███████▍  | 3.37G/4.54G [00:15<00:05, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  75%|███████▍  | 3.40G/4.54G [00:15<00:05, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  76%|███████▌  | 3.43G/4.54G [00:15<00:05, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  76%|███████▌  | 3.46G/4.54G [00:16<00:05, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  77%|███████▋  | 3.49G/4.54G [00:16<00:04, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  78%|███████▊  | 3.52G/4.54G [00:16<00:04, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  78%|███████▊  | 3.55G/4.54G [00:16<00:04, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  79%|███████▉  | 3.59G/4.54G [00:16<00:04, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  80%|███████▉  | 3.62G/4.54G [00:16<00:04, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  80%|████████  | 3.65G/4.54G [00:16<00:04, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  81%|████████  | 3.68G/4.54G [00:17<00:04, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  82%|████████▏ | 3.71G/4.54G [00:17<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  82%|████████▏ | 3.74G/4.54G [00:17<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  83%|████████▎ | 3.77G/4.54G [00:17<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  84%|████████▍ | 3.81G/4.54G [00:17<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  85%|████████▍ | 3.84G/4.54G [00:17<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  85%|████████▌ | 3.87G/4.54G [00:18<00:03, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  86%|████████▌ | 3.90G/4.54G [00:18<00:03, 213MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  87%|████████▋ | 3.93G/4.54G [00:18<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  87%|████████▋ | 3.96G/4.54G [00:18<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  88%|████████▊ | 4.00G/4.54G [00:18<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  89%|████████▊ | 4.03G/4.54G [00:18<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  89%|████████▉ | 4.06G/4.54G [00:18<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  90%|█████████ | 4.09G/4.54G [00:19<00:02, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  91%|█████████ | 4.12G/4.54G [00:19<00:01, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  91%|█████████▏| 4.15G/4.54G [00:19<00:01, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  92%|█████████▏| 4.18G/4.54G [00:19<00:01, 214MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  93%|█████████▎| 4.22G/4.54G [00:19<00:02, 150MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  94%|█████████▎| 4.25G/4.54G [00:19<00:01, 165MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  94%|█████████▍| 4.28G/4.54G [00:20<00:01, 177MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  95%|█████████▍| 4.31G/4.54G [00:20<00:01, 186MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  96%|█████████▌| 4.34G/4.54G [00:20<00:01, 195MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  96%|█████████▋| 4.37G/4.54G [00:20<00:00, 202MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  97%|█████████▋| 4.40G/4.54G [00:20<00:00, 207MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  98%|█████████▊| 4.44G/4.54G [00:20<00:00, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  98%|█████████▊| 4.47G/4.54G [00:21<00:00, 211MB/s]\u001b[A\nDownloading (…)of-00003.safetensors:  99%|█████████▉| 4.50G/4.54G [00:21<00:00, 212MB/s]\u001b[A\nDownloading (…)of-00003.safetensors: 100%|██████████| 4.54G/4.54G [00:21<00:00, 213MB/s]\u001b[A\nDownloading shards: 100%|██████████| 3/3 [01:09<00:00, 23.23s/it]\nLoading checkpoint shards: 100%|██████████| 3/3 [00:00<00:00,  3.47it/s]\nDownloading generation_config.json: 100%|██████████| 179/179 [00:00<00:00, 884kB/s]\n/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.__class__","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:25.243985Z","iopub.execute_input":"2024-01-18T11:09:25.244237Z","iopub.status.idle":"2024-01-18T11:09:25.248945Z","shell.execute_reply.started":"2024-01-18T11:09:25.244210Z","shell.execute_reply":"2024-01-18T11:09:25.248396Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"transformers.models.mistral.configuration_mistral.MistralConfig"},"metadata":{}}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:25.249744Z","iopub.execute_input":"2024-01-18T11:09:25.249992Z","iopub.status.idle":"2024-01-18T11:09:30.917706Z","shell.execute_reply.started":"2024-01-18T11:09:25.249965Z","shell.execute_reply":"2024-01-18T11:09:30.917032Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"MistralForCausalLM(\n  (model): MistralModel(\n    (embed_tokens): Embedding(32002, 4096)\n    (layers): ModuleList(\n      (0-31): 32 x MistralDecoderLayer(\n        (self_attn): MistralAttention(\n          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n          (rotary_emb): MistralRotaryEmbedding()\n        )\n        (mlp): MistralMLP(\n          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n          (act_fn): SiLUActivation()\n        )\n        (input_layernorm): MistralRMSNorm()\n        (post_attention_layernorm): MistralRMSNorm()\n      )\n    )\n    (norm): MistralRMSNorm()\n  )\n  (lm_head): Linear(in_features=4096, out_features=32002, bias=False)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"cnt = 0\nfor name, module in model.named_modules():\n    if isinstance(module, (nn.Embedding, nn.Linear)):\n        print(name, module.__class__.__name__)\n#         print(module)\nprint(cnt)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:09:30.918665Z","iopub.execute_input":"2024-01-18T11:09:30.918933Z","iopub.status.idle":"2024-01-18T11:09:31.066345Z","shell.execute_reply.started":"2024-01-18T11:09:30.918905Z","shell.execute_reply":"2024-01-18T11:09:31.065728Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"model.embed_tokens Embedding\nmodel.layers.0.self_attn.q_proj Linear\nmodel.layers.0.self_attn.k_proj Linear\nmodel.layers.0.self_attn.v_proj Linear\nmodel.layers.0.self_attn.o_proj Linear\nmodel.layers.0.mlp.gate_proj Linear\nmodel.layers.0.mlp.up_proj Linear\nmodel.layers.0.mlp.down_proj Linear\nmodel.layers.1.self_attn.q_proj Linear\nmodel.layers.1.self_attn.k_proj Linear\nmodel.layers.1.self_attn.v_proj Linear\nmodel.layers.1.self_attn.o_proj Linear\nmodel.layers.1.mlp.gate_proj Linear\nmodel.layers.1.mlp.up_proj Linear\nmodel.layers.1.mlp.down_proj Linear\nmodel.layers.2.self_attn.q_proj Linear\nmodel.layers.2.self_attn.k_proj Linear\nmodel.layers.2.self_attn.v_proj Linear\nmodel.layers.2.self_attn.o_proj Linear\nmodel.layers.2.mlp.gate_proj Linear\nmodel.layers.2.mlp.up_proj Linear\nmodel.layers.2.mlp.down_proj Linear\nmodel.layers.3.self_attn.q_proj Linear\nmodel.layers.3.self_attn.k_proj Linear\nmodel.layers.3.self_attn.v_proj Linear\nmodel.layers.3.self_attn.o_proj Linear\nmodel.layers.3.mlp.gate_proj Linear\nmodel.layers.3.mlp.up_proj Linear\nmodel.layers.3.mlp.down_proj Linear\nmodel.layers.4.self_attn.q_proj Linear\nmodel.layers.4.self_attn.k_proj Linear\nmodel.layers.4.self_attn.v_proj Linear\nmodel.layers.4.self_attn.o_proj Linear\nmodel.layers.4.mlp.gate_proj Linear\nmodel.layers.4.mlp.up_proj Linear\nmodel.layers.4.mlp.down_proj Linear\nmodel.layers.5.self_attn.q_proj Linear\nmodel.layers.5.self_attn.k_proj Linear\nmodel.layers.5.self_attn.v_proj Linear\nmodel.layers.5.self_attn.o_proj Linear\nmodel.layers.5.mlp.gate_proj Linear\nmodel.layers.5.mlp.up_proj Linear\nmodel.layers.5.mlp.down_proj Linear\nmodel.layers.6.self_attn.q_proj Linear\nmodel.layers.6.self_attn.k_proj Linear\nmodel.layers.6.self_attn.v_proj Linear\nmodel.layers.6.self_attn.o_proj Linear\nmodel.layers.6.mlp.gate_proj Linear\nmodel.layers.6.mlp.up_proj Linear\nmodel.layers.6.mlp.down_proj Linear\nmodel.layers.7.self_attn.q_proj Linear\nmodel.layers.7.self_attn.k_proj Linear\nmodel.layers.7.self_attn.v_proj Linear\nmodel.layers.7.self_attn.o_proj Linear\nmodel.layers.7.mlp.gate_proj Linear\nmodel.layers.7.mlp.up_proj Linear\nmodel.layers.7.mlp.down_proj Linear\nmodel.layers.8.self_attn.q_proj Linear\nmodel.layers.8.self_attn.k_proj Linear\nmodel.layers.8.self_attn.v_proj Linear\nmodel.layers.8.self_attn.o_proj Linear\nmodel.layers.8.mlp.gate_proj Linear\nmodel.layers.8.mlp.up_proj Linear\nmodel.layers.8.mlp.down_proj Linear\nmodel.layers.9.self_attn.q_proj Linear\nmodel.layers.9.self_attn.k_proj Linear\nmodel.layers.9.self_attn.v_proj Linear\nmodel.layers.9.self_attn.o_proj Linear\nmodel.layers.9.mlp.gate_proj Linear\nmodel.layers.9.mlp.up_proj Linear\nmodel.layers.9.mlp.down_proj Linear\nmodel.layers.10.self_attn.q_proj Linear\nmodel.layers.10.self_attn.k_proj Linear\nmodel.layers.10.self_attn.v_proj Linear\nmodel.layers.10.self_attn.o_proj Linear\nmodel.layers.10.mlp.gate_proj Linear\nmodel.layers.10.mlp.up_proj Linear\nmodel.layers.10.mlp.down_proj Linear\nmodel.layers.11.self_attn.q_proj Linear\nmodel.layers.11.self_attn.k_proj Linear\nmodel.layers.11.self_attn.v_proj Linear\nmodel.layers.11.self_attn.o_proj Linear\nmodel.layers.11.mlp.gate_proj Linear\nmodel.layers.11.mlp.up_proj Linear\nmodel.layers.11.mlp.down_proj Linear\nmodel.layers.12.self_attn.q_proj Linear\nmodel.layers.12.self_attn.k_proj Linear\nmodel.layers.12.self_attn.v_proj Linear\nmodel.layers.12.self_attn.o_proj Linear\nmodel.layers.12.mlp.gate_proj Linear\nmodel.layers.12.mlp.up_proj Linear\nmodel.layers.12.mlp.down_proj Linear\nmodel.layers.13.self_attn.q_proj Linear\nmodel.layers.13.self_attn.k_proj Linear\nmodel.layers.13.self_attn.v_proj Linear\nmodel.layers.13.self_attn.o_proj Linear\nmodel.layers.13.mlp.gate_proj Linear\nmodel.layers.13.mlp.up_proj Linear\nmodel.layers.13.mlp.down_proj Linear\nmodel.layers.14.self_attn.q_proj Linear\nmodel.layers.14.self_attn.k_proj Linear\nmodel.layers.14.self_attn.v_proj Linear\nmodel.layers.14.self_attn.o_proj Linear\nmodel.layers.14.mlp.gate_proj Linear\nmodel.layers.14.mlp.up_proj Linear\nmodel.layers.14.mlp.down_proj Linear\nmodel.layers.15.self_attn.q_proj Linear\nmodel.layers.15.self_attn.k_proj Linear\nmodel.layers.15.self_attn.v_proj Linear\nmodel.layers.15.self_attn.o_proj Linear\nmodel.layers.15.mlp.gate_proj Linear\nmodel.layers.15.mlp.up_proj Linear\nmodel.layers.15.mlp.down_proj Linear\nmodel.layers.16.self_attn.q_proj Linear\nmodel.layers.16.self_attn.k_proj Linear\nmodel.layers.16.self_attn.v_proj Linear\nmodel.layers.16.self_attn.o_proj Linear\nmodel.layers.16.mlp.gate_proj Linear\nmodel.layers.16.mlp.up_proj Linear\nmodel.layers.16.mlp.down_proj Linear\nmodel.layers.17.self_attn.q_proj Linear\nmodel.layers.17.self_attn.k_proj Linear\nmodel.layers.17.self_attn.v_proj Linear\nmodel.layers.17.self_attn.o_proj Linear\nmodel.layers.17.mlp.gate_proj Linear\nmodel.layers.17.mlp.up_proj Linear\nmodel.layers.17.mlp.down_proj Linear\nmodel.layers.18.self_attn.q_proj Linear\nmodel.layers.18.self_attn.k_proj Linear\nmodel.layers.18.self_attn.v_proj Linear\nmodel.layers.18.self_attn.o_proj Linear\nmodel.layers.18.mlp.gate_proj Linear\nmodel.layers.18.mlp.up_proj Linear\nmodel.layers.18.mlp.down_proj Linear\nmodel.layers.19.self_attn.q_proj Linear\nmodel.layers.19.self_attn.k_proj Linear\nmodel.layers.19.self_attn.v_proj Linear\nmodel.layers.19.self_attn.o_proj Linear\nmodel.layers.19.mlp.gate_proj Linear\nmodel.layers.19.mlp.up_proj Linear\nmodel.layers.19.mlp.down_proj Linear\nmodel.layers.20.self_attn.q_proj Linear\nmodel.layers.20.self_attn.k_proj Linear\nmodel.layers.20.self_attn.v_proj Linear\nmodel.layers.20.self_attn.o_proj Linear\nmodel.layers.20.mlp.gate_proj Linear\nmodel.layers.20.mlp.up_proj Linear\nmodel.layers.20.mlp.down_proj Linear\nmodel.layers.21.self_attn.q_proj Linear\nmodel.layers.21.self_attn.k_proj Linear\nmodel.layers.21.self_attn.v_proj Linear\nmodel.layers.21.self_attn.o_proj Linear\nmodel.layers.21.mlp.gate_proj Linear\nmodel.layers.21.mlp.up_proj Linear\nmodel.layers.21.mlp.down_proj Linear\nmodel.layers.22.self_attn.q_proj Linear\nmodel.layers.22.self_attn.k_proj Linear\nmodel.layers.22.self_attn.v_proj Linear\nmodel.layers.22.self_attn.o_proj Linear\nmodel.layers.22.mlp.gate_proj Linear\nmodel.layers.22.mlp.up_proj Linear\nmodel.layers.22.mlp.down_proj Linear\nmodel.layers.23.self_attn.q_proj Linear\nmodel.layers.23.self_attn.k_proj Linear\nmodel.layers.23.self_attn.v_proj Linear\nmodel.layers.23.self_attn.o_proj Linear\nmodel.layers.23.mlp.gate_proj Linear\nmodel.layers.23.mlp.up_proj Linear\nmodel.layers.23.mlp.down_proj Linear\nmodel.layers.24.self_attn.q_proj Linear\nmodel.layers.24.self_attn.k_proj Linear\nmodel.layers.24.self_attn.v_proj Linear\nmodel.layers.24.self_attn.o_proj Linear\nmodel.layers.24.mlp.gate_proj Linear\nmodel.layers.24.mlp.up_proj Linear\nmodel.layers.24.mlp.down_proj Linear\nmodel.layers.25.self_attn.q_proj Linear\nmodel.layers.25.self_attn.k_proj Linear\nmodel.layers.25.self_attn.v_proj Linear\nmodel.layers.25.self_attn.o_proj Linear\nmodel.layers.25.mlp.gate_proj Linear\nmodel.layers.25.mlp.up_proj Linear\nmodel.layers.25.mlp.down_proj Linear\nmodel.layers.26.self_attn.q_proj Linear\nmodel.layers.26.self_attn.k_proj Linear\nmodel.layers.26.self_attn.v_proj Linear\nmodel.layers.26.self_attn.o_proj Linear\nmodel.layers.26.mlp.gate_proj Linear\nmodel.layers.26.mlp.up_proj Linear\nmodel.layers.26.mlp.down_proj Linear\nmodel.layers.27.self_attn.q_proj Linear\nmodel.layers.27.self_attn.k_proj Linear\nmodel.layers.27.self_attn.v_proj Linear\nmodel.layers.27.self_attn.o_proj Linear\nmodel.layers.27.mlp.gate_proj Linear\nmodel.layers.27.mlp.up_proj Linear\nmodel.layers.27.mlp.down_proj Linear\nmodel.layers.28.self_attn.q_proj Linear\nmodel.layers.28.self_attn.k_proj Linear\nmodel.layers.28.self_attn.v_proj Linear\nmodel.layers.28.self_attn.o_proj Linear\nmodel.layers.28.mlp.gate_proj Linear\nmodel.layers.28.mlp.up_proj Linear\nmodel.layers.28.mlp.down_proj Linear\nmodel.layers.29.self_attn.q_proj Linear\nmodel.layers.29.self_attn.k_proj Linear\nmodel.layers.29.self_attn.v_proj Linear\nmodel.layers.29.self_attn.o_proj Linear\nmodel.layers.29.mlp.gate_proj Linear\nmodel.layers.29.mlp.up_proj Linear\nmodel.layers.29.mlp.down_proj Linear\nmodel.layers.30.self_attn.q_proj Linear\nmodel.layers.30.self_attn.k_proj Linear\nmodel.layers.30.self_attn.v_proj Linear\nmodel.layers.30.self_attn.o_proj Linear\nmodel.layers.30.mlp.gate_proj Linear\nmodel.layers.30.mlp.up_proj Linear\nmodel.layers.30.mlp.down_proj Linear\nmodel.layers.31.self_attn.q_proj Linear\nmodel.layers.31.self_attn.k_proj Linear\nmodel.layers.31.self_attn.v_proj Linear\nmodel.layers.31.self_attn.o_proj Linear\nmodel.layers.31.mlp.gate_proj Linear\nmodel.layers.31.mlp.up_proj Linear\nmodel.layers.31.mlp.down_proj Linear\nlm_head Linear\n0\n","output_type":"stream"}]},{"cell_type":"code","source":"cnt = 0\nfor param in model.parameters():\n    cnt += 1\nprint(cnt)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:09:31.067246Z","iopub.execute_input":"2024-01-18T11:09:31.067486Z","iopub.status.idle":"2024-01-18T11:09:31.259158Z","shell.execute_reply.started":"2024-01-18T11:09:31.067460Z","shell.execute_reply":"2024-01-18T11:09:31.258502Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"291\n","output_type":"stream"}]},{"cell_type":"code","source":"# for param in model.parameters():\n#     param.requires_grad = True\n\ncnt = 0\nfor param in model.parameters():\n    cnt += 1\n    param.requires_grad = False\n    if cnt > 250:\n        param.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:31.260071Z","iopub.execute_input":"2024-01-18T11:09:31.260399Z","iopub.status.idle":"2024-01-18T11:09:31.414791Z","shell.execute_reply.started":"2024-01-18T11:09:31.260348Z","shell.execute_reply":"2024-01-18T11:09:31.414090Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    base_model,\n    model_max_length=MAX_TOKEN_MODEL,\n    padding_side=\"right\",\n    use_fast=False,\n    trust_remote_code=True\n)\n# tokenizer.pad_token = tokenizer.eos_token","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:31.415746Z","iopub.execute_input":"2024-01-18T11:09:31.416001Z","iopub.status.idle":"2024-01-18T11:09:32.418193Z","shell.execute_reply.started":"2024-01-18T11:09:31.415974Z","shell.execute_reply":"2024-01-18T11:09:32.417468Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"Downloading tokenizer_config.json: 100%|██████████| 1.62k/1.62k [00:00<00:00, 8.95MB/s]\nDownloading tokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 322MB/s]\nDownloading added_tokens.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 280kB/s]\nDownloading (…)cial_tokens_map.json: 100%|██████████| 502/502 [00:00<00:00, 2.47MB/s]\nDownloading tokenizer.json: 100%|██████████| 1.80M/1.80M [00:00<00:00, 23.4MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.special_tokens_map","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:32.419129Z","iopub.execute_input":"2024-01-18T11:09:32.419374Z","iopub.status.idle":"2024-01-18T11:09:32.424346Z","shell.execute_reply.started":"2024-01-18T11:09:32.419347Z","shell.execute_reply":"2024-01-18T11:09:32.423740Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"{'bos_token': '<s>',\n 'eos_token': '<|end_of_turn|>',\n 'unk_token': '<unk>',\n 'additional_special_tokens': ['<|end_of_turn|>', '<|pad_0|>']}"},"metadata":{}}]},{"cell_type":"code","source":"special_tokens_dict = {\n    'additional_special_tokens': [DEFAULT_BOI_TOKEN, DEFAULT_EOI_TOKEN],\n    'pad_token': DEFAULT_PAD_TOKEN,\n    'bos_token': DEFAULT_BOS_TOKEN,\n    'eos_token': DEFAULT_EOS_TOKEN,\n    'unk_token': DEFAULT_UNK_TOKEN,\n}\nnum_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:32.425167Z","iopub.execute_input":"2024-01-18T11:09:32.425407Z","iopub.status.idle":"2024-01-18T11:09:50.081085Z","shell.execute_reply.started":"2024-01-18T11:09:32.425383Z","shell.execute_reply":"2024-01-18T11:09:50.080287Z"},"trusted":true},"execution_count":50,"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"Embedding(32004, 4096)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.special_tokens_map","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:50.082216Z","iopub.execute_input":"2024-01-18T11:09:50.082496Z","iopub.status.idle":"2024-01-18T11:09:50.088476Z","shell.execute_reply.started":"2024-01-18T11:09:50.082467Z","shell.execute_reply":"2024-01-18T11:09:50.087648Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'bos_token': '<s>',\n 'eos_token': '<|end_of_turn|>',\n 'unk_token': '<unk>',\n 'pad_token': '<|pad_0|>',\n 'additional_special_tokens': ['[INST]', '[/INST]']}"},"metadata":{}}]},{"cell_type":"code","source":"print(tokenizer.encode(\"{0} Hello, how are you? \\n{1} I'm fine, thank you!{2}\".format(\n    DEFAULT_BOI_TOKEN,\n    DEFAULT_EOI_TOKEN,\n    DEFAULT_EOS_TOKEN,\n)))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:09:50.089426Z","iopub.execute_input":"2024-01-18T11:09:50.089872Z","iopub.status.idle":"2024-01-18T11:10:03.618763Z","shell.execute_reply.started":"2024-01-18T11:09:50.089842Z","shell.execute_reply":"2024-01-18T11:10:03.618071Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"[1, 32002, 28705, 22557, 28725, 910, 460, 368, 28804, 28705, 13, 32003, 28705, 315, 28742, 28719, 4433, 28725, 6979, 368, 28808, 32000]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Check model","metadata":{}},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:10:03.619733Z","iopub.execute_input":"2024-01-18T11:10:03.619981Z","iopub.status.idle":"2024-01-18T11:10:03.797012Z","shell.execute_reply.started":"2024-01-18T11:10:03.619955Z","shell.execute_reply":"2024-01-18T11:10:03.796344Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"trainable params: 1193357312 || all params: 7241764864 || trainable%: 16.478818829542156\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Check testcase max token","metadata":{}},{"cell_type":"code","source":"def getListLongToken(dataset):\n    max_token_of_dataset = 0\n    listLongToken = []\n    for i in range(len(dataset)):\n        text = dataset[i]\n        token_len = len(tokenizer.encode(text))\n        max_token_of_dataset = max(token_len, max_token_of_dataset)\n        if token_len > MAX_TOKEN_MODEL:\n    #         print(text)\n            print(i, token_len, \"\\n\")\n            listLongToken.append(i)\n    #         print(text)\n#     print(max_token_of_dataset)\n    return listLongToken","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:10:03.797948Z","iopub.execute_input":"2024-01-18T11:10:03.798206Z","iopub.status.idle":"2024-01-18T11:10:04.004707Z","shell.execute_reply.started":"2024-01-18T11:10:03.798179Z","shell.execute_reply":"2024-01-18T11:10:04.003966Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"print(len(getListLongToken(dataset[\"text\"])))\n# print(len(getListLongToken(datasetStruct[\"input\"])))\n# print(len(getListLongToken(datasetStruct[\"output\"])))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:10:04.005690Z","iopub.execute_input":"2024-01-18T11:10:04.005948Z","iopub.status.idle":"2024-01-18T11:11:56.523846Z","shell.execute_reply.started":"2024-01-18T11:10:04.005913Z","shell.execute_reply":"2024-01-18T11:11:56.523092Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"539 1032 \n\n2038 1063 \n\n2039 1055 \n\n2490 1567 \n\n2491 1558 \n\n3053 6192 \n\n3102 1290 \n\n3103 1299 \n\n4222 1170 \n\n4223 1165 \n\n4259 6193 \n\n5040 1131 \n\n5041 1126 \n\n5138 1110 \n\n5139 1099 \n\n5586 1490 \n\n5587 1485 \n\n7030 1109 \n\n7031 1098 \n\n7052 1207 \n\n7053 1214 \n\n10610 1033 \n\n10611 1026 \n\n11044 1363 \n\n11045 1350 \n\n11068 1204 \n\n11069 1201 \n\n13040 1248 \n\n13041 1239 \n\n13074 1129 \n\n13075 1120 \n\n14586 1452 \n\n14587 1444 \n\n14646 1026 \n\n16316 1077 \n\n16317 1089 \n\n18636 1255 \n\n18637 1260 \n\n19960 1185 \n\n19961 1195 \n\n20084 1370 \n\n20085 1377 \n\n21262 1195 \n\n21263 1204 \n\n21732 1053 \n\n21733 1045 \n\n21816 1118 \n\n21817 1122 \n\n22080 1370 \n\n22081 1361 \n\n22632 1937 \n\n22633 1945 \n\n22968 1152 \n\n22969 1144 \n\n24618 2327 \n\n24619 2323 \n\n25282 1133 \n\n25283 1128 \n\n28816 1211 \n\n28817 1208 \n\n29062 1108 \n\n29063 1113 \n\n32450 1041 \n\n32451 1050 \n\n32472 2295 \n\n32473 2286 \n\n33802 2265 \n\n33803 2256 \n\n34622 4204 \n\n34623 4193 \n\n35222 1133 \n\n35223 1128 \n\n35426 1102 \n\n35427 1094 \n\n35522 1133 \n\n35523 1128 \n\n35798 2303 \n\n35799 2296 \n\n37648 1030 \n\n38192 1588 \n\n38193 1580 \n\n38968 1082 \n\n38969 1071 \n\n39606 1299 \n\n39607 1305 \n\n40228 1039 \n\n40229 1046 \n\n42176 1104 \n\n42177 1095 \n\n43112 1059 \n\n43113 1072 \n\n43126 1490 \n\n43127 1485 \n\n46906 1251 \n\n46907 1243 \n\n47070 1242 \n\n47071 1234 \n\n47930 1383 \n\n47931 1374 \n\n49794 1360 \n\n49795 1351 \n\n49952 1295 \n\n49953 1284 \n\n50234 1115 \n\n50235 1128 \n\n51372 2060 \n\n51373 2069 \n\n51714 1028 \n\n53406 1486 \n\n53407 1481 \n\n54770 1029 \n\n56036 1488 \n\n56037 1483 \n\n56620 1375 \n\n56621 1364 \n\n56666 1506 \n\n56667 1497 \n\n56954 1056 \n\n56955 1064 \n\n58294 1260 \n\n58295 1249 \n\n60128 1029 \n\n60129 1038 \n\n61774 1932 \n\n61775 1939 \n\n63272 1100 \n\n63273 1096 \n\n65550 1051 \n\n65551 1043 \n\n65636 1222 \n\n65637 1212 \n\n67738 1133 \n\n67739 1122 \n\n68368 1943 \n\n68369 1948 \n\n69516 1040 \n\n69517 1046 \n\n70544 1716 \n\n70545 1710 \n\n71056 1051 \n\n71057 1043 \n\n71926 2130 \n\n71927 2120 \n\n72544 1206 \n\n72545 1199 \n\n73150 1490 \n\n73151 1485 \n\n73232 1251 \n\n73233 1242 \n\n75042 1036 \n\n75043 1028 \n\n76134 1028 \n\n77207 1025 \n\n77520 1169 \n\n77521 1159 \n\n78166 1044 \n\n78167 1035 \n\n79302 1078 \n\n79303 1072 \n\n80864 1111 \n\n80865 1106 \n\n81492 1147 \n\n81493 1139 \n\n81494 1054 \n\n81495 1052 \n\n81786 1046 \n\n81787 1038 \n\n82474 1050 \n\n82475 1058 \n\n82714 1565 \n\n82715 1556 \n\n82994 1133 \n\n82995 1128 \n\n83270 1251 \n\n83271 1242 \n\n83558 1209 \n\n83559 1206 \n\n83728 1300 \n\n83729 1308 \n\n83782 1295 \n\n83783 1303 \n\n84198 1025 \n\n85244 1273 \n\n85245 1283 \n\n86172 1119 \n\n86173 1125 \n\n86395 1032 \n\n87036 1305 \n\n87037 1294 \n\n90558 1448 \n\n90559 1441 \n\n90674 1240 \n\n90675 1244 \n\n90825 1028 \n\n91704 2296 \n\n91705 2287 \n\n93120 1450 \n\n93121 1442 \n\n93270 1275 \n\n93271 1267 \n\n96642 1199 \n\n96643 1208 \n\n97090 1931 \n\n97091 1939 \n\n97436 1055 \n\n97437 1061 \n\n97984 1239 \n\n97985 1230 \n\n98826 1251 \n\n98827 1242 \n\n99416 1039 \n\n99417 1045 \n\n99732 1138 \n\n99733 1134 \n\n100073 1029 \n\n100110 2131 \n\n100111 2118 \n\n100796 1144 \n\n100797 1136 \n\n101270 2139 \n\n101271 2148 \n\n103066 1207 \n\n103067 1200 \n\n223\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Remove long token testcase","metadata":{}},{"cell_type":"code","source":"def removeLongToken(dataset, listLongToken):\n    newDataset = [dataset[i] for i in range(len(dataset)) if i not in listLongToken]\n    return newDataset","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:11:56.524845Z","iopub.execute_input":"2024-01-18T11:11:56.525104Z","iopub.status.idle":"2024-01-18T11:11:56.529151Z","shell.execute_reply.started":"2024-01-18T11:11:56.525076Z","shell.execute_reply":"2024-01-18T11:11:56.528575Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"listLongToken = getListLongToken(dataset[\"text\"])\n# listLongToken = getListLongToken(datasetStruct[\"input\"]) + getListLongToken(datasetStruct[\"output\"])","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:11:56.529955Z","iopub.execute_input":"2024-01-18T11:11:56.530180Z","iopub.status.idle":"2024-01-18T11:13:49.586215Z","shell.execute_reply.started":"2024-01-18T11:11:56.530157Z","shell.execute_reply":"2024-01-18T11:13:49.585548Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"539 1032 \n\n2038 1063 \n\n2039 1055 \n\n2490 1567 \n\n2491 1558 \n\n3053 6192 \n\n3102 1290 \n\n3103 1299 \n\n4222 1170 \n\n4223 1165 \n\n4259 6193 \n\n5040 1131 \n\n5041 1126 \n\n5138 1110 \n\n5139 1099 \n\n5586 1490 \n\n5587 1485 \n\n7030 1109 \n\n7031 1098 \n\n7052 1207 \n\n7053 1214 \n\n10610 1033 \n\n10611 1026 \n\n11044 1363 \n\n11045 1350 \n\n11068 1204 \n\n11069 1201 \n\n13040 1248 \n\n13041 1239 \n\n13074 1129 \n\n13075 1120 \n\n14586 1452 \n\n14587 1444 \n\n14646 1026 \n\n16316 1077 \n\n16317 1089 \n\n18636 1255 \n\n18637 1260 \n\n19960 1185 \n\n19961 1195 \n\n20084 1370 \n\n20085 1377 \n\n21262 1195 \n\n21263 1204 \n\n21732 1053 \n\n21733 1045 \n\n21816 1118 \n\n21817 1122 \n\n22080 1370 \n\n22081 1361 \n\n22632 1937 \n\n22633 1945 \n\n22968 1152 \n\n22969 1144 \n\n24618 2327 \n\n24619 2323 \n\n25282 1133 \n\n25283 1128 \n\n28816 1211 \n\n28817 1208 \n\n29062 1108 \n\n29063 1113 \n\n32450 1041 \n\n32451 1050 \n\n32472 2295 \n\n32473 2286 \n\n33802 2265 \n\n33803 2256 \n\n34622 4204 \n\n34623 4193 \n\n35222 1133 \n\n35223 1128 \n\n35426 1102 \n\n35427 1094 \n\n35522 1133 \n\n35523 1128 \n\n35798 2303 \n\n35799 2296 \n\n37648 1030 \n\n38192 1588 \n\n38193 1580 \n\n38968 1082 \n\n38969 1071 \n\n39606 1299 \n\n39607 1305 \n\n40228 1039 \n\n40229 1046 \n\n42176 1104 \n\n42177 1095 \n\n43112 1059 \n\n43113 1072 \n\n43126 1490 \n\n43127 1485 \n\n46906 1251 \n\n46907 1243 \n\n47070 1242 \n\n47071 1234 \n\n47930 1383 \n\n47931 1374 \n\n49794 1360 \n\n49795 1351 \n\n49952 1295 \n\n49953 1284 \n\n50234 1115 \n\n50235 1128 \n\n51372 2060 \n\n51373 2069 \n\n51714 1028 \n\n53406 1486 \n\n53407 1481 \n\n54770 1029 \n\n56036 1488 \n\n56037 1483 \n\n56620 1375 \n\n56621 1364 \n\n56666 1506 \n\n56667 1497 \n\n56954 1056 \n\n56955 1064 \n\n58294 1260 \n\n58295 1249 \n\n60128 1029 \n\n60129 1038 \n\n61774 1932 \n\n61775 1939 \n\n63272 1100 \n\n63273 1096 \n\n65550 1051 \n\n65551 1043 \n\n65636 1222 \n\n65637 1212 \n\n67738 1133 \n\n67739 1122 \n\n68368 1943 \n\n68369 1948 \n\n69516 1040 \n\n69517 1046 \n\n70544 1716 \n\n70545 1710 \n\n71056 1051 \n\n71057 1043 \n\n71926 2130 \n\n71927 2120 \n\n72544 1206 \n\n72545 1199 \n\n73150 1490 \n\n73151 1485 \n\n73232 1251 \n\n73233 1242 \n\n75042 1036 \n\n75043 1028 \n\n76134 1028 \n\n77207 1025 \n\n77520 1169 \n\n77521 1159 \n\n78166 1044 \n\n78167 1035 \n\n79302 1078 \n\n79303 1072 \n\n80864 1111 \n\n80865 1106 \n\n81492 1147 \n\n81493 1139 \n\n81494 1054 \n\n81495 1052 \n\n81786 1046 \n\n81787 1038 \n\n82474 1050 \n\n82475 1058 \n\n82714 1565 \n\n82715 1556 \n\n82994 1133 \n\n82995 1128 \n\n83270 1251 \n\n83271 1242 \n\n83558 1209 \n\n83559 1206 \n\n83728 1300 \n\n83729 1308 \n\n83782 1295 \n\n83783 1303 \n\n84198 1025 \n\n85244 1273 \n\n85245 1283 \n\n86172 1119 \n\n86173 1125 \n\n86395 1032 \n\n87036 1305 \n\n87037 1294 \n\n90558 1448 \n\n90559 1441 \n\n90674 1240 \n\n90675 1244 \n\n90825 1028 \n\n91704 2296 \n\n91705 2287 \n\n93120 1450 \n\n93121 1442 \n\n93270 1275 \n\n93271 1267 \n\n96642 1199 \n\n96643 1208 \n\n97090 1931 \n\n97091 1939 \n\n97436 1055 \n\n97437 1061 \n\n97984 1239 \n\n97985 1230 \n\n98826 1251 \n\n98827 1242 \n\n99416 1039 \n\n99417 1045 \n\n99732 1138 \n\n99733 1134 \n\n100073 1029 \n\n100110 2131 \n\n100111 2118 \n\n100796 1144 \n\n100797 1136 \n\n101270 2139 \n\n101271 2148 \n\n103066 1207 \n\n103067 1200 \n\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset[\"text\"] = removeLongToken(dataset[\"text\"], listLongToken)\n# datasetStruct[\"input\"] = removeLongToken(datasetStruct[\"input\"], listLongToken)\n# datasetStruct[\"output\"] = removeLongToken(datasetStruct[\"output\"], listLongToken)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:13:49.587112Z","iopub.execute_input":"2024-01-18T11:13:49.587349Z","iopub.status.idle":"2024-01-18T11:13:49.875737Z","shell.execute_reply.started":"2024-01-18T11:13:49.587323Z","shell.execute_reply":"2024-01-18T11:13:49.875036Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"len(getListLongToken(dataset[\"text\"]))\n# len(getListLongToken(datasetStruct[\"input\"]))\n# len(getListLongToken(datasetStruct[\"output\"]))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:13:49.876572Z","iopub.execute_input":"2024-01-18T11:13:49.876811Z","iopub.status.idle":"2024-01-18T11:15:42.391662Z","shell.execute_reply.started":"2024-01-18T11:13:49.876785Z","shell.execute_reply":"2024-01-18T11:15:42.390916Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}]},{"cell_type":"markdown","source":"### Nice stuct dataset","metadata":{}},{"cell_type":"code","source":"dataset = Dataset.from_dict(dataset)\n# dataset = Dataset.from_dict(datasetStruct)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:15:42.392663Z","iopub.execute_input":"2024-01-18T11:15:42.392936Z","iopub.status.idle":"2024-01-18T11:15:43.011942Z","shell.execute_reply.started":"2024-01-18T11:15:42.392906Z","shell.execute_reply":"2024-01-18T11:15:43.011171Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"def preprocess_dataset_function(example):\n    text_tokens = tokenizer(example[\"text\"], truncation=True, max_length=MAX_TOKEN_MODEL, padding='max_length').input_ids\n    return {\n        \"input_ids\": text_tokens,\n    }\n#     input_tokens = tokenizer(example[\"input\"], truncation=True, max_length=MAX_TOKEN_MODEL, padding='max_length').input_ids\n#     output_tokens = tokenizer(example[\"output\"], truncation=True, max_length=MAX_TOKEN_MODEL, padding='max_length').input_ids\n#     return {\n#         \"input_ids\": input_tokens,\n#         \"labels\": output_tokens,\n#     }\n\ndataset = dataset.map(preprocess_dataset_function, batched=False, remove_columns=['text'], num_proc=96)\n# dataset = dataset.map(preprocess_dataset_function, batched=False, remove_columns=['input', 'output'], num_proc=96)\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:15:43.018079Z","iopub.execute_input":"2024-01-18T11:15:43.018369Z","iopub.status.idle":"2024-01-18T11:16:29.356972Z","shell.execute_reply.started":"2024-01-18T11:15:43.018332Z","shell.execute_reply":"2024-01-18T11:16:29.355927Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stderr","text":"Map (num_proc=96): 100%|██████████| 103159/103159 [00:43<00:00, 2392.95 examples/s]\n/usr/local/lib/python3.10/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by mode='default'.\n  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n/usr/local/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n  table = cls._concat_blocks(blocks, axis=0)\n","output_type":"stream"},{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['input_ids'],\n    num_rows: 103159\n})"},"metadata":{}}]},{"cell_type":"markdown","source":"### DataCollator","metadata":{}},{"cell_type":"code","source":"from trl import DataCollatorForCompletionOnlyLM","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.358442Z","iopub.execute_input":"2024-01-18T11:16:29.358741Z","iopub.status.idle":"2024-01-18T11:16:29.362865Z","shell.execute_reply.started":"2024-01-18T11:16:29.358707Z","shell.execute_reply":"2024-01-18T11:16:29.362266Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"# instruction_template = DEFAULT_BOI_TOKEN\nresponse_template = DEFAULT_EOI_TOKEN\n# instruction_template=instruction_template, \ncollator = DataCollatorForCompletionOnlyLM(\n#     instruction_template=instruction_template,\nresponse_template=response_template, tokenizer=tokenizer, mlm=False)\n# collator = DataCollatorForSupervisedDataset(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.363859Z","iopub.execute_input":"2024-01-18T11:16:29.364149Z","iopub.status.idle":"2024-01-18T11:16:29.377483Z","shell.execute_reply.started":"2024-01-18T11:16:29.364103Z","shell.execute_reply":"2024-01-18T11:16:29.376664Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### XLA Trick","metadata":{}},{"cell_type":"code","source":"training_loader = torch.utils.data.DataLoader(dataset, batch_size=FLAGS['BATCH_SIZE'], collate_fn=collator)\ndevice = xm.xla_device()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.378495Z","iopub.execute_input":"2024-01-18T11:16:29.378752Z","iopub.status.idle":"2024-01-18T11:16:29.387877Z","shell.execute_reply.started":"2024-01-18T11:16:29.378726Z","shell.execute_reply":"2024-01-18T11:16:29.387216Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"for step, batch in enumerate(training_loader):\n#     print(tokenizer.decode(batch.input_ids[0]))\n#     print(tokenizer.decode(batch.attention_mask[0]))\n    print(tokenizer.decode([i for i in batch.labels[0] if i >= 0]))\n    break","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.388837Z","iopub.execute_input":"2024-01-18T11:16:29.389094Z","iopub.status.idle":"2024-01-18T11:16:29.421506Z","shell.execute_reply.started":"2024-01-18T11:16:29.389067Z","shell.execute_reply":"2024-01-18T11:16:29.420801Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":" Math Correct Assistant:\n## Explanation:\n\"Nước = w (lít) Sữa = m (lít) = = > Chi phí = giá x số lượng = 0,33 m = = > Doanh thu = giá x số lượng = 0,36 (m + w) = = > Lợi nhuận = 0,36 (m + w) - 0,33 m = 0,3 * (0,33 m) [30% chi phí] = = > 0,36 m + 0,36 w - 0,33 m = 0,099 m = = > 0,069 m = 0,36 w = = > m / w = 0,36 / 0,069 = 120 / 23 - - hoặc - - w / m = 23 / 120 b là đúng.\"\n\n## Expression:\n(1 / (30 / 2))<|end_of_turn|>\n","output_type":"stream"}]},{"cell_type":"code","source":"model.config.__class__","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.422623Z","iopub.execute_input":"2024-01-18T11:16:29.422903Z","iopub.status.idle":"2024-01-18T11:16:29.427628Z","shell.execute_reply.started":"2024-01-18T11:16:29.422875Z","shell.execute_reply":"2024-01-18T11:16:29.426993Z"},"trusted":true},"execution_count":66,"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"transformers.models.mistral.configuration_mistral.MistralConfig"},"metadata":{}}]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(base_model)\nnum_devices = xr.global_runtime_device_count()\nmesh_shape = (1, num_devices, 1)\ndevice_ids = np.array(range(num_devices))\nmesh = Mesh(device_ids, mesh_shape, ('dp', 'fsdp', 'mp'))\npartition_module(model, mesh) # After this, the model is sharded between cores but still has the same API as if it was on single device. Neat.","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:29.428471Z","iopub.execute_input":"2024-01-18T11:16:29.428715Z","iopub.status.idle":"2024-01-18T11:16:48.873946Z","shell.execute_reply.started":"2024-01-18T11:16:29.428679Z","shell.execute_reply":"2024-01-18T11:16:48.872904Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"!export XLA_USE_BF16=1 #I'm not even sure that exporting does anything\ndef train(FLAGS):\n    num_iterations = int(FLAGS['NUM_STEPS'] / FLAGS['BATCH_SIZE'])\n    lr = 1e-5\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=1.0, end_factor=0.1, total_iters=FLAGS['NUM_STEPS'] * FLAGS['BATCH_SIZE']) #You would probably wanna use cosine scheduler or something it's really easy to change\n    for epoch in range(1, FLAGS['NUM_EPOCHS'] + 1):\n        model.train()\n        xm.master_print('Epoch {} train begin {}'.format(epoch, test_utils.now())) # master print is meant to be used inside xmp function to not have it printed 8 times but whatever\n        for step, batch in enumerate(training_loader):\n            optimizer.zero_grad()\n            input_ids, attention_mask, labels = batch.input_ids.to(device), batch.attention_mask.to(device), batch.labels.to(device)\n            xs.mark_sharding(input_ids, mesh, (0, 1))\n            xs.mark_sharding(attention_mask, mesh, (0, 1))\n            xs.mark_sharding(labels, mesh, (0, 1))\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n            loss = outputs.loss\n            loss.backward()\n            optimizer.step()\n            xm.mark_step()\n            if (step + 1) % FLAGS['LOGGING_STEPS'] == 0:\n                print(f'loss: {loss.item()}, time: {test_utils.now()}, step: {step}')\n            scheduler.step()\n        xm.master_print('Epoch {} train end {}'.format(epoch, test_utils.now()))","metadata":{"execution":{"iopub.status.busy":"2024-01-18T11:16:48.875069Z","iopub.execute_input":"2024-01-18T11:16:48.875320Z","iopub.status.idle":"2024-01-18T11:16:49.585761Z","shell.execute_reply.started":"2024-01-18T11:16:48.875293Z","shell.execute_reply":"2024-01-18T11:16:49.584683Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"markdown","source":"### Train","metadata":{}},{"cell_type":"code","source":"train(FLAGS) # \"unlimited power\" palpatine meme","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T11:16:49.587188Z","iopub.execute_input":"2024-01-18T11:16:49.587500Z","iopub.status.idle":"2024-01-18T19:45:20.336956Z","shell.execute_reply.started":"2024-01-18T11:16:49.587466Z","shell.execute_reply":"2024-01-18T19:45:20.336102Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Epoch 1 train begin 11:16:49\nloss: 0.8215476274490356, time: 11:20:42, step: 99\nloss: 0.6719945669174194, time: 11:22:40, step: 199\nloss: 0.4720698893070221, time: 11:24:38, step: 299\nloss: 0.7125930190086365, time: 11:26:35, step: 399\nloss: 0.47873908281326294, time: 11:28:33, step: 499\nloss: 0.5422418117523193, time: 11:30:30, step: 599\nloss: 0.45155537128448486, time: 11:32:28, step: 699\nloss: 0.5657427906990051, time: 11:34:26, step: 799\nloss: 0.35086870193481445, time: 11:36:23, step: 899\nloss: 0.5675763487815857, time: 11:38:21, step: 999\nloss: 0.6290928721427917, time: 11:40:18, step: 1099\nloss: 0.46858730912208557, time: 11:42:16, step: 1199\nloss: 0.45859193801879883, time: 11:44:13, step: 1299\nloss: 0.6865434050559998, time: 11:46:11, step: 1399\nloss: 0.5152707099914551, time: 11:48:09, step: 1499\nloss: 0.4518758952617645, time: 11:50:06, step: 1599\nloss: 0.41706112027168274, time: 11:52:04, step: 1699\nloss: 0.546725869178772, time: 11:54:02, step: 1799\nloss: 0.4024645984172821, time: 11:55:59, step: 1899\nloss: 0.530915379524231, time: 11:57:57, step: 1999\nloss: 0.4550619125366211, time: 11:59:54, step: 2099\nloss: 0.21236532926559448, time: 12:01:52, step: 2199\nloss: 0.45109400153160095, time: 12:03:50, step: 2299\nloss: 0.3322356343269348, time: 12:05:47, step: 2399\nloss: 0.3463400602340698, time: 12:07:45, step: 2499\nloss: 0.3029622733592987, time: 12:09:42, step: 2599\nloss: 0.5248231291770935, time: 12:11:40, step: 2699\nloss: 0.5711607336997986, time: 12:13:37, step: 2799\nloss: 0.349738746881485, time: 12:15:35, step: 2899\nloss: 0.3135277032852173, time: 12:17:33, step: 2999\nloss: 0.32102036476135254, time: 12:19:30, step: 3099\nloss: 0.2839212417602539, time: 12:21:28, step: 3199\nloss: 0.4559171497821808, time: 12:23:26, step: 3299\nloss: 0.3649866580963135, time: 12:25:23, step: 3399\nloss: 0.20585881173610687, time: 12:27:21, step: 3499\nloss: 0.5060036182403564, time: 12:29:18, step: 3599\nloss: 0.2600036561489105, time: 12:31:16, step: 3699\nloss: 0.35719263553619385, time: 12:33:13, step: 3799\nloss: 0.5973914861679077, time: 12:35:11, step: 3899\nloss: 0.2738836705684662, time: 12:37:09, step: 3999\nloss: 0.5569530129432678, time: 12:39:06, step: 4099\nloss: 0.2294703871011734, time: 12:41:04, step: 4199\nloss: 0.37905627489089966, time: 12:43:02, step: 4299\nloss: 0.35108330845832825, time: 12:44:59, step: 4399\nloss: 0.16718600690364838, time: 12:46:57, step: 4499\nloss: 0.6063052415847778, time: 12:48:54, step: 4599\nloss: 0.2826618254184723, time: 12:50:52, step: 4699\nloss: 0.22275187075138092, time: 12:52:50, step: 4799\nloss: 0.3009066581726074, time: 12:54:47, step: 4899\nloss: 0.32845067977905273, time: 12:56:45, step: 4999\nloss: 0.33933085203170776, time: 12:58:42, step: 5099\nloss: 0.39136746525764465, time: 13:00:40, step: 5199\nloss: 0.26327890157699585, time: 13:02:38, step: 5299\nloss: 0.4481898248195648, time: 13:04:35, step: 5399\nloss: 0.1563180685043335, time: 13:06:33, step: 5499\nloss: 0.46763351559638977, time: 13:09:20, step: 5599\nloss: 0.1929149329662323, time: 13:11:17, step: 5699\nloss: 0.3839613199234009, time: 13:13:15, step: 5799\nloss: 0.21723663806915283, time: 13:15:12, step: 5899\nloss: 0.3712691068649292, time: 13:17:10, step: 5999\nloss: 0.2993241548538208, time: 13:19:07, step: 6099\nloss: 0.33766597509384155, time: 13:21:05, step: 6199\nloss: 0.30213841795921326, time: 13:23:02, step: 6299\nloss: 0.07901155948638916, time: 13:24:59, step: 6399\nloss: 0.3500443696975708, time: 13:26:57, step: 6499\nloss: 0.22842971980571747, time: 13:28:54, step: 6599\nloss: 0.1282002180814743, time: 13:30:52, step: 6699\nloss: 0.24780039489269257, time: 13:32:49, step: 6799\nloss: 0.19386881589889526, time: 13:34:47, step: 6899\nloss: 0.18963411450386047, time: 13:36:44, step: 6999\nloss: 0.3340315818786621, time: 13:38:41, step: 7099\nloss: 0.22426219284534454, time: 13:40:39, step: 7199\nloss: 0.1284455806016922, time: 13:42:36, step: 7299\nloss: 0.2992634177207947, time: 13:44:34, step: 7399\nloss: 0.3681492805480957, time: 13:46:31, step: 7499\nloss: 0.5319358110427856, time: 13:48:29, step: 7599\nloss: 0.2658040523529053, time: 13:50:26, step: 7699\nloss: 0.36848264932632446, time: 13:52:23, step: 7799\nloss: 0.33982643485069275, time: 13:54:21, step: 7899\nloss: 0.6011552214622498, time: 13:56:18, step: 7999\nloss: 0.33015188574790955, time: 13:58:16, step: 8099\nloss: 0.3137460947036743, time: 14:00:13, step: 8199\nloss: 0.21952348947525024, time: 14:02:11, step: 8299\nloss: 0.2954835295677185, time: 14:04:08, step: 8399\nloss: 0.21469616889953613, time: 14:06:06, step: 8499\nloss: 0.18936307728290558, time: 14:08:03, step: 8599\nloss: 0.40232428908348083, time: 14:10:00, step: 8699\nloss: 0.15524721145629883, time: 14:11:58, step: 8799\nloss: 0.15911927819252014, time: 14:13:55, step: 8899\nloss: 0.1541992425918579, time: 14:15:53, step: 8999\nloss: 0.21239863336086273, time: 14:17:50, step: 9099\nloss: 0.30603769421577454, time: 14:19:47, step: 9199\nloss: 0.18366841971874237, time: 14:21:45, step: 9299\nloss: 0.48411521315574646, time: 14:23:42, step: 9399\nloss: 0.2276410460472107, time: 14:25:40, step: 9499\nloss: 0.18324656784534454, time: 14:27:37, step: 9599\nloss: 0.18887798488140106, time: 14:29:35, step: 9699\nloss: 0.26693227887153625, time: 14:31:32, step: 9799\nloss: 0.43437260389328003, time: 14:33:29, step: 9899\nloss: 0.08075722306966782, time: 14:35:27, step: 9999\nloss: 0.12382428348064423, time: 14:37:24, step: 10099\nloss: 0.3013050854206085, time: 14:39:22, step: 10199\nloss: 0.16068370640277863, time: 14:41:19, step: 10299\nloss: 0.2085665762424469, time: 14:43:17, step: 10399\nloss: 0.17857131361961365, time: 14:45:14, step: 10499\nloss: 0.18260647356510162, time: 14:47:12, step: 10599\nloss: 0.24113376438617706, time: 14:49:09, step: 10699\nloss: 0.1832442283630371, time: 14:51:06, step: 10799\nloss: 0.09372150897979736, time: 14:53:04, step: 10899\nloss: 0.10361390560865402, time: 14:55:01, step: 10999\nloss: 0.1176331490278244, time: 14:56:59, step: 11099\nloss: 0.2714439332485199, time: 14:58:56, step: 11199\nloss: 0.1726958006620407, time: 15:00:54, step: 11299\nloss: 0.2361205816268921, time: 15:02:51, step: 11399\nloss: 0.267292320728302, time: 15:04:49, step: 11499\nloss: 0.2549099028110504, time: 15:06:46, step: 11599\nloss: 0.12235642224550247, time: 15:08:43, step: 11699\nloss: 0.08921321481466293, time: 15:10:41, step: 11799\nloss: 0.30931344628334045, time: 15:12:38, step: 11899\nloss: 0.18588973581790924, time: 15:14:36, step: 11999\nloss: 0.12928487360477448, time: 15:16:33, step: 12099\nloss: 0.1741018146276474, time: 15:18:30, step: 12199\nloss: 0.2509731352329254, time: 15:20:28, step: 12299\nloss: 0.37791866064071655, time: 15:22:25, step: 12399\nloss: 0.18014907836914062, time: 15:24:23, step: 12499\nloss: 0.21930533647537231, time: 15:26:20, step: 12599\nloss: 0.16413065791130066, time: 15:28:18, step: 12699\nloss: 0.20671916007995605, time: 15:30:15, step: 12799\nEpoch 1 train end 15:33:02\nEpoch 2 train begin 15:33:02\nloss: 0.22971178591251373, time: 15:35:00, step: 99\nloss: 0.347322016954422, time: 15:36:58, step: 199\nloss: 0.14259280264377594, time: 15:38:55, step: 299\nloss: 0.14365510642528534, time: 15:40:53, step: 399\nloss: 0.2494008094072342, time: 15:42:50, step: 499\nloss: 0.17110466957092285, time: 15:44:48, step: 599\nloss: 0.14695888757705688, time: 15:46:45, step: 699\nloss: 0.156096950173378, time: 15:48:42, step: 799\nloss: 0.08166833966970444, time: 15:50:40, step: 899\nloss: 0.1443219929933548, time: 15:52:37, step: 999\nloss: 0.07011628150939941, time: 15:54:35, step: 1099\nloss: 0.21583843231201172, time: 15:56:32, step: 1199\nloss: 0.18395332992076874, time: 15:58:30, step: 1299\nloss: 0.2366107702255249, time: 16:00:27, step: 1399\nloss: 0.15699858963489532, time: 16:02:24, step: 1499\nloss: 0.13033801317214966, time: 16:04:22, step: 1599\nloss: 0.2214290350675583, time: 16:06:19, step: 1699\nloss: 0.13075323402881622, time: 16:08:17, step: 1799\nloss: 0.0885455533862114, time: 16:10:14, step: 1899\nloss: 0.13541056215763092, time: 16:12:11, step: 1999\nloss: 0.1679229587316513, time: 16:14:09, step: 2099\nloss: 0.07508832216262817, time: 16:16:06, step: 2199\nloss: 0.21475274860858917, time: 16:18:04, step: 2299\nloss: 0.08517033606767654, time: 16:20:01, step: 2399\nloss: 0.16295188665390015, time: 16:21:59, step: 2499\nloss: 0.09779427200555801, time: 16:23:56, step: 2599\nloss: 0.26755496859550476, time: 16:25:53, step: 2699\nloss: 0.12154794484376907, time: 16:27:51, step: 2799\nloss: 0.13825452327728271, time: 16:29:48, step: 2899\nloss: 0.10423121601343155, time: 16:31:46, step: 2999\nloss: 0.17301850020885468, time: 16:33:43, step: 3099\nloss: 0.06161591410636902, time: 16:35:41, step: 3199\nloss: 0.22646920382976532, time: 16:37:38, step: 3299\nloss: 0.1415751427412033, time: 16:39:35, step: 3399\nloss: 0.06235726550221443, time: 16:41:33, step: 3499\nloss: 0.1832677572965622, time: 16:43:30, step: 3599\nloss: 0.10528182238340378, time: 16:45:28, step: 3699\nloss: 0.14353565871715546, time: 16:47:25, step: 3799\nloss: 0.24024905264377594, time: 16:49:23, step: 3899\nloss: 0.10153964906930923, time: 16:51:20, step: 3999\nloss: 0.30936411023139954, time: 16:53:17, step: 4099\nloss: 0.06413878500461578, time: 16:55:15, step: 4199\nloss: 0.09770062565803528, time: 16:57:12, step: 4299\nloss: 0.13891488313674927, time: 16:59:10, step: 4399\nloss: 0.03309903293848038, time: 17:01:07, step: 4499\nloss: 0.40481123328208923, time: 17:03:05, step: 4599\nloss: 0.11689435690641403, time: 17:05:02, step: 4699\nloss: 0.07421424239873886, time: 17:07:00, step: 4799\nloss: 0.06944383680820465, time: 17:08:57, step: 4899\nloss: 0.12342774122953415, time: 17:10:54, step: 4999\nloss: 0.08152101188898087, time: 17:12:52, step: 5099\nloss: 0.1658615618944168, time: 17:14:49, step: 5199\nloss: 0.07734282314777374, time: 17:16:47, step: 5299\nloss: 0.16357149183750153, time: 17:18:44, step: 5399\nloss: 0.057143040001392365, time: 17:20:42, step: 5499\nloss: 0.22483836114406586, time: 17:22:39, step: 5599\nloss: 0.059957150369882584, time: 17:24:36, step: 5699\nloss: 0.16244535148143768, time: 17:26:34, step: 5799\nloss: 0.08772066235542297, time: 17:28:31, step: 5899\nloss: 0.1298660784959793, time: 17:30:29, step: 5999\nloss: 0.07494455575942993, time: 17:32:26, step: 6099\nloss: 0.21051500737667084, time: 17:34:24, step: 6199\nloss: 0.12640705704689026, time: 17:36:21, step: 6299\nloss: 0.03271814063191414, time: 17:38:18, step: 6399\nloss: 0.19854633510112762, time: 17:40:16, step: 6499\nloss: 0.12971371412277222, time: 17:42:13, step: 6599\nloss: 0.03687145933508873, time: 17:44:11, step: 6699\nloss: 0.08402527868747711, time: 17:46:08, step: 6799\nloss: 0.04257367178797722, time: 17:48:06, step: 6899\nloss: 0.07103939354419708, time: 17:50:03, step: 6999\nloss: 0.11743254214525223, time: 17:52:00, step: 7099\nloss: 0.05686917155981064, time: 17:53:58, step: 7199\nloss: 0.045383140444755554, time: 17:55:55, step: 7299\nloss: 0.1250266283750534, time: 17:57:53, step: 7399\nloss: 0.15903855860233307, time: 17:59:50, step: 7499\nloss: 0.21763738989830017, time: 18:01:48, step: 7599\nloss: 0.1286647915840149, time: 18:03:45, step: 7699\nloss: 0.1760011464357376, time: 18:05:42, step: 7799\nloss: 0.19891200959682465, time: 18:07:40, step: 7899\nloss: 0.15652725100517273, time: 18:09:37, step: 7999\nloss: 0.12395832687616348, time: 18:11:35, step: 8099\nloss: 0.1147964596748352, time: 18:13:32, step: 8199\nloss: 0.09861423820257187, time: 18:15:30, step: 8299\nloss: 0.1129213348031044, time: 18:17:27, step: 8399\nloss: 0.10102827101945877, time: 18:19:24, step: 8499\nloss: 0.047908514738082886, time: 18:21:22, step: 8599\nloss: 0.13644008338451385, time: 18:23:19, step: 8699\nloss: 0.08057191967964172, time: 18:25:17, step: 8799\nloss: 0.07927601039409637, time: 18:27:14, step: 8899\nloss: 0.08435923606157303, time: 18:29:11, step: 8999\nloss: 0.0666358694434166, time: 18:31:09, step: 9099\nloss: 0.18315869569778442, time: 18:33:06, step: 9199\nloss: 0.05608317628502846, time: 18:35:04, step: 9299\nloss: 0.21014909446239471, time: 18:37:01, step: 9399\nloss: 0.07376822829246521, time: 18:38:59, step: 9499\nloss: 0.07680679112672806, time: 18:40:56, step: 9599\nloss: 0.07693413645029068, time: 18:42:54, step: 9699\nloss: 0.111598901450634, time: 18:44:51, step: 9799\nloss: 0.13293804228305817, time: 18:46:48, step: 9899\nloss: 0.02714235708117485, time: 18:48:46, step: 9999\nloss: 0.043554868549108505, time: 18:50:43, step: 10099\nloss: 0.11941371858119965, time: 18:52:41, step: 10199\nloss: 0.07413580268621445, time: 18:54:38, step: 10299\nloss: 0.07902921736240387, time: 18:56:36, step: 10399\nloss: 0.08556836098432541, time: 18:58:33, step: 10499\nloss: 0.07908113300800323, time: 19:00:30, step: 10599\nloss: 0.16481274366378784, time: 19:02:28, step: 10699\nloss: 0.09829827398061752, time: 19:04:25, step: 10799\nloss: 0.021362831816077232, time: 19:06:23, step: 10899\nloss: 0.03291096165776253, time: 19:08:20, step: 10999\nloss: 0.046687714755535126, time: 19:10:18, step: 11099\nloss: 0.12289990484714508, time: 19:12:15, step: 11199\nloss: 0.05155684053897858, time: 19:14:12, step: 11299\nloss: 0.058845289051532745, time: 19:16:10, step: 11399\nloss: 0.139785498380661, time: 19:18:07, step: 11499\nloss: 0.09783820062875748, time: 19:20:05, step: 11599\nloss: 0.05050531402230263, time: 19:22:02, step: 11699\nloss: 0.043456558138132095, time: 19:24:00, step: 11799\nloss: 0.12396728247404099, time: 19:25:57, step: 11899\nloss: 0.06470035016536713, time: 19:27:54, step: 11999\nloss: 0.05181620270013809, time: 19:29:52, step: 12099\nloss: 0.0867127850651741, time: 19:31:49, step: 12199\nloss: 0.13217012584209442, time: 19:33:47, step: 12299\nloss: 0.1551947444677353, time: 19:35:44, step: 12399\nloss: 0.05876551568508148, time: 19:37:41, step: 12499\nloss: 0.08281960338354111, time: 19:39:39, step: 12599\nloss: 0.07704824209213257, time: 19:41:36, step: 12699\nloss: 0.11039026081562042, time: 19:43:34, step: 12799\nEpoch 2 train end 19:45:20\n","output_type":"stream"}]},{"cell_type":"code","source":"model = model.cpu()","metadata":{"execution":{"iopub.status.busy":"2024-01-18T19:45:20.339618Z","iopub.execute_input":"2024-01-18T19:45:20.339874Z","iopub.status.idle":"2024-01-18T19:51:05.735607Z","shell.execute_reply.started":"2024-01-18T19:45:20.339846Z","shell.execute_reply":"2024-01-18T19:51:05.734313Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(new_model)\nmodel.config.to_json_file(os.path.join(new_model, \"config.json\"))\ntokenizer.save_pretrained(new_model)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T12:43:31.626935Z","iopub.execute_input":"2024-01-01T12:43:31.627357Z","iopub.status.idle":"2024-01-01T12:44:19.865649Z","shell.execute_reply.started":"2024-01-01T12:43:31.627323Z","shell.execute_reply":"2024-01-01T12:44:19.864872Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n\nThrown during validation:\n`do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"('BK-BigAI-Math/tokenizer_config.json',\n 'BK-BigAI-Math/special_tokens_map.json',\n 'BK-BigAI-Math/tokenizer.model',\n 'BK-BigAI-Math/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"secret_hf_write = user_secrets.get_secret(\"HUGGINGFACE_WRITE_TOKEN\")","metadata":{"execution":{"iopub.status.busy":"2024-01-18T19:51:05.736926Z","iopub.execute_input":"2024-01-18T19:51:05.737323Z","iopub.status.idle":"2024-01-18T19:51:05.945983Z","shell.execute_reply.started":"2024-01-18T19:51:05.737290Z","shell.execute_reply":"2024-01-18T19:51:05.945177Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf_write","metadata":{"execution":{"iopub.status.busy":"2024-01-18T19:51:05.948138Z","iopub.execute_input":"2024-01-18T19:51:05.948383Z","iopub.status.idle":"2024-01-18T19:51:07.749323Z","shell.execute_reply.started":"2024-01-18T19:51:05.948356Z","shell.execute_reply":"2024-01-18T19:51:07.748276Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"url_push_to_hub = \"hotamago/HotaMath-OpenMath-2023-01-18-ElementaryMathematics\"\nmodel.push_to_hub(url_push_to_hub)\ntokenizer.push_to_hub(url_push_to_hub)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-18T19:51:07.750665Z","iopub.execute_input":"2024-01-18T19:51:07.750940Z","iopub.status.idle":"2024-01-18T19:56:12.746068Z","shell.execute_reply.started":"2024-01-18T19:51:07.750910Z","shell.execute_reply":"2024-01-18T19:56:12.745304Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:527: UserWarning: The generation config instance is invalid -- `.validate()` throws warnings and/or exceptions. Fix these issues to save the configuration. This warning will be raised to an exception in v4.34.\n\nThrown during validation:\n`do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  warnings.warn(\nmodel-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]\nmodel-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]\u001b[A\n\nUpload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   0%|          | 16.4k/4.94G [00:00<8:48:48, 156kB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   0%|          | 16.4k/4.54G [00:00<7:43:36, 163kB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   0%|          | 6.29M/4.94G [00:00<02:16, 36.2MB/s] \u001b[A\n\n\nmodel-00003-of-00003.safetensors:   0%|          | 7.14M/4.54G [00:00<01:49, 41.6MB/s] \u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   0%|          | 16.0M/4.54G [00:00<02:01, 37.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   0%|          | 16.0M/4.94G [00:00<02:29, 33.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   1%|          | 28.8M/4.54G [00:00<01:12, 61.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   1%|          | 28.2M/4.94G [00:00<01:30, 54.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   1%|          | 36.0M/4.54G [00:00<01:44, 42.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   1%|          | 34.9M/4.94G [00:00<02:07, 38.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   1%|          | 47.7M/4.94G [00:01<01:26, 56.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   1%|          | 48.0M/4.54G [00:01<01:50, 40.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   1%|▏         | 61.1M/4.54G [00:01<01:20, 55.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   1%|          | 55.4M/4.94G [00:01<02:14, 36.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   2%|▏         | 68.5M/4.54G [00:01<01:44, 42.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   1%|▏         | 64.0M/4.94G [00:01<02:26, 33.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   2%|▏         | 76.9M/4.94G [00:01<01:43, 47.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   2%|▏         | 84.1M/4.94G [00:02<01:57, 41.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   2%|▏         | 95.3M/4.94G [00:02<01:31, 53.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   2%|▏         | 103M/4.94G [00:02<01:57, 41.1MB/s] \u001b[A\n\n\nmodel-00003-of-00003.safetensors:   2%|▏         | 80.0M/4.54G [00:02<03:14, 22.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   2%|▏         | 92.7M/4.54G [00:02<02:17, 32.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   2%|▏         | 112M/4.94G [00:02<02:10, 37.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 126M/4.94G [00:02<01:33, 51.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   2%|▏         | 99.6M/4.54G [00:02<02:31, 29.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   2%|▏         | 109M/4.54G [00:03<01:58, 37.3MB/s] \u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   3%|▎         | 116M/4.54G [00:03<02:13, 33.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 133M/4.94G [00:03<02:14, 35.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   3%|▎         | 128M/4.54G [00:03<01:39, 44.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 144M/4.94G [00:03<02:15, 35.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   3%|▎         | 135M/4.54G [00:03<01:59, 36.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 157M/4.94G [00:03<01:41, 47.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   3%|▎         | 144M/4.54G [00:04<02:08, 34.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 164M/4.94G [00:04<02:07, 37.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   3%|▎         | 157M/4.54G [00:04<01:33, 47.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   3%|▎         | 173M/4.94G [00:04<01:45, 45.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   4%|▎         | 180M/4.94G [00:04<01:53, 42.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   4%|▍         | 190M/4.94G [00:04<01:30, 52.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   4%|▎         | 164M/4.54G [00:04<01:59, 36.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   4%|▍         | 175M/4.54G [00:04<01:33, 46.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   4%|▍         | 197M/4.94G [00:04<02:03, 38.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   4%|▍         | 182M/4.54G [00:04<01:47, 40.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   4%|▍         | 208M/4.94G [00:04<01:34, 49.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   4%|▍         | 192M/4.54G [00:05<01:53, 38.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   4%|▍         | 215M/4.94G [00:05<02:01, 39.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   5%|▍         | 205M/4.54G [00:05<01:22, 52.6MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   5%|▍         | 213M/4.54G [00:05<01:34, 45.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   5%|▍         | 224M/4.94G [00:05<02:21, 33.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   5%|▍         | 224M/4.54G [00:05<01:17, 56.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   5%|▍         | 237M/4.94G [00:05<01:41, 46.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   5%|▌         | 231M/4.54G [00:05<01:33, 46.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   5%|▍         | 244M/4.94G [00:05<02:03, 38.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   5%|▌         | 255M/4.94G [00:06<01:36, 48.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   5%|▌         | 240M/4.54G [00:06<01:58, 36.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   6%|▌         | 253M/4.54G [00:06<01:26, 49.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   5%|▌         | 262M/4.94G [00:06<02:05, 37.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   6%|▌         | 260M/4.54G [00:06<02:02, 35.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▌         | 272M/4.94G [00:06<02:14, 34.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▌         | 284M/4.94G [00:06<01:39, 46.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   6%|▌         | 272M/4.54G [00:06<01:56, 36.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▌         | 291M/4.94G [00:07<01:55, 40.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   6%|▋         | 285M/4.54G [00:07<01:26, 49.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▌         | 302M/4.94G [00:07<01:32, 50.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   6%|▋         | 292M/4.54G [00:07<01:39, 42.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▌         | 309M/4.94G [00:07<01:50, 42.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   7%|▋         | 303M/4.54G [00:07<01:19, 53.6MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   7%|▋         | 311M/4.54G [00:07<01:45, 39.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   6%|▋         | 320M/4.94G [00:07<02:03, 37.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   7%|▋         | 333M/4.94G [00:07<01:31, 50.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   7%|▋         | 320M/4.54G [00:08<01:55, 36.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   7%|▋         | 340M/4.94G [00:08<01:49, 41.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   7%|▋         | 333M/4.54G [00:08<01:24, 49.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   7%|▋         | 351M/4.94G [00:08<01:27, 52.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   7%|▋         | 340M/4.54G [00:08<01:38, 42.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   8%|▊         | 352M/4.54G [00:08<01:17, 54.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   7%|▋         | 358M/4.94G [00:08<01:50, 41.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   7%|▋         | 368M/4.94G [00:08<02:07, 35.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   8%|▊         | 359M/4.54G [00:08<01:59, 35.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   8%|▊         | 381M/4.94G [00:08<01:33, 48.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   8%|▊         | 368M/4.54G [00:09<02:05, 33.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   8%|▊         | 388M/4.94G [00:09<01:55, 39.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   8%|▊         | 380M/4.54G [00:09<01:31, 45.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   8%|▊         | 400M/4.94G [00:09<01:58, 38.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   9%|▊         | 388M/4.54G [00:09<01:46, 38.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   8%|▊         | 413M/4.94G [00:09<01:29, 50.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   9%|▉         | 398M/4.54G [00:09<01:23, 49.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   9%|▉         | 406M/4.54G [00:09<01:31, 45.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   9%|▊         | 420M/4.94G [00:09<01:45, 42.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   9%|▉         | 416M/4.54G [00:10<01:29, 46.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:   9%|▉         | 429M/4.54G [00:10<01:08, 59.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   9%|▊         | 432M/4.94G [00:10<01:57, 38.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:   9%|▉         | 445M/4.94G [00:10<01:29, 50.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  10%|▉         | 437M/4.54G [00:10<01:20, 50.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   9%|▉         | 452M/4.94G [00:10<01:43, 43.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  10%|▉         | 448M/4.54G [00:10<01:52, 36.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:   9%|▉         | 464M/4.94G [00:11<01:52, 39.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  10%|▉         | 478M/4.94G [00:11<01:24, 52.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  10%|█         | 464M/4.54G [00:11<01:39, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  11%|█         | 477M/4.54G [00:11<01:18, 52.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  10%|▉         | 485M/4.94G [00:11<01:46, 41.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  10%|█         | 496M/4.94G [00:11<01:53, 39.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  10%|█         | 509M/4.94G [00:11<01:26, 51.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  11%|█         | 484M/4.54G [00:11<02:02, 33.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  11%|█         | 496M/4.54G [00:12<01:55, 34.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  10%|█         | 516M/4.94G [00:12<02:29, 29.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  11%|█▏        | 512M/4.54G [00:12<01:48, 37.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  12%|█▏        | 525M/4.54G [00:12<01:24, 47.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  12%|█▏        | 532M/4.54G [00:12<01:36, 41.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  11%|█         | 528M/4.94G [00:13<02:43, 27.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  12%|█▏        | 543M/4.54G [00:13<01:19, 50.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  11%|█         | 542M/4.94G [00:13<01:55, 38.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  12%|█▏        | 550M/4.54G [00:13<01:40, 39.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  11%|█         | 549M/4.94G [00:13<02:10, 33.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  12%|█▏        | 560M/4.54G [00:13<01:47, 37.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  11%|█▏        | 560M/4.94G [00:13<02:06, 34.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  13%|█▎        | 573M/4.54G [00:13<01:18, 50.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  12%|█▏        | 573M/4.94G [00:13<01:34, 46.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  12%|█▏        | 580M/4.94G [00:14<01:46, 40.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  13%|█▎        | 581M/4.54G [00:14<01:39, 40.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  12%|█▏        | 592M/4.94G [00:14<01:24, 51.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  13%|█▎        | 592M/4.54G [00:14<01:42, 38.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  12%|█▏        | 599M/4.94G [00:14<01:42, 42.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  13%|█▎        | 606M/4.54G [00:14<01:15, 51.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  12%|█▏        | 608M/4.94G [00:14<01:53, 38.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  14%|█▎        | 613M/4.54G [00:14<01:33, 42.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  13%|█▎        | 621M/4.94G [00:14<01:23, 51.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  14%|█▎        | 624M/4.54G [00:15<01:32, 42.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  13%|█▎        | 628M/4.94G [00:15<01:53, 38.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  14%|█▍        | 640M/4.54G [00:15<01:22, 47.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  13%|█▎        | 640M/4.94G [00:15<01:49, 39.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  13%|█▎        | 653M/4.94G [00:15<01:22, 51.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  14%|█▍        | 656M/4.54G [00:15<01:26, 44.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  13%|█▎        | 660M/4.94G [00:15<01:40, 42.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  14%|█▎        | 670M/4.94G [00:15<01:23, 51.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  15%|█▍        | 672M/4.54G [00:16<01:29, 43.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  14%|█▎        | 677M/4.94G [00:16<01:59, 35.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  15%|█▌        | 688M/4.54G [00:16<01:24, 45.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  14%|█▍        | 688M/4.94G [00:16<01:42, 41.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  15%|█▌        | 701M/4.54G [00:16<01:09, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  16%|█▌        | 708M/4.54G [00:16<01:21, 46.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  14%|█▍        | 704M/4.94G [00:16<01:44, 40.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  16%|█▌        | 720M/4.54G [00:17<01:18, 48.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  15%|█▍        | 718M/4.94G [00:17<01:19, 53.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  16%|█▌        | 736M/4.54G [00:17<01:18, 48.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  16%|█▋        | 749M/4.54G [00:17<01:04, 58.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  15%|█▍        | 726M/4.94G [00:17<02:29, 28.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  17%|█▋        | 757M/4.54G [00:17<01:26, 43.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  15%|█▍        | 736M/4.94G [00:18<02:14, 31.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  17%|█▋        | 768M/4.54G [00:18<01:27, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  17%|█▋        | 784M/4.54G [00:18<01:50, 34.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  15%|█▌        | 752M/4.94G [00:18<02:56, 23.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  18%|█▊        | 800M/4.54G [00:19<01:35, 39.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  16%|█▌        | 768M/4.94G [00:19<02:18, 30.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  18%|█▊        | 816M/4.54G [00:19<01:23, 44.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  16%|█▌        | 780M/4.94G [00:19<01:49, 37.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  18%|█▊        | 832M/4.54G [00:19<01:12, 51.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  16%|█▌        | 787M/4.94G [00:19<01:55, 36.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  19%|█▊        | 848M/4.54G [00:19<01:12, 51.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  16%|█▌        | 800M/4.94G [00:19<01:54, 36.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  16%|█▋        | 813M/4.94G [00:20<01:27, 47.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  19%|█▉        | 864M/4.54G [00:20<01:06, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  19%|█▉        | 874M/4.54G [00:20<01:01, 59.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  17%|█▋        | 820M/4.94G [00:20<01:36, 42.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  19%|█▉        | 881M/4.54G [00:20<01:17, 47.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  17%|█▋        | 832M/4.94G [00:20<01:29, 46.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  17%|█▋        | 845M/4.94G [00:20<01:10, 58.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  20%|█▉        | 896M/4.54G [00:20<01:10, 52.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  17%|█▋        | 853M/4.94G [00:20<01:22, 49.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  17%|█▋        | 864M/4.94G [00:20<01:07, 60.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  20%|██        | 912M/4.54G [00:20<01:06, 54.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  18%|█▊        | 872M/4.94G [00:21<01:26, 47.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  20%|██        | 928M/4.54G [00:21<01:02, 57.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  18%|█▊        | 880M/4.94G [00:21<01:32, 44.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  21%|██        | 944M/4.54G [00:21<01:02, 57.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  18%|█▊        | 896M/4.94G [00:21<01:21, 49.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  21%|██        | 960M/4.54G [00:21<01:01, 58.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  18%|█▊        | 909M/4.94G [00:21<01:04, 62.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  21%|██▏       | 974M/4.54G [00:21<00:51, 68.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  19%|█▊        | 917M/4.94G [00:22<01:32, 43.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  22%|██▏       | 982M/4.54G [00:22<01:07, 53.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  19%|█▉        | 928M/4.94G [00:22<01:14, 53.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  22%|██▏       | 992M/4.54G [00:22<01:19, 44.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  19%|█▉        | 935M/4.94G [00:22<01:30, 44.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  22%|██▏       | 1.01G/4.54G [00:22<01:11, 49.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  19%|█▉        | 944M/4.94G [00:22<01:42, 38.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  23%|██▎       | 1.02G/4.54G [00:23<01:06, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  23%|██▎       | 1.04G/4.54G [00:23<01:04, 53.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  23%|██▎       | 1.06G/4.54G [00:23<01:06, 52.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  24%|██▎       | 1.07G/4.54G [00:23<01:04, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  24%|██▍       | 1.09G/4.54G [00:24<00:54, 63.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  24%|██▍       | 1.09G/4.54G [00:24<01:08, 50.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  24%|██▍       | 1.10G/4.54G [00:24<00:59, 57.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  24%|██▍       | 1.11G/4.54G [00:24<01:25, 40.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  25%|██▍       | 1.12G/4.54G [00:25<01:21, 41.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  25%|██▍       | 1.13G/4.54G [00:25<01:02, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  25%|██▌       | 1.14G/4.54G [00:25<01:14, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  25%|██▌       | 1.15G/4.54G [00:25<01:15, 44.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  26%|██▌       | 1.17G/4.54G [00:25<01:09, 48.6MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  26%|██▌       | 1.18G/4.54G [00:26<01:02, 53.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  26%|██▋       | 1.20G/4.54G [00:26<01:03, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  27%|██▋       | 1.22G/4.54G [00:26<01:02, 52.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  27%|██▋       | 1.23G/4.54G [00:27<00:57, 57.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  19%|█▉        | 960M/4.94G [00:27<08:19, 7.98MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  20%|█▉        | 968M/4.94G [00:27<06:30, 10.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  27%|██▋       | 1.25G/4.54G [00:27<00:57, 57.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  20%|█▉        | 976M/4.94G [00:27<05:28, 12.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  20%|██        | 989M/4.94G [00:27<03:39, 18.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  28%|██▊       | 1.26G/4.54G [00:27<00:57, 56.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  20%|██        | 996M/4.94G [00:27<03:37, 18.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  20%|██        | 1.01G/4.94G [00:27<02:41, 24.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  28%|██▊       | 1.28G/4.54G [00:27<01:05, 49.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  20%|██        | 1.01G/4.94G [00:28<02:37, 24.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  29%|██▊       | 1.30G/4.54G [00:28<01:01, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  29%|██▉       | 1.31G/4.54G [00:28<00:58, 55.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  21%|██        | 1.02G/4.94G [00:28<02:26, 26.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  29%|██▉       | 1.33G/4.54G [00:28<00:57, 56.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  21%|██        | 1.04G/4.94G [00:28<01:52, 34.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  21%|██▏       | 1.06G/4.94G [00:29<01:34, 41.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  22%|██▏       | 1.07G/4.94G [00:29<01:15, 51.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  30%|██▉       | 1.34G/4.54G [00:29<01:14, 43.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  30%|██▉       | 1.36G/4.54G [00:29<01:06, 47.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  22%|██▏       | 1.08G/4.94G [00:29<01:47, 36.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  22%|██▏       | 1.09G/4.94G [00:29<01:26, 44.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  30%|███       | 1.38G/4.54G [00:29<01:02, 50.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  22%|██▏       | 1.09G/4.94G [00:30<01:49, 35.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  31%|███       | 1.39G/4.54G [00:30<01:08, 45.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  22%|██▏       | 1.10G/4.94G [00:30<01:50, 34.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  23%|██▎       | 1.12G/4.94G [00:30<01:31, 41.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  31%|███       | 1.41G/4.54G [00:30<01:10, 44.6MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  31%|███▏      | 1.42G/4.54G [00:30<01:06, 46.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  23%|██▎       | 1.14G/4.94G [00:31<01:37, 39.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  32%|███▏      | 1.44G/4.54G [00:31<01:03, 48.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  23%|██▎       | 1.15G/4.94G [00:31<01:39, 38.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  32%|███▏      | 1.46G/4.54G [00:31<01:04, 47.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  24%|██▎       | 1.17G/4.94G [00:31<01:22, 45.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  32%|███▏      | 1.47G/4.54G [00:31<01:00, 50.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  24%|██▍       | 1.18G/4.94G [00:32<01:23, 45.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  33%|███▎      | 1.49G/4.54G [00:32<00:59, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  33%|███▎      | 1.50G/4.54G [00:32<00:56, 53.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  24%|██▍       | 1.20G/4.94G [00:32<01:22, 45.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  33%|███▎      | 1.52G/4.54G [00:32<00:58, 51.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  25%|██▍       | 1.22G/4.94G [00:32<01:22, 45.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  25%|██▍       | 1.23G/4.94G [00:32<01:07, 55.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  34%|███▍      | 1.54G/4.54G [00:33<00:54, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  34%|███▍      | 1.55G/4.54G [00:33<00:49, 60.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  25%|██▌       | 1.24G/4.94G [00:33<01:23, 44.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  35%|███▍      | 1.57G/4.54G [00:33<00:47, 62.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  25%|██▌       | 1.25G/4.94G [00:33<01:22, 44.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  35%|███▍      | 1.58G/4.54G [00:33<00:50, 58.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  26%|██▌       | 1.26G/4.94G [00:34<01:40, 36.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  35%|███▌      | 1.60G/4.54G [00:34<00:56, 52.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  26%|██▌       | 1.28G/4.94G [00:34<01:24, 43.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  36%|███▌      | 1.62G/4.54G [00:34<00:54, 54.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  26%|██▌       | 1.30G/4.94G [00:34<01:13, 49.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  36%|███▌      | 1.63G/4.54G [00:34<00:53, 54.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  27%|██▋       | 1.31G/4.94G [00:34<01:18, 46.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  27%|██▋       | 1.33G/4.94G [00:35<01:17, 46.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  27%|██▋       | 1.34G/4.94G [00:35<01:18, 46.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  36%|███▋      | 1.65G/4.54G [00:35<01:29, 32.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  28%|██▊       | 1.36G/4.94G [00:35<01:11, 49.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  37%|███▋      | 1.66G/4.54G [00:36<01:21, 35.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  28%|██▊       | 1.38G/4.94G [00:36<01:07, 52.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  37%|███▋      | 1.68G/4.54G [00:36<01:14, 38.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  28%|██▊       | 1.39G/4.94G [00:36<01:10, 50.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  28%|██▊       | 1.41G/4.94G [00:36<00:59, 59.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  37%|███▋      | 1.70G/4.54G [00:36<01:06, 42.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  29%|██▊       | 1.41G/4.94G [00:36<01:10, 49.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  38%|███▊      | 1.71G/4.54G [00:36<01:01, 45.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  38%|███▊      | 1.73G/4.54G [00:37<00:55, 50.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  29%|██▉       | 1.42G/4.94G [00:37<01:21, 42.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  38%|███▊      | 1.74G/4.54G [00:37<00:51, 53.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  29%|██▉       | 1.44G/4.94G [00:37<01:15, 46.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  29%|██▉       | 1.45G/4.94G [00:37<01:02, 56.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  39%|███▉      | 1.76G/4.54G [00:37<00:50, 55.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  30%|██▉       | 1.46G/4.94G [00:38<01:23, 41.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  30%|██▉       | 1.47G/4.94G [00:38<01:21, 42.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  39%|███▉      | 1.78G/4.54G [00:38<01:10, 39.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  30%|███       | 1.49G/4.94G [00:38<01:13, 47.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  30%|███       | 1.50G/4.94G [00:38<01:09, 49.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  39%|███▉      | 1.79G/4.54G [00:38<01:16, 35.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  31%|███       | 1.52G/4.94G [00:39<01:04, 53.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  40%|███▉      | 1.81G/4.54G [00:39<01:08, 39.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  31%|███       | 1.54G/4.94G [00:39<01:05, 52.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  40%|████      | 1.82G/4.54G [00:39<01:06, 40.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  31%|███▏      | 1.55G/4.94G [00:39<01:09, 49.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  32%|███▏      | 1.56G/4.94G [00:39<00:57, 58.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  41%|████      | 1.84G/4.54G [00:40<01:05, 41.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  32%|███▏      | 1.57G/4.94G [00:40<01:14, 45.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  41%|████      | 1.86G/4.54G [00:40<00:58, 45.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  32%|███▏      | 1.58G/4.94G [00:40<01:15, 44.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  41%|████      | 1.87G/4.54G [00:40<00:59, 44.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  42%|████▏     | 1.89G/4.54G [00:40<00:54, 48.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  32%|███▏      | 1.60G/4.94G [00:41<01:24, 39.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  42%|████▏     | 1.90G/4.54G [00:41<00:52, 49.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  33%|███▎      | 1.62G/4.94G [00:41<01:16, 43.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  42%|████▏     | 1.92G/4.54G [00:41<00:49, 52.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  33%|███▎      | 1.63G/4.94G [00:41<01:12, 45.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  33%|███▎      | 1.65G/4.94G [00:41<00:59, 55.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  43%|████▎     | 1.94G/4.54G [00:41<00:48, 53.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  33%|███▎      | 1.65G/4.94G [00:42<01:13, 44.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  43%|████▎     | 1.95G/4.54G [00:42<00:46, 55.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  34%|███▎      | 1.66G/4.94G [00:42<01:14, 44.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  43%|████▎     | 1.97G/4.54G [00:42<00:48, 53.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  34%|███▍      | 1.68G/4.94G [00:42<01:08, 47.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  44%|████▎     | 1.98G/4.54G [00:42<00:48, 53.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  34%|███▍      | 1.70G/4.94G [00:42<01:00, 53.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  44%|████▍     | 2.00G/4.54G [00:42<00:42, 60.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  35%|███▍      | 1.71G/4.94G [00:43<01:00, 53.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  44%|████▍     | 2.02G/4.54G [00:43<00:43, 58.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  45%|████▍     | 2.03G/4.54G [00:43<00:42, 59.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  35%|███▍      | 1.73G/4.94G [00:43<01:14, 43.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  45%|████▌     | 2.05G/4.54G [00:43<00:44, 55.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  35%|███▌      | 1.74G/4.94G [00:43<01:04, 49.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  45%|████▌     | 2.06G/4.54G [00:43<00:43, 57.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  36%|███▌      | 1.76G/4.94G [00:44<01:02, 50.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  46%|████▌     | 2.08G/4.54G [00:44<00:41, 59.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  36%|███▌      | 1.77G/4.94G [00:44<00:54, 58.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  46%|████▌     | 2.10G/4.54G [00:44<00:39, 61.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  36%|███▌      | 1.78G/4.94G [00:44<01:09, 45.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  47%|████▋     | 2.11G/4.54G [00:44<00:40, 59.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  36%|███▋      | 1.79G/4.94G [00:44<01:06, 47.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  47%|████▋     | 2.13G/4.54G [00:45<00:41, 58.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  37%|███▋      | 1.81G/4.94G [00:45<01:01, 50.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  47%|████▋     | 2.14G/4.54G [00:45<00:38, 61.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  37%|███▋      | 1.82G/4.94G [00:45<00:59, 52.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  48%|████▊     | 2.16G/4.54G [00:45<00:40, 59.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  37%|███▋      | 1.84G/4.94G [00:45<00:58, 52.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  48%|████▊     | 2.18G/4.54G [00:45<00:41, 57.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  38%|███▊      | 1.86G/4.94G [00:45<00:57, 54.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  38%|███▊      | 1.87G/4.94G [00:46<00:54, 56.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  48%|████▊     | 2.19G/4.54G [00:46<00:49, 47.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  38%|███▊      | 1.89G/4.94G [00:46<00:53, 57.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  39%|███▊      | 1.90G/4.94G [00:46<00:56, 53.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  49%|████▊     | 2.21G/4.54G [00:46<00:56, 41.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  49%|████▉     | 2.22G/4.54G [00:47<00:52, 44.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  39%|███▉      | 1.92G/4.94G [00:47<00:59, 50.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  39%|███▉      | 1.94G/4.94G [00:47<00:53, 56.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  49%|████▉     | 2.24G/4.54G [00:47<00:51, 44.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  39%|███▉      | 1.95G/4.94G [00:47<00:54, 55.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  50%|████▉     | 2.26G/4.54G [00:47<00:52, 43.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  40%|███▉      | 1.97G/4.94G [00:47<00:52, 56.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  50%|█████     | 2.27G/4.54G [00:48<00:48, 46.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  40%|████      | 1.98G/4.94G [00:48<00:51, 57.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  50%|█████     | 2.29G/4.54G [00:48<00:45, 49.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  40%|████      | 2.00G/4.94G [00:48<00:53, 55.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  51%|█████     | 2.30G/4.54G [00:48<00:42, 52.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  41%|████      | 2.02G/4.94G [00:48<00:57, 51.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  51%|█████     | 2.32G/4.54G [00:49<00:45, 48.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  41%|████      | 2.03G/4.94G [00:49<00:53, 54.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  51%|█████▏    | 2.34G/4.54G [00:49<00:45, 48.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  41%|████▏     | 2.05G/4.94G [00:49<00:57, 50.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  52%|█████▏    | 2.35G/4.54G [00:49<00:42, 51.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  42%|████▏     | 2.06G/4.94G [00:49<00:51, 55.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  52%|█████▏    | 2.37G/4.54G [00:49<00:41, 52.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  42%|████▏     | 2.08G/4.94G [00:50<00:51, 55.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  52%|█████▏    | 2.38G/4.54G [00:50<00:35, 61.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  53%|█████▎    | 2.39G/4.54G [00:50<00:41, 51.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  42%|████▏     | 2.10G/4.94G [00:50<00:52, 54.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  53%|█████▎    | 2.40G/4.54G [00:50<00:42, 50.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  43%|████▎     | 2.11G/4.94G [00:50<00:55, 51.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  53%|█████▎    | 2.42G/4.54G [00:50<00:38, 55.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  54%|█████▎    | 2.43G/4.54G [00:51<00:37, 56.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  43%|████▎     | 2.13G/4.94G [00:51<01:05, 43.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  54%|█████▍    | 2.45G/4.54G [00:51<00:39, 53.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  43%|████▎     | 2.14G/4.94G [00:51<01:03, 44.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  54%|█████▍    | 2.46G/4.54G [00:51<00:37, 56.0MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  55%|█████▍    | 2.48G/4.54G [00:51<00:34, 59.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  44%|████▎     | 2.16G/4.94G [00:51<01:04, 43.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  55%|█████▍    | 2.50G/4.54G [00:52<00:34, 59.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  55%|█████▌    | 2.51G/4.54G [00:52<00:37, 54.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  56%|█████▌    | 2.53G/4.54G [00:52<00:33, 59.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  44%|████▍     | 2.18G/4.94G [00:52<01:31, 30.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  56%|█████▌    | 2.54G/4.54G [00:53<00:36, 55.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  44%|████▍     | 2.19G/4.94G [00:53<01:19, 34.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  56%|█████▋    | 2.56G/4.54G [00:53<00:36, 55.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  45%|████▍     | 2.21G/4.94G [00:53<01:11, 38.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  57%|█████▋    | 2.58G/4.54G [00:53<00:36, 54.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  45%|████▍     | 2.22G/4.94G [00:53<01:04, 42.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  45%|████▌     | 2.24G/4.94G [00:54<00:59, 45.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  46%|████▌     | 2.26G/4.94G [00:54<00:54, 49.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  57%|█████▋    | 2.59G/4.54G [00:54<00:56, 34.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  46%|████▌     | 2.27G/4.94G [00:54<00:50, 53.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  57%|█████▋    | 2.61G/4.54G [00:54<00:50, 38.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  46%|████▋     | 2.29G/4.94G [00:54<00:51, 51.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  58%|█████▊    | 2.62G/4.54G [00:55<00:48, 39.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  47%|████▋     | 2.30G/4.94G [00:55<00:56, 46.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  58%|█████▊    | 2.64G/4.54G [00:55<00:45, 41.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  47%|████▋     | 2.32G/4.94G [00:55<00:53, 48.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  58%|█████▊    | 2.66G/4.54G [00:55<00:40, 46.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  47%|████▋     | 2.34G/4.94G [00:55<00:53, 48.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  59%|█████▉    | 2.67G/4.54G [00:56<00:38, 48.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  48%|████▊     | 2.35G/4.94G [00:56<00:51, 50.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  59%|█████▉    | 2.69G/4.54G [00:56<00:38, 48.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  48%|████▊     | 2.37G/4.94G [00:56<00:47, 54.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  48%|████▊     | 2.38G/4.94G [00:56<00:49, 51.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  60%|█████▉    | 2.70G/4.54G [00:57<00:49, 37.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  60%|█████▉    | 2.72G/4.54G [00:57<00:47, 38.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  49%|████▊     | 2.40G/4.94G [00:57<01:08, 36.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  49%|████▉     | 2.42G/4.94G [00:57<01:00, 41.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  60%|██████    | 2.74G/4.54G [00:57<00:47, 38.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  49%|████▉     | 2.43G/4.94G [00:58<00:56, 44.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  61%|██████    | 2.75G/4.54G [00:58<00:46, 38.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  50%|████▉     | 2.45G/4.94G [00:58<00:53, 46.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  50%|████▉     | 2.46G/4.94G [00:58<00:44, 55.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  61%|██████    | 2.77G/4.54G [00:58<00:39, 45.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  50%|████▉     | 2.47G/4.94G [00:58<00:52, 47.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  61%|██████▏   | 2.78G/4.54G [00:58<00:36, 48.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  50%|█████     | 2.48G/4.94G [00:59<00:52, 46.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  62%|██████▏   | 2.80G/4.54G [00:59<00:35, 49.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  50%|█████     | 2.50G/4.94G [00:59<00:51, 47.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  62%|██████▏   | 2.82G/4.54G [00:59<00:35, 48.4MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  62%|██████▏   | 2.83G/4.54G [00:59<00:32, 53.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  51%|█████     | 2.51G/4.94G [00:59<00:55, 43.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  63%|██████▎   | 2.85G/4.54G [01:00<00:32, 52.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  51%|█████     | 2.53G/4.94G [01:00<00:52, 46.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  51%|█████▏    | 2.54G/4.94G [01:00<00:48, 49.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  52%|█████▏    | 2.56G/4.94G [01:00<00:45, 52.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  52%|█████▏    | 2.58G/4.94G [01:00<00:44, 53.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  52%|█████▏    | 2.59G/4.94G [01:01<00:43, 54.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  53%|█████▎    | 2.61G/4.94G [01:01<00:46, 49.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  53%|█████▎    | 2.62G/4.94G [01:01<00:44, 52.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  53%|█████▎    | 2.64G/4.94G [01:02<00:43, 52.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  54%|█████▎    | 2.66G/4.94G [01:02<00:43, 52.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  63%|██████▎   | 2.86G/4.54G [01:02<01:46, 15.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  54%|█████▍    | 2.67G/4.94G [01:02<00:43, 52.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  63%|██████▎   | 2.87G/4.54G [01:02<01:30, 18.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  54%|█████▍    | 2.69G/4.94G [01:02<00:39, 57.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  63%|██████▎   | 2.88G/4.54G [01:02<01:21, 20.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  55%|█████▍    | 2.70G/4.94G [01:03<00:37, 60.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  64%|██████▍   | 2.90G/4.54G [01:03<01:02, 26.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  55%|█████▌    | 2.72G/4.94G [01:03<00:37, 60.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  64%|██████▍   | 2.91G/4.54G [01:03<00:52, 31.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  55%|█████▌    | 2.74G/4.94G [01:03<00:34, 63.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  64%|██████▍   | 2.93G/4.54G [01:03<00:43, 37.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  56%|█████▌    | 2.75G/4.94G [01:03<00:35, 61.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  65%|██████▍   | 2.94G/4.54G [01:04<00:36, 43.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  56%|█████▌    | 2.77G/4.94G [01:04<00:36, 59.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  65%|██████▌   | 2.96G/4.54G [01:04<00:34, 45.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  56%|█████▋    | 2.78G/4.94G [01:04<00:35, 61.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  66%|██████▌   | 2.98G/4.54G [01:04<00:32, 47.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  57%|█████▋    | 2.80G/4.94G [01:04<00:35, 60.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  57%|█████▋    | 2.82G/4.94G [01:05<00:36, 57.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  66%|██████▌   | 2.99G/4.54G [01:05<00:35, 44.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  57%|█████▋    | 2.83G/4.94G [01:05<00:36, 57.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  58%|█████▊    | 2.85G/4.94G [01:05<00:36, 57.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  66%|██████▌   | 3.01G/4.54G [01:05<00:40, 37.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  58%|█████▊    | 2.86G/4.94G [01:06<00:39, 52.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  67%|██████▋   | 3.02G/4.54G [01:06<00:36, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  67%|██████▋   | 3.04G/4.54G [01:06<00:33, 44.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  58%|█████▊    | 2.88G/4.94G [01:06<00:41, 50.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  67%|██████▋   | 3.06G/4.54G [01:06<00:29, 50.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  59%|█████▊    | 2.90G/4.94G [01:06<00:38, 53.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  68%|██████▊   | 3.07G/4.54G [01:06<00:27, 52.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  59%|█████▉    | 2.91G/4.94G [01:06<00:36, 55.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  68%|██████▊   | 3.09G/4.54G [01:07<00:27, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  68%|██████▊   | 3.10G/4.54G [01:07<00:27, 52.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  59%|█████▉    | 2.93G/4.94G [01:07<00:55, 36.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  69%|██████▊   | 3.12G/4.54G [01:07<00:28, 50.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  60%|█████▉    | 2.94G/4.94G [01:08<00:51, 38.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  69%|██████▉   | 3.14G/4.54G [01:08<00:27, 51.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  60%|█████▉    | 2.96G/4.94G [01:08<00:47, 41.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  69%|██████▉   | 3.15G/4.54G [01:08<00:26, 51.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  60%|██████    | 2.98G/4.94G [01:08<00:44, 43.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  70%|██████▉   | 3.17G/4.54G [01:08<00:26, 52.0MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  70%|███████   | 3.18G/4.54G [01:08<00:25, 52.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  61%|██████    | 2.99G/4.94G [01:09<00:43, 44.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  70%|███████   | 3.20G/4.54G [01:09<00:25, 52.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  61%|██████    | 3.01G/4.94G [01:09<00:44, 43.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  71%|███████   | 3.22G/4.54G [01:09<00:27, 48.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  61%|██████    | 3.02G/4.94G [01:09<00:42, 45.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  61%|██████▏   | 3.04G/4.94G [01:09<00:38, 49.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  71%|███████   | 3.23G/4.54G [01:10<00:28, 46.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  62%|██████▏   | 3.06G/4.94G [01:10<00:37, 50.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  72%|███████▏  | 3.25G/4.54G [01:10<00:27, 46.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  62%|██████▏   | 3.07G/4.94G [01:10<00:35, 52.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  72%|███████▏  | 3.26G/4.54G [01:10<00:25, 50.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  62%|██████▏   | 3.09G/4.94G [01:10<00:33, 54.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  72%|███████▏  | 3.28G/4.54G [01:10<00:24, 52.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  63%|██████▎   | 3.10G/4.94G [01:11<00:32, 56.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  73%|███████▎  | 3.30G/4.54G [01:11<00:23, 53.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  63%|██████▎   | 3.12G/4.94G [01:11<00:33, 54.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  73%|███████▎  | 3.31G/4.54G [01:11<00:23, 52.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  63%|██████▎   | 3.14G/4.94G [01:11<00:32, 55.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  73%|███████▎  | 3.33G/4.54G [01:11<00:21, 57.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  64%|██████▍   | 3.15G/4.94G [01:11<00:30, 58.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  74%|███████▎  | 3.34G/4.54G [01:12<00:21, 54.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  64%|██████▍   | 3.17G/4.94G [01:12<00:32, 55.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  74%|███████▍  | 3.36G/4.54G [01:12<00:21, 56.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  64%|██████▍   | 3.18G/4.94G [01:12<00:33, 52.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  74%|███████▍  | 3.38G/4.54G [01:12<00:19, 59.0MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  75%|███████▍  | 3.39G/4.54G [01:12<00:18, 60.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  65%|██████▍   | 3.20G/4.94G [01:12<00:31, 54.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  65%|██████▌   | 3.22G/4.94G [01:13<00:31, 54.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  75%|███████▌  | 3.41G/4.54G [01:13<00:20, 56.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  65%|██████▌   | 3.23G/4.94G [01:13<00:30, 55.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  75%|███████▌  | 3.42G/4.54G [01:13<00:20, 54.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  76%|███████▌  | 3.44G/4.54G [01:13<00:20, 54.2MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  76%|███████▌  | 3.46G/4.54G [01:14<00:26, 40.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  76%|███████▋  | 3.47G/4.54G [01:14<00:23, 45.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  77%|███████▋  | 3.49G/4.54G [01:14<00:21, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  77%|███████▋  | 3.50G/4.54G [01:15<00:20, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  78%|███████▊  | 3.52G/4.54G [01:15<00:19, 52.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  78%|███████▊  | 3.54G/4.54G [01:15<00:18, 53.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  78%|███████▊  | 3.55G/4.54G [01:16<00:18, 52.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  79%|███████▊  | 3.57G/4.54G [01:16<00:18, 52.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  79%|███████▉  | 3.58G/4.54G [01:16<00:17, 53.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  79%|███████▉  | 3.60G/4.54G [01:17<00:18, 50.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  80%|███████▉  | 3.62G/4.54G [01:17<00:18, 51.3MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  80%|███████▉  | 3.63G/4.54G [01:17<00:17, 50.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  80%|████████  | 3.65G/4.54G [01:17<00:17, 49.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  81%|████████  | 3.66G/4.54G [01:18<00:16, 53.0MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  81%|████████  | 3.68G/4.54G [01:18<00:15, 56.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  66%|██████▌   | 3.25G/4.94G [01:18<03:06, 9.08MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  66%|██████▌   | 3.26G/4.94G [01:18<02:37, 10.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  81%|████████▏ | 3.70G/4.54G [01:18<00:15, 54.9MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  82%|████████▏ | 3.71G/4.54G [01:19<00:16, 50.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  66%|██████▌   | 3.26G/4.94G [01:19<02:25, 11.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  82%|████████▏ | 3.73G/4.54G [01:19<00:15, 52.7MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  82%|████████▏ | 3.74G/4.54G [01:19<00:15, 51.5MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  83%|████████▎ | 3.76G/4.54G [01:20<00:14, 55.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  66%|██████▋   | 3.28G/4.94G [01:20<02:06, 13.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  83%|████████▎ | 3.78G/4.54G [01:20<00:14, 53.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  67%|██████▋   | 3.30G/4.94G [01:20<01:33, 17.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  67%|██████▋   | 3.31G/4.94G [01:20<01:10, 23.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  84%|████████▎ | 3.79G/4.54G [01:20<00:15, 49.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  67%|██████▋   | 3.33G/4.94G [01:20<00:55, 29.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  84%|████████▍ | 3.81G/4.54G [01:21<00:15, 47.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  68%|██████▊   | 3.34G/4.94G [01:21<00:46, 34.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  84%|████████▍ | 3.82G/4.54G [01:21<00:15, 47.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  68%|██████▊   | 3.36G/4.94G [01:21<00:40, 39.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  68%|██████▊   | 3.38G/4.94G [01:21<00:35, 44.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  85%|████████▍ | 3.84G/4.54G [01:22<00:18, 38.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  69%|██████▊   | 3.39G/4.94G [01:22<00:34, 45.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  85%|████████▍ | 3.86G/4.54G [01:22<00:15, 43.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  69%|██████▉   | 3.41G/4.94G [01:22<00:32, 47.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  85%|████████▌ | 3.87G/4.54G [01:22<00:14, 47.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  69%|██████▉   | 3.42G/4.94G [01:22<00:30, 50.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  86%|████████▌ | 3.89G/4.54G [01:22<00:13, 49.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  70%|██████▉   | 3.44G/4.94G [01:23<00:31, 47.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  86%|████████▌ | 3.90G/4.54G [01:23<00:13, 47.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  70%|██████▉   | 3.46G/4.94G [01:23<00:29, 50.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  86%|████████▋ | 3.92G/4.54G [01:23<00:11, 53.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  70%|███████   | 3.47G/4.94G [01:23<00:27, 54.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  87%|████████▋ | 3.94G/4.54G [01:23<00:10, 58.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  71%|███████   | 3.49G/4.94G [01:23<00:24, 59.1MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  87%|████████▋ | 3.95G/4.54G [01:24<00:11, 50.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  71%|███████   | 3.50G/4.94G [01:24<00:25, 55.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  87%|████████▋ | 3.97G/4.54G [01:24<00:10, 53.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  71%|███████   | 3.52G/4.94G [01:24<00:25, 56.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  88%|████████▊ | 3.98G/4.54G [01:24<00:09, 56.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  72%|███████▏  | 3.54G/4.94G [01:24<00:25, 54.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  88%|████████▊ | 4.00G/4.54G [01:24<00:10, 52.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  72%|███████▏  | 3.55G/4.94G [01:25<00:29, 46.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  88%|████████▊ | 4.02G/4.54G [01:25<00:09, 55.1MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  89%|████████▉ | 4.03G/4.54G [01:25<00:08, 57.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  72%|███████▏  | 3.57G/4.94G [01:25<00:29, 46.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  89%|████████▉ | 4.05G/4.54G [01:25<00:08, 56.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  73%|███████▎  | 3.58G/4.94G [01:25<00:27, 48.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  90%|████████▉ | 4.06G/4.54G [01:26<00:08, 55.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  73%|███████▎  | 3.60G/4.94G [01:26<00:25, 51.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  73%|███████▎  | 3.62G/4.94G [01:26<00:23, 56.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  90%|████████▉ | 4.08G/4.54G [01:26<00:08, 53.8MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  90%|█████████ | 4.10G/4.54G [01:26<00:07, 56.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  73%|███████▎  | 3.63G/4.94G [01:26<00:24, 54.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  91%|█████████ | 4.11G/4.54G [01:26<00:07, 58.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  74%|███████▍  | 3.65G/4.94G [01:27<00:26, 48.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  91%|█████████ | 4.13G/4.54G [01:27<00:07, 57.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  74%|███████▍  | 3.66G/4.94G [01:27<00:24, 52.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  91%|█████████▏| 4.14G/4.54G [01:27<00:06, 57.4MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  74%|███████▍  | 3.68G/4.94G [01:27<00:23, 54.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  92%|█████████▏| 4.16G/4.54G [01:27<00:07, 53.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  75%|███████▍  | 3.70G/4.94G [01:27<00:22, 56.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  75%|███████▌  | 3.71G/4.94G [01:28<00:20, 58.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  92%|█████████▏| 4.18G/4.54G [01:28<00:06, 53.5MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  75%|███████▌  | 3.73G/4.94G [01:28<00:20, 58.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  92%|█████████▏| 4.19G/4.54G [01:28<00:06, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  93%|█████████▎| 4.21G/4.54G [01:28<00:06, 54.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  76%|███████▌  | 3.74G/4.94G [01:28<00:21, 54.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  76%|███████▌  | 3.76G/4.94G [01:29<00:23, 50.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  93%|█████████▎| 4.22G/4.54G [01:29<00:06, 49.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  76%|███████▋  | 3.78G/4.94G [01:29<00:21, 53.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  93%|█████████▎| 4.24G/4.54G [01:29<00:06, 49.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  77%|███████▋  | 3.79G/4.94G [01:29<00:20, 55.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  94%|█████████▎| 4.26G/4.54G [01:29<00:05, 50.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  77%|███████▋  | 3.81G/4.94G [01:29<00:19, 57.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  94%|█████████▍| 4.27G/4.54G [01:29<00:05, 53.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  77%|███████▋  | 3.82G/4.94G [01:30<00:18, 59.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  94%|█████████▍| 4.29G/4.54G [01:30<00:04, 51.9MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  78%|███████▊  | 3.84G/4.94G [01:30<00:19, 57.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  95%|█████████▍| 4.30G/4.54G [01:30<00:04, 51.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  78%|███████▊  | 3.86G/4.94G [01:30<00:20, 52.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  95%|█████████▌| 4.32G/4.54G [01:30<00:04, 49.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  78%|███████▊  | 3.87G/4.94G [01:31<00:20, 52.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  79%|███████▊  | 3.89G/4.94G [01:31<00:18, 56.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  95%|█████████▌| 4.34G/4.54G [01:31<00:04, 42.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  79%|███████▉  | 3.90G/4.94G [01:31<00:17, 58.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  96%|█████████▌| 4.35G/4.54G [01:31<00:04, 46.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  79%|███████▉  | 3.92G/4.94G [01:31<00:18, 56.8MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  96%|█████████▌| 4.37G/4.54G [01:32<00:03, 46.6MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  80%|███████▉  | 3.94G/4.94G [01:32<00:21, 47.4MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  97%|█████████▋| 4.38G/4.54G [01:32<00:03, 48.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  80%|███████▉  | 3.95G/4.94G [01:32<00:20, 49.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  97%|█████████▋| 4.40G/4.54G [01:32<00:02, 51.1MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  80%|████████  | 3.97G/4.94G [01:32<00:19, 50.6MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  97%|█████████▋| 4.42G/4.54G [01:32<00:02, 50.8MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  81%|████████  | 3.98G/4.94G [01:33<00:16, 56.5MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  98%|█████████▊| 4.43G/4.54G [01:33<00:02, 52.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  81%|████████  | 4.00G/4.94G [01:33<00:16, 58.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  98%|█████████▊| 4.45G/4.54G [01:33<00:01, 54.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  81%|████████  | 4.02G/4.94G [01:33<00:17, 53.3MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  98%|█████████▊| 4.46G/4.54G [01:33<00:01, 54.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  82%|████████▏ | 4.03G/4.94G [01:34<00:17, 51.9MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  99%|█████████▊| 4.48G/4.54G [01:34<00:01, 49.0MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  82%|████████▏ | 4.05G/4.94G [01:34<00:16, 53.7MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  99%|█████████▉| 4.50G/4.54G [01:34<00:00, 51.3MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  82%|████████▏ | 4.06G/4.94G [01:34<00:15, 55.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  83%|████████▎ | 4.08G/4.94G [01:34<00:15, 57.2MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors:  99%|█████████▉| 4.51G/4.54G [01:34<00:00, 43.7MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00001-of-00003.safetensors:  83%|████████▎ | 4.10G/4.94G [01:35<00:14, 57.0MB/s]\u001b[A\n\n\nmodel-00003-of-00003.safetensors: 100%|█████████▉| 4.53G/4.54G [01:35<00:00, 46.2MB/s]\u001b[A\u001b[A\u001b[A\nmodel-00003-of-00003.safetensors: 100%|██████████| 4.54G/4.54G [01:35<00:00, 47.5MB/s]\u001b[A\n\nmodel-00001-of-00003.safetensors:  84%|████████▎ | 4.13G/4.94G [01:35<00:15, 53.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  84%|████████▍ | 4.14G/4.94G [01:36<00:14, 54.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  84%|████████▍ | 4.16G/4.94G [01:36<00:13, 56.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  84%|████████▍ | 4.18G/4.94G [01:36<00:15, 50.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  85%|████████▍ | 4.19G/4.94G [01:37<00:15, 49.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  85%|████████▌ | 4.21G/4.94G [01:37<00:14, 50.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  85%|████████▌ | 4.22G/4.94G [01:37<00:14, 48.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  86%|████████▌ | 4.24G/4.94G [01:37<00:13, 51.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  86%|████████▌ | 4.26G/4.94G [01:38<00:12, 53.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  86%|████████▋ | 4.27G/4.94G [01:38<00:14, 45.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  87%|████████▋ | 4.29G/4.94G [01:38<00:13, 49.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  87%|████████▋ | 4.30G/4.94G [01:39<00:12, 50.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  87%|████████▋ | 4.32G/4.94G [01:39<00:16, 37.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  88%|████████▊ | 4.34G/4.94G [01:40<00:15, 39.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  88%|████████▊ | 4.35G/4.94G [01:40<00:12, 45.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  88%|████████▊ | 4.37G/4.94G [01:40<00:11, 49.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  89%|████████▊ | 4.38G/4.94G [01:41<00:11, 49.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  89%|████████▉ | 4.40G/4.94G [01:41<00:10, 53.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  89%|████████▉ | 4.42G/4.94G [01:41<00:10, 50.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  90%|████████▉ | 4.43G/4.94G [01:41<00:09, 53.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  90%|████████▉ | 4.45G/4.94G [01:42<00:09, 51.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  90%|█████████ | 4.46G/4.94G [01:42<00:08, 57.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  91%|█████████ | 4.48G/4.94G [01:42<00:08, 57.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  91%|█████████ | 4.50G/4.94G [01:43<00:08, 51.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  91%|█████████▏| 4.51G/4.94G [01:43<00:08, 53.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  92%|█████████▏| 4.53G/4.94G [01:43<00:07, 53.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  92%|█████████▏| 4.54G/4.94G [01:44<00:07, 55.0MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  92%|█████████▏| 4.56G/4.94G [01:44<00:06, 55.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  93%|█████████▎| 4.58G/4.94G [01:44<00:06, 58.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  93%|█████████▎| 4.59G/4.94G [01:44<00:06, 57.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  93%|█████████▎| 4.61G/4.94G [01:46<00:17, 19.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  93%|█████████▎| 4.62G/4.94G [01:47<00:14, 22.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  94%|█████████▎| 4.62G/4.94G [01:47<00:13, 24.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  94%|█████████▍| 4.64G/4.94G [01:47<00:12, 23.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  94%|█████████▍| 4.66G/4.94G [01:48<00:09, 30.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  95%|█████████▍| 4.67G/4.94G [01:48<00:07, 35.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  95%|█████████▍| 4.69G/4.94G [01:48<00:06, 40.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  95%|█████████▌| 4.70G/4.94G [01:49<00:05, 46.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  95%|█████████▌| 4.72G/4.94G [01:49<00:04, 49.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  96%|█████████▌| 4.74G/4.94G [01:49<00:04, 51.5MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  96%|█████████▌| 4.75G/4.94G [01:49<00:03, 54.6MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  96%|█████████▋| 4.77G/4.94G [01:50<00:03, 53.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  97%|█████████▋| 4.78G/4.94G [01:50<00:03, 52.7MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  97%|█████████▋| 4.80G/4.94G [01:50<00:02, 55.3MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  97%|█████████▋| 4.82G/4.94G [01:51<00:02, 55.1MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  98%|█████████▊| 4.83G/4.94G [01:51<00:01, 58.4MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  98%|█████████▊| 4.85G/4.94G [01:51<00:01, 54.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  98%|█████████▊| 4.86G/4.94G [01:51<00:01, 56.2MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  99%|█████████▊| 4.88G/4.94G [01:52<00:01, 58.8MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  99%|█████████▉| 4.90G/4.94G [01:52<00:00, 61.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors:  99%|█████████▉| 4.91G/4.94G [01:52<00:00, 44.9MB/s]\u001b[A\nmodel-00001-of-00003.safetensors: 100%|██████████| 4.94G/4.94G [01:53<00:00, 43.4MB/s]\u001b[A\n'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/dc/53/dc534182134213703e0cfb31e9335b832cf4535a059fa087fbc24c70310f6ef4/26b18d5d207afd2257427cfa2a7f5f041bea575b77113855a25faae88d82c408?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240118T195213Z&X-Amz-Expires=86400&X-Amz-Signature=181f93c00bde1637d3b3077cc77de9cead956dcdd2cbbcda54466144b0354aa9&X-Amz-SignedHeaders=host&partNumber=1&uploadId=oBp_AZAy0F4B.076RvznWYdNNyKz_9lus1t8.rnNdbWXUj_Ff2KvBb4zi2ONo.PkoQfMz3TwqnZdiVAIcArD_zjw6iUVaeb8i0rodLrQL.wTx2136kTPWGt2.9C089lg&x-id=UploadPart (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7974ea067040>, 'Connection to hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com timed out. (connect timeout=None)'))\"), '(Request ID: e939707b-7452-4071-b0b2-66774faa3045)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/dc/53/dc534182134213703e0cfb31e9335b832cf4535a059fa087fbc24c70310f6ef4/26b18d5d207afd2257427cfa2a7f5f041bea575b77113855a25faae88d82c408?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240118T195213Z&X-Amz-Expires=86400&X-Amz-Signature=181f93c00bde1637d3b3077cc77de9cead956dcdd2cbbcda54466144b0354aa9&X-Amz-SignedHeaders=host&partNumber=1&uploadId=oBp_AZAy0F4B.076RvznWYdNNyKz_9lus1t8.rnNdbWXUj_Ff2KvBb4zi2ONo.PkoQfMz3TwqnZdiVAIcArD_zjw6iUVaeb8i0rodLrQL.wTx2136kTPWGt2.9C089lg&x-id=UploadPart\nWARNING:huggingface_hub.utils._http:'(MaxRetryError(\"HTTPSConnectionPool(host='hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com', port=443): Max retries exceeded with url: /repos/dc/53/dc534182134213703e0cfb31e9335b832cf4535a059fa087fbc24c70310f6ef4/26b18d5d207afd2257427cfa2a7f5f041bea575b77113855a25faae88d82c408?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240118T195213Z&X-Amz-Expires=86400&X-Amz-Signature=181f93c00bde1637d3b3077cc77de9cead956dcdd2cbbcda54466144b0354aa9&X-Amz-SignedHeaders=host&partNumber=1&uploadId=oBp_AZAy0F4B.076RvznWYdNNyKz_9lus1t8.rnNdbWXUj_Ff2KvBb4zi2ONo.PkoQfMz3TwqnZdiVAIcArD_zjw6iUVaeb8i0rodLrQL.wTx2136kTPWGt2.9C089lg&x-id=UploadPart (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7974ea067040>, 'Connection to hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com timed out. (connect timeout=None)'))\"), '(Request ID: e939707b-7452-4071-b0b2-66774faa3045)')' thrown while requesting PUT https://hf-hub-lfs-us-east-1.s3-accelerate.amazonaws.com/repos/dc/53/dc534182134213703e0cfb31e9335b832cf4535a059fa087fbc24c70310f6ef4/26b18d5d207afd2257427cfa2a7f5f041bea575b77113855a25faae88d82c408?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=AKIA2JU7TKAQFN2FTF47%2F20240118%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240118T195213Z&X-Amz-Expires=86400&X-Amz-Signature=181f93c00bde1637d3b3077cc77de9cead956dcdd2cbbcda54466144b0354aa9&X-Amz-SignedHeaders=host&partNumber=1&uploadId=oBp_AZAy0F4B.076RvznWYdNNyKz_9lus1t8.rnNdbWXUj_Ff2KvBb4zi2ONo.PkoQfMz3TwqnZdiVAIcArD_zjw6iUVaeb8i0rodLrQL.wTx2136kTPWGt2.9C089lg&x-id=UploadPart\nRetrying in 1s [Retry 1/5].\nWARNING:huggingface_hub.utils._http:Retrying in 1s [Retry 1/5].\nmodel-00002-of-00003.safetensors: 100%|██████████| 5.00G/5.00G [03:53<00:00, 21.4MB/s]    \n\n\nUpload 3 LFS files: 100%|██████████| 3/3 [03:53<00:00, 77.93s/it] \u001b[A\u001b[A\ntokenizer.model: 100%|██████████| 493k/493k [00:00<00:00, 1.42MB/s]\n","output_type":"stream"},{"execution_count":73,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/hotamago/HotaMath-OpenMath-2023-01-18-ElementaryMathematics/commit/282d04db95504f55b78e73081d8ef57f82375ec9', commit_message='Upload tokenizer', commit_description='', oid='282d04db95504f55b78e73081d8ef57f82375ec9', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"# !apt-get update","metadata":{"execution":{"iopub.status.busy":"2023-12-24T07:38:52.903945Z","iopub.execute_input":"2023-12-24T07:38:52.904193Z","iopub.status.idle":"2023-12-24T07:38:52.907233Z","shell.execute_reply.started":"2023-12-24T07:38:52.904168Z","shell.execute_reply":"2023-12-24T07:38:52.906615Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"code","source":"# !apt-get install sudo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r BK-BigAI-Math.zip BK-BigAI-Math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'BK-BigAI-Math.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks(r'BK-BigAI-Math')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T12:44:19.866645Z","iopub.execute_input":"2024-01-01T12:44:19.866923Z","iopub.status.idle":"2024-01-01T12:44:19.872653Z","shell.execute_reply.started":"2024-01-01T12:44:19.866894Z","shell.execute_reply":"2024-01-01T12:44:19.871661Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"BK-BigAI-Math/\n  special_tokens_map.json\n  model-00003-of-00003.safetensors\n  model-00002-of-00003.safetensors\n  added_tokens.json\n  model.safetensors.index.json\n  model-00001-of-00003.safetensors\n  tokenizer_config.json\n  tokenizer.model\n  config.json","text/html":"BK-BigAI-Math/<br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/special_tokens_map.json' target='_blank'>special_tokens_map.json</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/model-00003-of-00003.safetensors' target='_blank'>model-00003-of-00003.safetensors</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/model-00002-of-00003.safetensors' target='_blank'>model-00002-of-00003.safetensors</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/added_tokens.json' target='_blank'>added_tokens.json</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/model.safetensors.index.json' target='_blank'>model.safetensors.index.json</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/model-00001-of-00003.safetensors' target='_blank'>model-00001-of-00003.safetensors</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/tokenizer_config.json' target='_blank'>tokenizer_config.json</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/tokenizer.model' target='_blank'>tokenizer.model</a><br>\n&nbsp;&nbsp;<a href='BK-BigAI-Math/config.json' target='_blank'>config.json</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"import time\ni = 0\nwhile 1:\n    time.sleep(1)\n    i += 1\n    print(\"time: \" + str(i))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-01T12:52:49.136837Z","iopub.execute_input":"2024-01-01T12:52:49.137180Z","iopub.status.idle":"2024-01-01T13:02:26.812261Z","shell.execute_reply.started":"2024-01-01T12:52:49.137150Z","shell.execute_reply":"2024-01-01T13:02:26.811158Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"time: 1\ntime: 2\ntime: 3\ntime: 4\ntime: 5\ntime: 6\ntime: 7\ntime: 8\ntime: 9\ntime: 10\ntime: 11\ntime: 12\ntime: 13\ntime: 14\ntime: 15\ntime: 16\ntime: 17\ntime: 18\ntime: 19\ntime: 20\ntime: 21\ntime: 22\ntime: 23\ntime: 24\ntime: 25\ntime: 26\ntime: 27\ntime: 28\ntime: 29\ntime: 30\ntime: 31\ntime: 32\ntime: 33\ntime: 34\ntime: 35\ntime: 36\ntime: 37\ntime: 38\ntime: 39\ntime: 40\ntime: 41\ntime: 42\ntime: 43\ntime: 44\ntime: 45\ntime: 46\ntime: 47\ntime: 48\ntime: 49\ntime: 50\ntime: 51\ntime: 52\ntime: 53\ntime: 54\ntime: 55\ntime: 56\ntime: 57\ntime: 58\ntime: 59\ntime: 60\ntime: 61\ntime: 62\ntime: 63\ntime: 64\ntime: 65\ntime: 66\ntime: 67\ntime: 68\ntime: 69\ntime: 70\ntime: 71\ntime: 72\ntime: 73\ntime: 74\ntime: 75\ntime: 76\ntime: 77\ntime: 78\ntime: 79\ntime: 80\ntime: 81\ntime: 82\ntime: 83\ntime: 84\ntime: 85\ntime: 86\ntime: 87\ntime: 88\ntime: 89\ntime: 90\ntime: 91\ntime: 92\ntime: 93\ntime: 94\ntime: 95\ntime: 96\ntime: 97\ntime: 98\ntime: 99\ntime: 100\ntime: 101\ntime: 102\ntime: 103\ntime: 104\ntime: 105\ntime: 106\ntime: 107\ntime: 108\ntime: 109\ntime: 110\ntime: 111\ntime: 112\ntime: 113\ntime: 114\ntime: 115\ntime: 116\ntime: 117\ntime: 118\ntime: 119\ntime: 120\ntime: 121\ntime: 122\ntime: 123\ntime: 124\ntime: 125\ntime: 126\ntime: 127\ntime: 128\ntime: 129\ntime: 130\ntime: 131\ntime: 132\ntime: 133\ntime: 134\ntime: 135\ntime: 136\ntime: 137\ntime: 138\ntime: 139\ntime: 140\ntime: 141\ntime: 142\ntime: 143\ntime: 144\ntime: 145\ntime: 146\ntime: 147\ntime: 148\ntime: 149\ntime: 150\ntime: 151\ntime: 152\ntime: 153\ntime: 154\ntime: 155\ntime: 156\ntime: 157\ntime: 158\ntime: 159\ntime: 160\ntime: 161\ntime: 162\ntime: 163\ntime: 164\ntime: 165\ntime: 166\ntime: 167\ntime: 168\ntime: 169\ntime: 170\ntime: 171\ntime: 172\ntime: 173\ntime: 174\ntime: 175\ntime: 176\ntime: 177\ntime: 178\ntime: 179\ntime: 180\ntime: 181\ntime: 182\ntime: 183\ntime: 184\ntime: 185\ntime: 186\ntime: 187\ntime: 188\ntime: 189\ntime: 190\ntime: 191\ntime: 192\ntime: 193\ntime: 194\ntime: 195\ntime: 196\ntime: 197\ntime: 198\ntime: 199\ntime: 200\ntime: 201\ntime: 202\ntime: 203\ntime: 204\ntime: 205\ntime: 206\ntime: 207\ntime: 208\ntime: 209\ntime: 210\ntime: 211\ntime: 212\ntime: 213\ntime: 214\ntime: 215\ntime: 216\ntime: 217\ntime: 218\ntime: 219\ntime: 220\ntime: 221\ntime: 222\ntime: 223\ntime: 224\ntime: 225\ntime: 226\ntime: 227\ntime: 228\ntime: 229\ntime: 230\ntime: 231\ntime: 232\ntime: 233\ntime: 234\ntime: 235\ntime: 236\ntime: 237\ntime: 238\ntime: 239\ntime: 240\ntime: 241\ntime: 242\ntime: 243\ntime: 244\ntime: 245\ntime: 246\ntime: 247\ntime: 248\ntime: 249\ntime: 250\ntime: 251\ntime: 252\ntime: 253\ntime: 254\ntime: 255\ntime: 256\ntime: 257\ntime: 258\ntime: 259\ntime: 260\ntime: 261\ntime: 262\ntime: 263\ntime: 264\ntime: 265\ntime: 266\ntime: 267\ntime: 268\ntime: 269\ntime: 270\ntime: 271\ntime: 272\ntime: 273\ntime: 274\ntime: 275\ntime: 276\ntime: 277\ntime: 278\ntime: 279\ntime: 280\ntime: 281\ntime: 282\ntime: 283\ntime: 284\ntime: 285\ntime: 286\ntime: 287\ntime: 288\ntime: 289\ntime: 290\ntime: 291\ntime: 292\ntime: 293\ntime: 294\ntime: 295\ntime: 296\ntime: 297\ntime: 298\ntime: 299\ntime: 300\ntime: 301\ntime: 302\ntime: 303\ntime: 304\ntime: 305\ntime: 306\ntime: 307\ntime: 308\ntime: 309\ntime: 310\ntime: 311\ntime: 312\ntime: 313\ntime: 314\ntime: 315\ntime: 316\ntime: 317\ntime: 318\ntime: 319\ntime: 320\ntime: 321\ntime: 322\ntime: 323\ntime: 324\ntime: 325\ntime: 326\ntime: 327\ntime: 328\ntime: 329\ntime: 330\ntime: 331\ntime: 332\ntime: 333\ntime: 334\ntime: 335\ntime: 336\ntime: 337\ntime: 338\ntime: 339\ntime: 340\ntime: 341\ntime: 342\ntime: 343\ntime: 344\ntime: 345\ntime: 346\ntime: 347\ntime: 348\ntime: 349\ntime: 350\ntime: 351\ntime: 352\ntime: 353\ntime: 354\ntime: 355\ntime: 356\ntime: 357\ntime: 358\ntime: 359\ntime: 360\ntime: 361\ntime: 362\ntime: 363\ntime: 364\ntime: 365\ntime: 366\ntime: 367\ntime: 368\ntime: 369\ntime: 370\ntime: 371\ntime: 372\ntime: 373\ntime: 374\ntime: 375\ntime: 376\ntime: 377\ntime: 378\ntime: 379\ntime: 380\ntime: 381\ntime: 382\ntime: 383\ntime: 384\ntime: 385\ntime: 386\ntime: 387\ntime: 388\ntime: 389\ntime: 390\ntime: 391\ntime: 392\ntime: 393\ntime: 394\ntime: 395\ntime: 396\ntime: 397\ntime: 398\ntime: 399\ntime: 400\ntime: 401\ntime: 402\ntime: 403\ntime: 404\ntime: 405\ntime: 406\ntime: 407\ntime: 408\ntime: 409\ntime: 410\ntime: 411\ntime: 412\ntime: 413\ntime: 414\ntime: 415\ntime: 416\ntime: 417\ntime: 418\ntime: 419\ntime: 420\ntime: 421\ntime: 422\ntime: 423\ntime: 424\ntime: 425\ntime: 426\ntime: 427\ntime: 428\ntime: 429\ntime: 430\ntime: 431\ntime: 432\ntime: 433\ntime: 434\ntime: 435\ntime: 436\ntime: 437\ntime: 438\ntime: 439\ntime: 440\ntime: 441\ntime: 442\ntime: 443\ntime: 444\ntime: 445\ntime: 446\ntime: 447\ntime: 448\ntime: 449\ntime: 450\ntime: 451\ntime: 452\ntime: 453\ntime: 454\ntime: 455\ntime: 456\ntime: 457\ntime: 458\ntime: 459\ntime: 460\ntime: 461\ntime: 462\ntime: 463\ntime: 464\ntime: 465\ntime: 466\ntime: 467\ntime: 468\ntime: 469\ntime: 470\ntime: 471\ntime: 472\ntime: 473\ntime: 474\ntime: 475\ntime: 476\ntime: 477\ntime: 478\ntime: 479\ntime: 480\ntime: 481\ntime: 482\ntime: 483\ntime: 484\ntime: 485\ntime: 486\ntime: 487\ntime: 488\ntime: 489\ntime: 490\ntime: 491\ntime: 492\ntime: 493\ntime: 494\ntime: 495\ntime: 496\ntime: 497\ntime: 498\ntime: 499\ntime: 500\ntime: 501\ntime: 502\ntime: 503\ntime: 504\ntime: 505\ntime: 506\ntime: 507\ntime: 508\ntime: 509\ntime: 510\ntime: 511\ntime: 512\ntime: 513\ntime: 514\ntime: 515\ntime: 516\ntime: 517\ntime: 518\ntime: 519\ntime: 520\ntime: 521\ntime: 522\ntime: 523\ntime: 524\ntime: 525\ntime: 526\ntime: 527\ntime: 528\ntime: 529\ntime: 530\ntime: 531\ntime: 532\ntime: 533\ntime: 534\ntime: 535\ntime: 536\ntime: 537\ntime: 538\ntime: 539\ntime: 540\ntime: 541\ntime: 542\ntime: 543\ntime: 544\ntime: 545\ntime: 546\ntime: 547\ntime: 548\ntime: 549\ntime: 550\ntime: 551\ntime: 552\ntime: 553\ntime: 554\ntime: 555\ntime: 556\ntime: 557\ntime: 558\ntime: 559\ntime: 560\ntime: 561\ntime: 562\ntime: 563\ntime: 564\ntime: 565\ntime: 566\ntime: 567\ntime: 568\ntime: 569\ntime: 570\ntime: 571\ntime: 572\ntime: 573\ntime: 574\ntime: 575\ntime: 576\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[71], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime: \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(i))\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"## Evalution","metadata":{}},{"cell_type":"markdown","source":"### Download model","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023-Model\", filename=\"Hota-Math.zip\", repo_type=\"model\", local_dir=\"/kaggle/working/\", local_dir_use_symlinks=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q -o Hota-Math.zip -d ./","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### load model by GPU","metadata":{}},{"cell_type":"code","source":"dataset = Dataset.from_dict(dataset)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:25.612426Z","iopub.execute_input":"2024-01-19T07:52:25.613072Z","iopub.status.idle":"2024-01-19T07:52:26.048407Z","shell.execute_reply.started":"2024-01-19T07:52:25.613035Z","shell.execute_reply":"2024-01-19T07:52:26.047351Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model_name_or_path = \"hotamago/HotaMath-OpenMath-2023-01-18-ElementaryMathematics\"\n# model_name_or_path = \"hotamago/xDAN-AI-HotaMath\"\n\n# bnb_config = BitsAndBytesConfig(  \n#     load_in_4bit= True,\n#     bnb_4bit_quant_type= \"nf4\",\n#     bnb_4bit_compute_dtype= torch.bfloat16,\n#     bnb_4bit_use_double_quant= False,\n# )\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name_or_path,\n#     torch_dtype=torch.bfloat16,\n    torch_dtype=torch.float16,\n#     quantization_config=bnb_config,\n    device_map=\"auto\",\n    trust_remote_code=True,\n#     load_in_4bit=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:52:29.724540Z","iopub.execute_input":"2024-01-19T07:52:29.725227Z","iopub.status.idle":"2024-01-19T07:58:07.345787Z","shell.execute_reply.started":"2024-01-19T07:52:29.725192Z","shell.execute_reply":"2024-01-19T07:58:07.344741Z"},"trusted":true},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dba1751029a849b9b503c8475f16f33a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dccfca3603b94dd1a6bdc7c14d5ecff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc77193578c04c9d9016695eb38a5536"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1a74734e62c4131a86f623fb8407ec2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e75ba6ce65df4ec1ae02be2a666a5736"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"057e5321cbaa466f947a5032e0cde3fc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b20b812b73e0465fb6458303b5c415ad"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_name_or_path,\n    model_max_length=1024,\n    padding_side=\"right\",\n#     use_fast=True,\n    trust_remote_code=True\n)\ntokenizer.pad_token_id = tokenizer.eos_token_id\n# tokenizer.pad_token = \"[PAD]\"\n# 28705","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:07.347747Z","iopub.execute_input":"2024-01-19T07:58:07.348169Z","iopub.status.idle":"2024-01-19T07:58:08.733005Z","shell.execute_reply.started":"2024-01-19T07:58:07.348131Z","shell.execute_reply":"2024-01-19T07:58:08.732051Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.96k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a34e53ae30ee4ba49b1c6f02815c66cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f8376ea5604472081e95f1d84f7a18a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/92.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d60e1343866f481fb7d07d29f8158a7e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/885 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50728137631c4e8e819fdecba134162d"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer.special_tokens_map","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.734555Z","iopub.execute_input":"2024-01-19T07:58:08.735272Z","iopub.status.idle":"2024-01-19T07:58:08.741442Z","shell.execute_reply.started":"2024-01-19T07:58:08.735223Z","shell.execute_reply":"2024-01-19T07:58:08.740545Z"},"trusted":true},"execution_count":42,"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"{'bos_token': '<s>',\n 'eos_token': '<|end_of_turn|>',\n 'unk_token': '<unk>',\n 'pad_token': '<|end_of_turn|>',\n 'additional_special_tokens': ['[INST]', '[/INST]']}"},"metadata":{}}]},{"cell_type":"code","source":"model.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.743514Z","iopub.execute_input":"2024-01-19T07:58:08.743803Z","iopub.status.idle":"2024-01-19T07:58:08.762035Z","shell.execute_reply.started":"2024-01-19T07:58:08.743769Z","shell.execute_reply":"2024-01-19T07:58:08.761074Z"},"trusted":true},"execution_count":43,"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"Embedding(32004, 4096)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Init function evalution","metadata":{}},{"cell_type":"code","source":"from transformers import pipeline","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.763039Z","iopub.execute_input":"2024-01-19T07:58:08.763317Z","iopub.status.idle":"2024-01-19T07:58:08.771657Z","shell.execute_reply.started":"2024-01-19T07:58:08.763294Z","shell.execute_reply":"2024-01-19T07:58:08.770841Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"pipeGenEx = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n#     do_sample=False,\n    do_sample=True,\n    temperature=0.01,\n    top_p=1.0,\n    top_k=60,\n#     repetition_penalty=1.1,\n    pad_token_id=tokenizer.eos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\npipeGenExStick = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n    do_sample=True,\n    temperature=0.01,\n    top_p=1.0,\n#     top_k=50,\n    repetition_penalty=1.3,\n    pad_token_id=tokenizer.eos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\npipeGenAns = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n#     do_sample=False,\n    do_sample=True,\n    temperature=0.01,\n    top_p=1.0,\n    top_k=60,\n#     repetition_penalty=1.1,\n    pad_token_id=tokenizer.eos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\npipeGenAnsStick = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n    do_sample=True,\n    temperature=0.01,\n    top_p=1.0,\n#     top_k=80,\n    repetition_penalty=1.3,\n    pad_token_id=tokenizer.eos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)\n\npipeGenFull = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=1024,\n    do_sample=True,\n    temperature=0.01,\n    top_p=1.0,\n#     top_k=40,\n#     top_p=0.4,\n#     top_k=40,\n#     repetition_penalty=1.3,\n    pad_token_id=tokenizer.eos_token_id,\n    eos_token_id=tokenizer.eos_token_id,\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.773062Z","iopub.execute_input":"2024-01-19T07:58:08.773407Z","iopub.status.idle":"2024-01-19T07:58:08.784945Z","shell.execute_reply.started":"2024-01-19T07:58:08.773375Z","shell.execute_reply":"2024-01-19T07:58:08.784184Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"import random\n# globalRegxCompire = \"0-9a-zA-Z\\.\\:\\-\\^\\! \"\ndef niceValueToCompire(x):\n#     x = re.sub(\"[^{0}]\".format(globalRegxCompire), \"\", x)\n#     x = re.sub(\"[ \\t\\n]\", \"\", x)\n#     x = re.sub(\"[ \\t\\n]\", \"\", x)\n    y = re.findall(\"^[\\n ]*([a-z])\\. ?\", x.strip().lower())\n    if len(y) == 0:\n        return x.strip().lower()\n    return y[0].strip()\n\ndef autoLLMFormatExpVsFormula(inp, debug=False):\n#     print(inp)\n    prompt_template = ApplyPromptTemplate({\n        \"question\": inp['question'],\n        \"choices\": \"\\n\".join(inp['choices'])\n    }, \"prompt_formula_run\")\n    \n    res = pipeGenEx(prompt_template)[0]['generated_text']\n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n    \n    if len(x) == 0:\n        res = pipeGenExStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n\n    if len(x) == 0:\n        print(\"## Res:\\n{0}\".format(res))\n        return False, None, None\n    \n    return True, x[-1][0], x[-1][1]\n\ndef autoLLMFormatExpVsFormulaPrev(inp, prevExplanation, prevFormula, debug=False):\n#     print(inp)\n    try:\n        outformula = eval(prevFormula)\n    except Exception as ist:\n        outformula = \"Invail expression: {0}\".format(str(ist))\n        \n    prompt_template = ApplyPromptTemplate({\n        \"question\": inp['question'],\n        \"choices\": \"\\n\".join(inp['choices']),\n        \"explanation\": prevExplanation,\n        \"formula\": prevFormula,\n        \"outformula\": outformula,\n    }, \"prompt_formula_run_previous\")\n    \n    res = pipeGenEx(prompt_template)[0]['generated_text']\n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n    \n    if len(x) == 0:\n        res = pipeGenExStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n\n    if len(x) == 0:\n        print(\"## Res:\\n{0}\".format(res))\n        return False, None, None\n    \n    return True, x[-1][0], x[-1][1]\n\ndef autoLLMFormatAnswer(inp, debug=False):\n    # init random choice\n    question, choices = inp['question'], inp['choices']\n    randomAnswer = choices[random.randrange(0, len(choices))]\n    \n    # Run get first formula\n    ok, explanation, formula = autoLLMFormatExpVsFormula(inp, debug=debug)\n    \n    if ok == False:\n        print(f\"Error, no 01: {inp}\")\n        return randomAnswer\n\n    # Run get n prev formula\n    for i in range(3):\n        ok, explanation, formula = autoLLMFormatExpVsFormulaPrev(inp, explanation, formula, debug=debug)\n        if ok == False:\n            print(f\"Error, no 01: {inp}\")\n            return randomAnswer\n        \n    \n    formula = formula.strip()\n    \n    try:\n        outformula = eval(formula)\n    except Exception as ist:\n        outformula = \"Invail expression\"\n        print(ist)\n        \n    prompt_template = ApplyPromptTemplate({\n        \"question\": question,\n        \"choices\": \"\\n\".join(choices),\n        \"explanation\": explanation,\n        \"formula\": formula,\n        \"outformula\": outformula,\n    }, \"prompt_input_run\")\n#     print(\"WTF: {0}\".format(prompt_template))\n    res = pipeGenAns(prompt_template)[0]['generated_text']\n    \n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số|[Tt]he answer)(?:.*):?[\\n ](.+)\", res)\n    \n    if len(x) < 1:\n        res = pipeGenAnsStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số|[Tt]he answer)(?:.*):?[\\n ](.+)\", res)\n    \n    choices_compare = [niceValueToCompire(choice_pred) for choice_pred in choices]\n\n    if len(x) < 1:\n        print(\"Error, no Answer 1: {0}\".format(res))\n#         raise Exception(\"Error, no Answer 1\")\n        return randomAnswer\n    \n    x = niceValueToCompire(x[-1])\n    \n    if x is None:\n        print(\"Error, no Answer 2: {0}\".format(res))\n#         raise Exception(\"Error, no Answer 2\")\n        return randomAnswer\n    \n    if (x not in choices_compare):\n        print(\"Error, no Answer in choices: {0}\\n{1}\\n{2}\".format(res, choices_compare, x))\n#         raise Exception(\"Error, no Answer in choices\")\n        return randomAnswer\n    \n    for i in range(len(choices_compare)):\n        if x == choices_compare[i]:\n            return x\n#             return choices[i]\n    \n    return \"wtf\"\n\ndef autoLLMFull(inp, debug=False):\n    question, choices = inp['question'], inp['choices']\n    prompt_template = ApplyPromptTemplate({\n        \"question\": question,\n        \"choices\": \"\\n\".join(choices),\n    }, \"prompt_full_run\")\n    res = pipeGenFull(prompt_template)[0]['generated_text']\n    \n    randomAnswer = choices[random.randrange(0, len(choices))]\n    \n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số)(?:.*):?[\\n ](.+)\", res)\n    \n    if len(x) < 1:\n        res = pipeGenAnsStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số|[Tt]he answer)(?:.*):?[\\n ](.+)\", res)\n    \n    choices_compare = [niceValueToCompire(choice_pred) for choice_pred in choices]\n\n    if len(x) < 1:\n        print(\"Error, no Answer 1: {0}\".format(res))\n#         raise Exception(\"Error, no Answer 1\")\n        return randomAnswer\n    \n    x = niceValueToCompire(x[0])\n    \n    if x is None:\n        print(\"Error, no Answer 2: {0}\".format(res))\n#         raise Exception(\"Error, no Answer 2\")\n        return randomAnswer\n    \n    if (x not in choices_compare):\n        print(\"Error, no Answer in choices: {0}\\n{1}\\n{2}\".format(res, choices_compare, x))\n#         raise Exception(\"Error, no Answer in choices\")\n        return randomAnswer\n    \n    for i in range(len(choices_compare)):\n        if x == choices_compare[i]:\n            return x\n#             return choices[i]\n    \n    return \"wtf\"","metadata":{"execution":{"iopub.status.busy":"2024-01-09T13:38:34.635902Z","iopub.execute_input":"2024-01-09T13:38:34.636268Z","iopub.status.idle":"2024-01-09T13:38:34.663338Z","shell.execute_reply.started":"2024-01-09T13:38:34.636239Z","shell.execute_reply":"2024-01-09T13:38:34.662556Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Implement\nimport random\n\ndef niceValueToCompire(x):\n    y = re.findall(\"^[\\n ]*([a-z])\\. ?\", x.strip().lower())\n    if len(y) == 0:\n        return x.strip().lower()\n    return y[0].strip()\n\ndef autoLLMFormatExpVsFormula_i(inp, debug=False):\n    prompt_template = ApplyPromptTemplate({\n        \"question\": inp['question'],\n    }, \"prompt_formula_run_i\")\n    \n    res = pipeGenEx(prompt_template)[0]['generated_text']\n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n    \n    if len(x) == 0:\n        res = pipeGenExStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n\n    if len(x) == 0:\n        print(\"## Res:\\n{0}\".format(res))\n        return False, None, None\n    \n    return True, x[-1][0], x[-1][1]\n\ndef autoLLMFormatExpVsFormulaPrev_i(inp, prevExplanation, prevFormula, debug=False):\n#     print(inp)\n    try:\n        outformula = eval(prevFormula)\n    except Exception as ist:\n        outformula = \"Invail expression: {0}\".format(str(ist))\n        \n    prompt_template = ApplyPromptTemplate({\n        \"question\": inp['question'],\n        \"explanation\": prevExplanation,\n        \"formula\": prevFormula,\n        \"outformula\": outformula,\n    }, \"prompt_formula_run_previous_i\")\n    \n    res = pipeGenEx(prompt_template)[0]['generated_text']\n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n    \n    if len(x) == 0:\n        res = pipeGenExStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*[Ee]xplanation(?:.*):?\\n([\\s\\S]*?)\\n\\n##[ ]*[Ee]xpression(?:.*):?\\n(.*)\", res)\n\n    if len(x) == 0:\n        print(\"## Res:\\n{0}\".format(res))\n        return False, None, None\n    \n    return True, x[-1][0], x[-1][1]\n\ndef autoLLMFormatAnswer_i(inp, debug=False):\n    # init random choice\n    question = inp['question']\n    \n    # Run get first formula\n    ok, explanation, formula = autoLLMFormatExpVsFormula_i(inp, debug=debug)\n    \n    if ok == False:\n        print(f\"Error, no 01: {inp}\")\n\n    # Run get n prev formula\n    for i in range(1):\n        ok, explanation, formula = autoLLMFormatExpVsFormulaPrev_i(inp, explanation, formula, debug=debug)\n        if ok == False:\n            print(f\"Error, no 01: {inp}\")\n    \n    formula = formula.strip()\n    \n    try:\n        outformula = eval(formula)\n    except Exception as ist:\n        outformula = \"Invail expression\"\n        print(ist)\n        \n    prompt_template = ApplyPromptTemplate({\n        \"question\": question,\n        \"explanation\": explanation,\n        \"formula\": formula,\n        \"outformula\": outformula,\n    }, \"prompt_input_run_i\")\n    \n    res = pipeGenAns(prompt_template)[0]['generated_text']\n    \n    if debug:\n        print(res)\n        \n    x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số|[Tt]he answer)(?:.*):?[\\n ](.+)\", res)\n    \n    if len(x) < 1:\n        res = pipeGenAnsStick(prompt_template)[0]['generated_text']\n        x = re.findall(\"##[ ]*(?:[Aa]nswer|[Đđ]áp số|[Tt]he answer)(?:.*):?[\\n ](.+)\", res)\n\n    if len(x) < 1:\n        print(\"Error, no Answer 1: {0}\".format(res))\n        raise Exception(\"Error, no Answer 1\")\n    \n#     x = niceValueToCompire(x[-1])\n    x = x[-1]\n    \n    if x is None:\n        print(\"Error, no Answer 2: {0}\".format(res))\n        raise Exception(\"Error, no Answer 2\")\n    \n    return explanation, formula, x\n    \n    return \"wtf\"","metadata":{"execution":{"iopub.status.busy":"2024-01-19T08:10:43.314289Z","iopub.execute_input":"2024-01-19T08:10:43.314672Z","iopub.status.idle":"2024-01-19T08:10:43.336662Z","shell.execute_reply.started":"2024-01-19T08:10:43.314643Z","shell.execute_reply":"2024-01-19T08:10:43.334601Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"markdown","source":"### Run","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy\nimport datetime\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.852891Z","iopub.execute_input":"2024-01-19T07:58:08.853184Z","iopub.status.idle":"2024-01-19T07:58:08.864613Z","shell.execute_reply.started":"2024-01-19T07:58:08.853160Z","shell.execute_reply":"2024-01-19T07:58:08.863787Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"count_proc_testcase = 0\ncount_pass_testcase = 0","metadata":{"execution":{"iopub.status.busy":"2024-01-19T08:05:33.436157Z","iopub.execute_input":"2024-01-19T08:05:33.436541Z","iopub.status.idle":"2024-01-19T08:05:33.441250Z","shell.execute_reply.started":"2024-01-19T08:05:33.436511Z","shell.execute_reply":"2024-01-19T08:05:33.440107Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"while count_proc_testcase < len(tokenized_val_dataset_raw):\n    tvdo = tokenized_val_dataset_raw[count_proc_testcase]\n    startTime()\n    answer = autoLLMFormatAnswer(tvdo, True)\n    deltaTime = getTime()\n    if \"sol\" in tvdo:\n        tvdo['answer'] = tvdo['sol']\n    \n    answer = answer.strip().lower()\n    trueanswer = tvdo['answer'].strip().lower()\n\n    if answer == trueanswer:\n        count_pass_testcase += 1\n    \n    count_proc_testcase += 1\n    print(\"Testcase {0}, time: {1}, answer: {2} | {3}, Passed: {4}, IsPass: {5}\".format(\n        count_proc_testcase,\n        deltaTime,\n        answer,\n        trueanswer,\n        count_pass_testcase,\n        (answer == trueanswer)\n    ))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-19T08:05:33.891384Z","iopub.execute_input":"2024-01-19T08:05:33.891752Z","iopub.status.idle":"2024-01-19T08:05:33.946829Z","shell.execute_reply.started":"2024-01-19T08:05:33.891723Z","shell.execute_reply":"2024-01-19T08:05:33.945396Z"},"trusted":true},"execution_count":60,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m tvdo \u001b[38;5;241m=\u001b[39m tokenized_val_dataset_raw[count_proc_testcase]\n\u001b[1;32m      3\u001b[0m startTime()\n\u001b[0;32m----> 4\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mautoLLMFormatAnswer\u001b[49m(tvdo, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m deltaTime \u001b[38;5;241m=\u001b[39m getTime()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msol\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m tvdo:\n","\u001b[0;31mNameError\u001b[0m: name 'autoLLMFormatAnswer' is not defined"],"ename":"NameError","evalue":"name 'autoLLMFormatAnswer' is not defined","output_type":"error"}]},{"cell_type":"code","source":"print((count_pass_testcase/count_proc_testcase) * 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test implement","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy\nimport datetime\nimport itertools","metadata":{"execution":{"iopub.status.busy":"2024-01-19T07:58:08.865669Z","iopub.execute_input":"2024-01-19T07:58:08.865992Z","iopub.status.idle":"2024-01-19T07:58:08.874612Z","shell.execute_reply.started":"2024-01-19T07:58:08.865959Z","shell.execute_reply":"2024-01-19T07:58:08.873805Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"count_proc_testcase = 0\ncount_pass_testcase = 0","metadata":{"execution":{"iopub.status.busy":"2024-01-19T08:10:46.745545Z","iopub.execute_input":"2024-01-19T08:10:46.745882Z","iopub.status.idle":"2024-01-19T08:10:46.750269Z","shell.execute_reply.started":"2024-01-19T08:10:46.745857Z","shell.execute_reply":"2024-01-19T08:10:46.749176Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"while count_proc_testcase < len(tokenized_val_dataset_raw):\n    # Alice\n    tvdo = tokenized_val_dataset_raw[count_proc_testcase]\n    \n    # Run LLM\n    startTime()\n    explanation, formula, answer = autoLLMFormatAnswer_i(tvdo, False)\n    deltaTime = getTime()\n    \n    # Except\n    if \"sol\" in tvdo:\n        tvdo['answer'] = tvdo['sol']\n    \n    # Lower case\n#     answer = answer.strip().lower()\n#     trueanswer = tvdo['answer'].strip().lower()\n\n#     if answer == trueanswer:\n#         count_pass_testcase += 1\n\n    outformula = \"Invail formula\"\n    try:\n        outformula = eval(formula)\n    except:\n        pass\n    \n    count_proc_testcase += 1\n    print(\"Testcase {0}, time: {1}, answer: {2} | {3}\\n Choices: {4}\\n Explanation: {5}\\n Formula: {6} = {7}\\n\\n\".format(\n        count_proc_testcase,\n        deltaTime,\n        answer,\n        tvdo['answer'],\n        tvdo['choices'],\n        explanation,\n        formula,\n        outformula,\n    ))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T08:10:46.909589Z","iopub.execute_input":"2024-01-19T08:10:46.909921Z","iopub.status.idle":"2024-01-19T08:14:41.403424Z","shell.execute_reply.started":"2024-01-19T08:10:46.909894Z","shell.execute_reply":"2024-01-19T08:14:41.401708Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Testcase 1, time: 13.232266187667847, answer: C. 24dm2 | B\n Choices: ['A. 16 dm^{2}', 'B. 24 dm^{2}', 'C. 8 dm^{2}']\n Explanation: Diện tích toàn phần là 6 * 2^2 = 24 (dm^2)\n Formula: 6 * math.pow(2, 2) = 24.0\n\n\nTestcase 2, time: 8.764178991317749, answer: C. 15,7 cm | B\n Choices: ['A. 10,5 cm', 'B. 15,7 cm', 'C. 17,5 cm']\n Explanation: Chu vi hình tròn = 2 x bán kính x π\n Formula: 2 * 2.5 * math.pi = 15.707963267948966\n\n\nTestcase 3, time: 21.376580953598022, answer: C. 1000 | A\n Choices: ['A. 321,89', 'B. 931,28', 'C. 321,98', 'D. 931,82']\n Explanation: 19%, 39%, 90%, 900%\n Formula: numpy.where(numpy.array([[1, 9], [10, 9], [100, 9], [1000, 9]]) == 9)[0][-1] = 3\n\n\nTestcase 4, time: 13.588300943374634, answer: 2023 | C\n Choices: ['A. 20,23', 'B. 20,0023', 'C. 0,2023', 'D. 2023']\n Explanation: 20dm^{2}   23cm^{2}  =…. m^{2}\n2000cm^{2}   23cm^{2}  = 2023 m^{2}\n Formula: 2000 + 23 = 2023\n\n\nTestcase 5, time: 31.103223085403442, answer: a. 1 | B\n Choices: ['A. 2,25', 'B. 2', 'C. 3,25', 'D. 3']\n Explanation: \"2\\frac{3}{10} = \\frac{23}{10}; 75% = \\frac{3}{4}; \\frac{1}{4} = \\frac{1}{4}; 0,7 = \\frac{7}{10}. Do đó: A = \\frac{23}{10} - \\frac{3}{4} - \\frac{1}{4} + \\frac{7}{10} = \\frac{23-3-1+7}{10} = \\frac{22}{10} = 2,2. Đáp án: a\"\n Formula: (((2 * 10) + 3) / 10) - (75 / 100) - (1 / 4) + (0.7 * 100) = 71.3\n\n\nTestcase 6, time: 93.91122460365295, answer: d. 1 | B\n Choices: ['A. 1100 quyển', 'B. 1210 quyển', 'C. 2310 quyển', 'D. 2310 quyển']\n Explanation: \"1000 + (1000 * 10 / 100) + (1000 * 10 / 100) = 1210. Đáp án: a\"\n Formula: (1000 + ((1000 * 10) / 100)) = 1100.0\n\n\ninvalid syntax (<string>, line 1)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[66], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Run LLM\u001b[39;00m\n\u001b[1;32m      6\u001b[0m startTime()\n\u001b[0;32m----> 7\u001b[0m explanation, formula, answer \u001b[38;5;241m=\u001b[39m \u001b[43mautoLLMFormatAnswer_i\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtvdo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m deltaTime \u001b[38;5;241m=\u001b[39m getTime()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Except\u001b[39;00m\n","Cell \u001b[0;32mIn[64], line 92\u001b[0m, in \u001b[0;36mautoLLMFormatAnswer_i\u001b[0;34m(inp, debug)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ist)\n\u001b[1;32m     85\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m ApplyPromptTemplate({\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m: explanation,\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m\"\u001b[39m: formula,\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutformula\u001b[39m\u001b[38;5;124m\"\u001b[39m: outformula,\n\u001b[1;32m     90\u001b[0m }, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_input_run_i\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpipeGenAns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mprint\u001b[39m(res)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1764\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1757\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1758\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1759\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1761\u001b[0m     )\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1781\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1782\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1788\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2861\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1053\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1066\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:938\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    928\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    929\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    930\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m         use_cache,\n\u001b[1;32m    936\u001b[0m     )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 938\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:660\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    645\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    hidden_states (`torch.FloatTensor`): input to the layer of shape `(batch, seq_len, embed_dim)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m    past_key_value (`Tuple(torch.FloatTensor)`, *optional*): cached past key and value projection states\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    658\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 660\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_layernorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[1;32m    663\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(\n\u001b[1;32m    664\u001b[0m     hidden_states\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    665\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    669\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    670\u001b[0m )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:86\u001b[0m, in \u001b[0;36mMistralRMSNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m     84\u001b[0m input_dtype \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m     85\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m---> 86\u001b[0m variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight \u001b[38;5;241m*\u001b[39m hidden_states\u001b[38;5;241m.\u001b[39mto(input_dtype)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"### Load answer public test","metadata":{}},{"cell_type":"code","source":"print(len(result_test))","metadata":{"execution":{"iopub.status.busy":"2023-12-28T12:11:09.189256Z","iopub.status.idle":"2023-12-28T12:11:09.189659Z","shell.execute_reply.started":"2023-12-28T12:11:09.189479Z","shell.execute_reply":"2023-12-28T12:11:09.189497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run check answer","metadata":{}},{"cell_type":"code","source":"count_id = 0","metadata":{"execution":{"iopub.status.busy":"2024-01-04T09:30:11.313293Z","iopub.execute_input":"2024-01-04T09:30:11.313767Z","iopub.status.idle":"2024-01-04T09:30:11.318288Z","shell.execute_reply.started":"2024-01-04T09:30:11.313728Z","shell.execute_reply":"2024-01-04T09:30:11.317400Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"while count_id < len(test_data):\n    one_test_data = test_data[count_id]\n    answer = result_test[count_id]\n    startTime()\n    answercheck = autoLLMCheck(one_test_data['question'], one_test_data['choices'], answer, True)\n    deltaTime = getTime()\n#     result_test[count_id] = answercheck\n    count_id += 1\n    print(\"Testcase {0}, time: {1}, answer: {2}, answercheck: {3}\".format(count_id, deltaTime, answer, answercheck))","metadata":{"execution":{"iopub.status.busy":"2023-12-26T04:49:42.446523Z","iopub.execute_input":"2023-12-26T04:49:42.446903Z","iopub.status.idle":"2023-12-26T04:49:42.499947Z","shell.execute_reply.started":"2023-12-26T04:49:42.446873Z","shell.execute_reply":"2023-12-26T04:49:42.498726Z"},"trusted":true},"execution_count":101,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[101], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m count_id \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_data):\n\u001b[1;32m      2\u001b[0m     one_test_data \u001b[38;5;241m=\u001b[39m test_data[count_id]\n\u001b[0;32m----> 3\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[43mresult_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcount_id\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      4\u001b[0m     startTime()\n\u001b[1;32m      5\u001b[0m     answercheck \u001b[38;5;241m=\u001b[39m autoLLMCheck(one_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], one_test_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m], answer, \u001b[38;5;28;01mTrue\u001b[39;00m)\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"],"ename":"IndexError","evalue":"list index out of range","output_type":"error"}]},{"cell_type":"markdown","source":"## Run public test dataset","metadata":{}},{"cell_type":"code","source":"result_test = []\nif os.path.exists(os.path.join(\"result\", \"result.txt\")):\n    with open(os.path.join(\"result\", \"result.txt\"), \"r\") as f:\n        result_test = f.read().split(\"\\n\")\ncount_id = len(result_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:03:43.509168Z","iopub.execute_input":"2024-01-08T06:03:43.510109Z","iopub.status.idle":"2024-01-08T06:03:43.515660Z","shell.execute_reply.started":"2024-01-08T06:03:43.510071Z","shell.execute_reply":"2024-01-08T06:03:43.514613Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"result_test = []\ncount_id = len(result_test)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:03:43.740827Z","iopub.execute_input":"2024-01-08T06:03:43.741681Z","iopub.status.idle":"2024-01-08T06:03:43.745964Z","shell.execute_reply.started":"2024-01-08T06:03:43.741647Z","shell.execute_reply":"2024-01-08T06:03:43.744844Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"!mkdir result","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:03:43.905190Z","iopub.execute_input":"2024-01-08T06:03:43.905988Z","iopub.status.idle":"2024-01-08T06:03:44.945689Z","shell.execute_reply.started":"2024-01-08T06:03:43.905929Z","shell.execute_reply":"2024-01-08T06:03:44.944341Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:03:44.948068Z","iopub.execute_input":"2024-01-08T06:03:44.948421Z","iopub.status.idle":"2024-01-08T06:03:44.954450Z","shell.execute_reply.started":"2024-01-08T06:03:44.948387Z","shell.execute_reply":"2024-01-08T06:03:44.953363Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"189\n","output_type":"stream"}]},{"cell_type":"code","source":"while count_id < len(test_data):\n    one_test_data = test_data[count_id]\n    startTime()\n    answer = autoLLMFull(one_test_data, False)\n    deltaTime = getTime()\n    result_test.append(\"{0}\".format(answer))\n    count_id += 1\n    if count_id%10 == 0:\n        with open(os.path.join(\"result\", \"result.txt\"), \"w\", encoding='utf-8') as f:\n            f.write(\"\\n\".join(result_test))\n    print(\"Testcase {0}, time: {1}, answer: {2}\".format(count_id, deltaTime, answer))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-08T06:03:44.955725Z","iopub.execute_input":"2024-01-08T06:03:44.956046Z","iopub.status.idle":"2024-01-08T06:04:24.189844Z","shell.execute_reply.started":"2024-01-08T06:03:44.956019Z","shell.execute_reply":"2024-01-08T06:04:24.187016Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"Testcase 1, time: 16.008486032485962, answer: d\nTestcase 2, time: 11.946000337600708, answer: a\nTestcase 3, time: 4.959412574768066, answer: a\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[52], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m one_test_data \u001b[38;5;241m=\u001b[39m test_data[count_id]\n\u001b[1;32m      3\u001b[0m startTime()\n\u001b[0;32m----> 4\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mautoLLMFull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mone_test_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m deltaTime \u001b[38;5;241m=\u001b[39m getTime()\n\u001b[1;32m      6\u001b[0m result_test\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n","Cell \u001b[0;32mIn[44], line 116\u001b[0m, in \u001b[0;36mautoLLMFull\u001b[0;34m(inp, debug)\u001b[0m\n\u001b[1;32m    111\u001b[0m question, choices \u001b[38;5;241m=\u001b[39m inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m], inp[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    112\u001b[0m prompt_template \u001b[38;5;241m=\u001b[39m ApplyPromptTemplate({\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: question,\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(choices),\n\u001b[1;32m    115\u001b[0m }, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt_full_run\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 116\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mpipeGenFull\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_template\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    118\u001b[0m randomAnswer \u001b[38;5;241m=\u001b[39m choices[random\u001b[38;5;241m.\u001b[39mrandrange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(choices))]\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m debug:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:208\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, text_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m    Complete the prompt(s) given as inputs.\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m          ids of the generated text.\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1140\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1134\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         )\n\u001b[1;32m   1138\u001b[0m     )\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1147\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1146\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1147\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1046\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1045\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1046\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1047\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py:271\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    268\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1764\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1756\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1757\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1758\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1759\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1761\u001b[0m     )\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;66;03m# 13. run sample\u001b[39;00m\n\u001b[0;32m-> 1764\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1765\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1766\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1771\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   1780\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   1781\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1782\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1787\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   1788\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:2861\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2858\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2862\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2863\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2864\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2865\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2866\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2869\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:1053\u001b[0m, in \u001b[0;36mMistralForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1050\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1065\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1066\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(hidden_states)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:938\u001b[0m, in \u001b[0;36mMistralModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    928\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    929\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    930\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m         use_cache,\n\u001b[1;32m    936\u001b[0m     )\n\u001b[1;32m    937\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 938\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:676\u001b[0m, in \u001b[0;36mMistralDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    675\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_attention_layernorm(hidden_states)\n\u001b[0;32m--> 676\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    677\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    679\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py:177\u001b[0m, in \u001b[0;36mMistralMLP.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_proj(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgate_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_proj(x))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"with open(os.path.join(\"result\", \"result.txt\"), \"w\", encoding='utf-8') as f:\n    f.write(\"\\n\".join(result_test))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.190816Z","iopub.status.idle":"2024-01-08T06:04:24.191444Z","shell.execute_reply.started":"2024-01-08T06:04:24.191170Z","shell.execute_reply":"2024-01-08T06:04:24.191199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\".join(result_test))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-08T06:04:24.192719Z","iopub.status.idle":"2024-01-08T06:04:24.193216Z","shell.execute_reply.started":"2024-01-08T06:04:24.192935Z","shell.execute_reply":"2024-01-08T06:04:24.192973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Convert json to csv","metadata":{}},{"cell_type":"code","source":"!pip install pandas","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.194537Z","iopub.status.idle":"2024-01-08T06:04:24.195096Z","shell.execute_reply.started":"2024-01-08T06:04:24.194777Z","shell.execute_reply":"2024-01-08T06:04:24.194812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.196503Z","iopub.status.idle":"2024-01-08T06:04:24.196995Z","shell.execute_reply.started":"2024-01-08T06:04:24.196739Z","shell.execute_reply":"2024-01-08T06:04:24.196761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"json_result = []\nfor i in range(len(test_data)):\n    one_test_data = test_data[i]\n    json_result.append({\n        \"id\": one_test_data[\"id\"],\n        \"answer\": result_test[i]\n    })","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.198342Z","iopub.status.idle":"2024-01-08T06:04:24.198812Z","shell.execute_reply.started":"2024-01-08T06:04:24.198565Z","shell.execute_reply":"2024-01-08T06:04:24.198587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\njson_result_str = json.dumps(json_result)","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.200279Z","iopub.status.idle":"2024-01-08T06:04:24.200756Z","shell.execute_reply.started":"2024-01-08T06:04:24.200507Z","shell.execute_reply":"2024-01-08T06:04:24.200531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_json(json_result_str)\ndf.to_csv(os.path.join(\"result\", \"result.csv\"))","metadata":{"execution":{"iopub.status.busy":"2024-01-08T06:04:24.202271Z","iopub.status.idle":"2024-01-08T06:04:24.202775Z","shell.execute_reply.started":"2024-01-08T06:04:24.202511Z","shell.execute_reply":"2024-01-08T06:04:24.202535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\ni = 0\nwhile 1:\n    time.sleep(1)\n    i += 1\n    print(\"time: \" + str(i))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-01-08T06:04:24.203924Z","iopub.status.idle":"2024-01-08T06:04:24.204417Z","shell.execute_reply.started":"2024-01-08T06:04:24.204173Z","shell.execute_reply":"2024-01-08T06:04:24.204195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}