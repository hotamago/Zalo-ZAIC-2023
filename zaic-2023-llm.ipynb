{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install","metadata":{}},{"cell_type":"code","source":"!pip3 install huggingface-hub","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade openai\n!pip install --upgrade pydantic","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U peft\n%pip install -U accelerate\n%pip install -U trl","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !mkdir MetaMath-Mistral-7B\n# !huggingface-cli download meta-math/MetaMath-Mistral-7B --local-dir MetaMath-Mistral-7B --local-dir-use-symlinks False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install sentencepiece","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# VERSION = \"1.11\"\n# !curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py > /dev/null\n# !python pytorch-xla-env-setup.py --version $VERSION  > /dev/null","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import library","metadata":{}},{"cell_type":"code","source":"# import tensorflow as tf\n# import tensorflow_hub as hub\n# print(\"Tensorflow version \" + tf.__version__)\n# AUTO = tf.data.experimental.AUTOTUNE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Detect TPU, return appropriate distribution strategy\n# try:\n#     tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n#     print('Running on TPU ', tpu.master())\n# except ValueError:\n#     tpu = None\n\n# if tpu:\n#     tf.config.experimental_connect_to_cluster(tpu)\n#     tf.tpu.experimental.initialize_tpu_system(tpu)\n#     strategy = tf.distribute.experimental.TPUStrategy(tpu)\n# else:\n#     strategy = tf.distribute.get_strategy() \n\n# print(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging\nfrom peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\nimport os,torch, wandb\nfrom datasets import load_dataset\nfrom trl import SFTTrainer","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:41.899591Z","iopub.execute_input":"2023-11-28T15:45:41.900011Z","iopub.status.idle":"2023-11-28T15:45:50.788259Z","shell.execute_reply.started":"2023-11-28T15:45:41.899983Z","shell.execute_reply":"2023-11-28T15:45:50.787317Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"# # PyTorch XLA-specific imports\n# import torch_xla.core.xla_model as xm\n# import torch_xla.distributed.parallel_loader as pl\n# import torch_xla.distributed.xla_multiprocessing as xmp\n# import torch_xla.debug.metrics as met","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:50.793431Z","iopub.execute_input":"2023-11-28T15:45:50.793795Z","iopub.status.idle":"2023-11-28T15:45:50.798161Z","shell.execute_reply.started":"2023-11-28T15:45:50.793752Z","shell.execute_reply":"2023-11-28T15:45:50.797290Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_hf = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n# secret_wandb = user_secrets.get_secret(\"wandb\")","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:50.799309Z","iopub.execute_input":"2023-11-28T15:45:50.799586Z","iopub.status.idle":"2023-11-28T15:45:51.201762Z","shell.execute_reply.started":"2023-11-28T15:45:50.799563Z","shell.execute_reply":"2023-11-28T15:45:51.200857Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!huggingface-cli login --token $secret_hf","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:51.204295Z","iopub.execute_input":"2023-11-28T15:45:51.204594Z","iopub.status.idle":"2023-11-28T15:45:53.212184Z","shell.execute_reply.started":"2023-11-28T15:45:51.204568Z","shell.execute_reply":"2023-11-28T15:45:53.211077Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\nToken is valid (permission: read).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n","output_type":"stream"}]},{"cell_type":"code","source":"# wandb.login(key = secret_wandb)\n# run = wandb.init(\n# #     project='Fine tuning MetaMath mistral 7B - ZAIC',\n#     project='Fine tuning openchat 7B - ZAIC',\n#     job_type=\"training\", \n#     anonymous=\"allow\"\n# )","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.213858Z","iopub.execute_input":"2023-11-28T15:45:53.214246Z","iopub.status.idle":"2023-11-28T15:45:53.218973Z","shell.execute_reply.started":"2023-11-28T15:45:53.214213Z","shell.execute_reply":"2023-11-28T15:45:53.218102Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"base_model = \"meta-math/MetaMath-Mistral-7B\"\n# base_model = \"gpt2-xl\"\n# base_model = \"openchat/openchat_3.5\"\nnew_model = \"BK-BigAI-Math\"\nmodel_hotamath_path = \"/kaggle/working/BK-BigAI-Math\"","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.220371Z","iopub.execute_input":"2023-11-28T15:45:53.221411Z","iopub.status.idle":"2023-11-28T15:45:53.231200Z","shell.execute_reply.started":"2023-11-28T15:45:53.221377Z","shell.execute_reply":"2023-11-28T15:45:53.230501Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Download dataset","metadata":{}},{"cell_type":"code","source":"!mkdir dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/test.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023\", filename=\"Elementary Maths Solving/train.zip\", revision=\"main\", repo_type=\"dataset\", local_dir=\"dataset\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!sudo apt-get install unzip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir datasetRaw\n!unzip -q -o \"dataset/Elementary Maths Solving/test.zip\" -d \"datasetRaw\"\n!unzip -q -o \"dataset/Elementary Maths Solving/train.zip\" -d \"datasetRaw\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport re\nimport time","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.232152Z","iopub.execute_input":"2023-11-28T15:45:53.232423Z","iopub.status.idle":"2023-11-28T15:45:53.242163Z","shell.execute_reply.started":"2023-11-28T15:45:53.232400Z","shell.execute_reply":"2023-11-28T15:45:53.241222Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data = None\ntest_data = None\nwith open(os.path.join(\"datasetRaw\", \"train\", \"/kaggle/working/datasetRaw/math_train.json\"), \"r\") as f:\n    train_data = json.loads(f.read())['data']\nwith open(os.path.join(\"datasetRaw\", \"test\", \"/kaggle/working/datasetRaw/math_test.json\"), \"r\") as f:\n    test_data = json.loads(f.read())['data']","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.243515Z","iopub.execute_input":"2023-11-28T15:45:53.243861Z","iopub.status.idle":"2023-11-28T15:45:53.273815Z","shell.execute_reply.started":"2023-11-28T15:45:53.243828Z","shell.execute_reply":"2023-11-28T15:45:53.273073Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.274845Z","iopub.execute_input":"2023-11-28T15:45:53.275113Z","iopub.status.idle":"2023-11-28T15:45:53.282510Z","shell.execute_reply.started":"2023-11-28T15:45:53.275088Z","shell.execute_reply":"2023-11-28T15:45:53.281660Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"{'id': '1',\n 'question': 'Một người bán hàng bỏ ra 80,000 đồng tiền vốn và bị lỗ 6%. Để tính số tiền lỗ ta phải tính',\n 'choices': ['A. 80,000 : 6',\n  'B. 80,000 x 6',\n  'C. 80,000 : (6 x 100)',\n  'D. (80,000 x 6) : 100'],\n 'explanation': 'Theo đề bài, số tiền lỗ bằng 6% của 80 000 đồng . Để tìm số tiền lỗ ta có thể lấy 80 000 chia cho 100 rồi nhân với 6 (tức là 80 000 : 100 × 6) hoặc lấy 80000 nhân với 6 rồi chia cho 100 (tức là 80 000 × 6 : 100).',\n 'answer': 'D. (80,000 x 6) : 100'}"},"metadata":{}}]},{"cell_type":"code","source":"test_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.283779Z","iopub.execute_input":"2023-11-28T15:45:53.284108Z","iopub.status.idle":"2023-11-28T15:45:53.294034Z","shell.execute_reply.started":"2023-11-28T15:45:53.284077Z","shell.execute_reply":"2023-11-28T15:45:53.293228Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"{'id': '01-0203',\n 'question': 'Một cửa hàng đã bán 30% số hàng hiện có và thu được 15 000 000 đồng. Hỏi nếu bán hết hàng thì cửa hàng thu được bao nhiêu tiền?',\n 'choices': ['A. 4 500 000 đồng',\n  'B. 45 000 000 đồng',\n  'C. 50 000 000 đồng',\n  'D. 450 000 000 đồng']}"},"metadata":{}}]},{"cell_type":"code","source":"DEFAULT_PAD_TOKEN = \"[PAD]\"\nDEFAULT_EOS_TOKEN = \"</s>\" # \"<|end_of_turn|>\" # \"</s>\"\nDEFAULT_BOS_TOKEN = \"<s>\"\nDEFAULT_UNK_TOKEN = \"<unk>\"\nDEFAULT_BOI_TOKEN = \"[INST]\" # \"Human:\" # \"[INST]\"\nDEFAULT_EOI_TOKEN = \"[/INST]\" # \"Assistant:\" # \"[/INST]\"\nPROMPT_DICT = {\n    \"prompt_input\": (\n        \"Below is an instruction that describes a task, paired with the choices, one of the choices is the correct answer to the request. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Choices:\\n{choices}\"\n    ),\n    \"prompt_input_run\": (\n        DEFAULT_BOI_TOKEN  + \" Below is an instruction that describes a task. paired with the choices, one of the choices is the correct answer to the request. \"\n        \"Write a response that appropriately completes the request.\\n\\n\"\n        \"### Instruction:\\n{instruction}\\n\\n### Choices:\\n{choices}\"\n        \"\\n\" + DEFAULT_EOI_TOKEN + \" \\n\\n\"\n#         \"### Explanation:\\n Let's think step by step.\\n\"\n        \"### Explanation:\\n Hãy suy nghĩ từng bước một.\\n\"\n    ),\n}","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:31:50.351562Z","iopub.execute_input":"2023-11-28T16:31:50.352328Z","iopub.status.idle":"2023-11-28T16:31:50.358530Z","shell.execute_reply.started":"2023-11-28T16:31:50.352287Z","shell.execute_reply":"2023-11-28T16:31:50.357511Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"timeGlobal = 0\ndef startTime():\n    global timeGlobal\n    timeGlobal = time.time()\ndef getTime():\n    return (time.time() - timeGlobal)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:31:50.531150Z","iopub.execute_input":"2023-11-28T16:31:50.531535Z","iopub.status.idle":"2023-11-28T16:31:50.536441Z","shell.execute_reply.started":"2023-11-28T16:31:50.531504Z","shell.execute_reply":"2023-11-28T16:31:50.535536Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def ApplyPromptTemplate(instruction, choices, typeP = \"prompt_input\"):\n    return PROMPT_DICT[typeP].format(instruction = instruction, choices = \"\\n\".join(choices))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T16:31:50.670907Z","iopub.execute_input":"2023-11-28T16:31:50.671204Z","iopub.status.idle":"2023-11-28T16:31:50.675976Z","shell.execute_reply.started":"2023-11-28T16:31:50.671178Z","shell.execute_reply":"2023-11-28T16:31:50.675031Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"### Add explantion by GPT 3.5 Tubo","metadata":{}},{"cell_type":"code","source":"from openai import OpenAI\nclient = OpenAI(\n    api_key=user_secrets.get_secret(\"OPENAI_API_KEY\"),\n#     organization='org-j48waUrvSOM1n0J1SLXiAr8n',\n)\n\ndef autoGPTAddExplantion(problem, answer):\n    response = client.chat.completions.create(\n      model=\"gpt-3.5-turbo\",\n      messages=[\n        {\"role\": \"system\", \"content\": \"Explan by Vietnamese step-by-step for given answer to given problem.\\nRule:\\n- No markdown format\\n- Given answer always true for given problem\\n- No title\\n- Short explantion\\n\"},\n        {\"role\": \"user\", \"content\": f\"### Problem:\\n{problem}\\n\\n### Answer:\\n{answer}\"},\n        {\"role\": \"system\", \"content\": \"Giải thích: \"},\n      ],\n#       max_tokens=512,\n      temperature=0,\n      top_p=1.0,\n#       top_k=50,\n    )\n    return response.choices[0].message.content","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"startTime()\ncntSt = 0\ni = 0\ntimeWait = 20\nwhile i < len(train_data):\n    singleData = train_data[i]\n    if \"explanation\" in singleData.keys():\n        i += 1\n        continue\n    print(f\"Runing testcase ({i})\")\n    \n    try:\n        res = autoGPTAddExplantion(singleData['question'], singleData['answer'])\n    except Exception as inst:\n        print(type(inst))\n        print(inst)\n        \n        time.sleep(timeWait)\n        timeWait *= 2\n        if timeWait > 80:\n            break\n        print\n        continue\n    \n    timeWait = 20\n        \n    cntSt += 1\n    train_data[i]['explanation'] = res\n    print(f\"Done testcase ({i})\")\n    #     print(train_data[i])\n    if cntSt%3 == 0:\n        deltaTime = getTime()\n        if (60 - deltaTime) > -1:\n            time.sleep(60 - deltaTime + 2)\n        startTime()\n        cntSt = 0\n    \n    i += 1\nprint(\"Done all testcase\")","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/working/datasetRaw/math_train.json\", \"w\", encoding='utf-8') as f:\n    json.dump({\n        \"__count__\": len(train_data),\n        \"data\": train_data\n    }, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Add data by education program","metadata":{}},{"cell_type":"markdown","source":"Todo: Create data generation algorithms for each chapter.\n\nBelow is class base, change \\_call function to a function that create radom question for that chapter","metadata":{}},{"cell_type":"code","source":"class BaseGenChapter:\n    def __init__(*args, **kwargs):\n        pass\n    \n    def _call(self, *args, **kwargs) -> str:\n        raise NotImplementedError(\"_call not Implement yet\")\n    \n    def call(self, *args, **kwargs) -> str:\n        return self._call(*args, **kwargs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Preprocess data","metadata":{}},{"cell_type":"code","source":"from datasets import Dataset\nimport random","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.328894Z","iopub.execute_input":"2023-11-28T15:45:53.329153Z","iopub.status.idle":"2023-11-28T15:45:53.338005Z","shell.execute_reply.started":"2023-11-28T15:45:53.329131Z","shell.execute_reply":"2023-11-28T15:45:53.337111Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# random.shuffle(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.407818Z","iopub.execute_input":"2023-11-28T15:45:53.408102Z","iopub.status.idle":"2023-11-28T15:45:53.411996Z","shell.execute_reply.started":"2023-11-28T15:45:53.408077Z","shell.execute_reply":"2023-11-28T15:45:53.411058Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"num_train_dataset = len(train_data)\nvalition_radio = 0.1\ntokenized_train_dataset_raw = train_data[:-int(num_train_dataset*valition_radio)]\ntokenized_val_dataset_raw = train_data[-int(num_train_dataset*valition_radio):]","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.577634Z","iopub.execute_input":"2023-11-28T15:45:53.578254Z","iopub.status.idle":"2023-11-28T15:45:53.582651Z","shell.execute_reply.started":"2023-11-28T15:45:53.578226Z","shell.execute_reply":"2023-11-28T15:45:53.581758Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"datasetStruct = {\"input\":[], \"output\":[]}\ndataset = {\"text\":[]}\nnum_train_dataset = len(tokenized_train_dataset_raw)\nfor i in range(num_train_dataset):\n    ttdro = tokenized_train_dataset_raw[i]\n    \n    if \"explanation\" not in ttdro.keys():\n        continue\n    \n    input_content = \"{0} {1}\".format(\n        DEFAULT_BOI_TOKEN,\n        ApplyPromptTemplate(ttdro['question'], ttdro['choices']),\n    )\n    datasetStruct[\"input\"].append(input_content)\n    \n    if \"explanation\" not in ttdro.keys():\n        output_content = \"\\n{0} \\n\\n{1}\\n\\n{2} {3}\".format(\n            DEFAULT_EOI_TOKEN,\n            \"### Explanation:\\nNo explanation{0}\",\n            \"### Answer:\\n{0}\".format(ttdro['answer']),\n            DEFAULT_EOS_TOKEN,\n        )\n    else:\n        output_content = \"\\n{0} \\n\\n{1}\\n\\n{2} {3}\".format(\n            DEFAULT_EOI_TOKEN,\n            \"### Explanation:\\n{0}\".format(ttdro['explanation']),\n            \"### Answer:\\n{0}\".format(ttdro['answer']),\n            DEFAULT_EOS_TOKEN,\n        )\n    datasetStruct[\"output\"].append(output_content)\n    \n    dataset[\"text\"].append(input_content + output_content)\n#     <s>[INST][/INST] </s>","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.720123Z","iopub.execute_input":"2023-11-28T15:45:53.720696Z","iopub.status.idle":"2023-11-28T15:45:53.738429Z","shell.execute_reply.started":"2023-11-28T15:45:53.720668Z","shell.execute_reply":"2023-11-28T15:45:53.737188Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"print(dataset[\"text\"][32])","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:53.943206Z","iopub.execute_input":"2023-11-28T15:45:53.943608Z","iopub.status.idle":"2023-11-28T15:45:53.948767Z","shell.execute_reply.started":"2023-11-28T15:45:53.943577Z","shell.execute_reply":"2023-11-28T15:45:53.947892Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"[INST] Below is an instruction that describes a task, paired with the choices, one of the choices is the correct answer to the request. Write a response that appropriately completes the request.\n\n### Instruction:\nNgày thứ nhất, bác Thái thu hoạch được 250 kg nhãn. Ngày thứ hai, số ki- lô-gam nhãn bác Thái thu hoạch được đã giảm đi 2 lần so với ngày thứ nhất. Vậy cả hai ngày bác Thái thu hoạch được số ki-lô-gam nhãn là:\n\n### Choices:\nA. 500 kg\nB. 750 kg\nC. 125kg\nD. 375 kg\n[/INST] \n\n### Explanation:\nNgày thứ hai, bác Thái thu hoạch được số ki-lô-ham nhãn là: 250 : 2 = 125 (kg) \n Cả hai ngày bác Thái thu hoạch được số ki-lô-gam nhãn là: $250 + 125 = 375$ (kg)\n Đáp số: 375 kg\n\n### Answer:\nD. 375 kg </s>\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(dataset[\"text\"]))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:45:54.352331Z","iopub.execute_input":"2023-11-28T15:45:54.352706Z","iopub.status.idle":"2023-11-28T15:45:54.357658Z","shell.execute_reply.started":"2023-11-28T15:45:54.352677Z","shell.execute_reply":"2023-11-28T15:45:54.356734Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1080\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Train model","metadata":{}},{"cell_type":"markdown","source":"### Load model","metadata":{}},{"cell_type":"code","source":"bnb_config = BitsAndBytesConfig(  \n    load_in_4bit= True,\n    bnb_4bit_quant_type= \"nf4\",\n    bnb_4bit_compute_dtype= torch.bfloat16,\n    bnb_4bit_use_double_quant= False,\n)\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n#         model_hotamath_path,\n    load_in_4bit=True,\n#     load_in_8bit= True,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n#     torch_dtype=torch.float16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    base_model,\n    model_max_length=512,\n    padding_side=\"right\",\n    use_fast=False,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"special_tokens_dict = {\n    'additional_special_tokens': [DEFAULT_BOI_TOKEN, DEFAULT_EOI_TOKEN],\n    'pad_token': DEFAULT_PAD_TOKEN,\n    'bos_token': DEFAULT_BOS_TOKEN,\n    'eos_token': DEFAULT_EOS_TOKEN,\n    'unk_token': DEFAULT_UNK_TOKEN,\n}\nnum_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tokenizer.encode(\"{0} Hello, how are you? \\n{1} I'm fine, thank you!{2}\".format(\n    DEFAULT_BOI_TOKEN,\n    DEFAULT_EOI_TOKEN,\n    DEFAULT_EOS_TOKEN,\n)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check max token","metadata":{}},{"cell_type":"code","source":"max_token_of_dataset = 0\nlistLongToken = []\nfor i in range(len(dataset[\"text\"])):\n    text = dataset[\"text\"][i]\n    token_len = len(tokenizer.encode(text))\n    max_token_of_dataset = max(token_len, max_token_of_dataset)\n    if token_len > 512:\n        print(i, token_len, \"\\n\")\n        listLongToken.append(i)\n#         print(text)\nprint(max_token_of_dataset)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Remove long token","metadata":{}},{"cell_type":"code","source":"print(len(listLongToken))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset[\"text\"] = [dataset[\"text\"][i] for i in range(len(dataset[\"text\"])) if i not in listLongToken]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check\nmax_token_of_dataset = 0\nfor i in range(len(dataset[\"text\"])):\n    text = dataset[\"text\"][i]\n    token_len = len(tokenizer.encode(text))\n    max_token_of_dataset = max(token_len, max_token_of_dataset)\n    if token_len > 512:\n        print(i, token_len, \"\\n\")\nprint(max_token_of_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Nice stuct dataset","metadata":{}},{"cell_type":"code","source":"dataset = Dataset.from_dict(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DataCollator","metadata":{}},{"cell_type":"code","source":"from trl import DataCollatorForCompletionOnlyLM","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"instruction_template = DEFAULT_BOI_TOKEN\nresponse_template = DEFAULT_EOI_TOKEN\ncollator = DataCollatorForCompletionOnlyLM(instruction_template=instruction_template, response_template=response_template, tokenizer=tokenizer, mlm=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Setup model for train","metadata":{}},{"cell_type":"code","source":"print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)\npeft_config = LoraConfig(\n    lora_alpha=16,\n    lora_dropout=0.1,\n    r=64,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n)\nmodel = get_peft_model(model, peft_config)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=2,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_steps=200,\n    logging_steps=10,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    fp16=False,\n    bf16=False,\n    max_grad_norm=0.3,\n    max_steps=-1,\n    save_total_limit = 1,\n    warmup_ratio=0.03,\n    group_by_length=True,\n    lr_scheduler_type=\"constant\",\n    report_to=\"none\"\n#     report_to=\"wandb\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import bitsandbytes as bnb\n# from torch import nn\n# from transformers.trainer_pt_utils import get_parameter_names\n\n# no_decay = [\"bias\", \"LayerNorm.weight\"]\n# optimizer_grouped_parameters = [{\n#     \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n#     \"weight_decay\": training_arguments.weight_decay,\n# },\n# {\n#     \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n#     \"weight_decay\": 0.0,\n# }]\n\n\n# optimizer_kwargs = {\n#     \"betas\": (training_arguments.adam_beta1, training_arguments.adam_beta2),\n#     \"eps\": training_arguments.adam_epsilon,\n# }\n# optimizer_kwargs[\"lr\"] = training_arguments.learning_rate\n# adam_bnb_optim = bnb.optim.Adam8bit(\n#     optimizer_grouped_parameters,\n#     betas=(training_arguments.adam_beta1, training_arguments.adam_beta2),\n#     eps=training_arguments.adam_epsilon,\n#     lr=training_arguments.learning_rate,\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = model.to(\"cuda:0\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    \"\"\"\n    Prints the number of trainable parameters in the model.\n    \"\"\"\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_trainable_parameters(model)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = SFTTrainer(\n    model=model,\n#     model = base_model,\n    train_dataset=dataset,\n    peft_config=peft_config,\n    max_seq_length=512,\n    dataset_text_field=\"text\",\n    tokenizer=tokenizer,\n    args=training_arguments,\n    packing= False,\n    data_collator=collator,\n#     optimizers=(adam_bnb_optim, None)\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Train and save","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.save_pretrained(new_model)\ntrainer.model.save_pretrained(new_model)\nmodel.config.to_json_file(os.path.join(new_model, \"config.json\"))\ntokenizer.save_pretrained(new_model)\nwandb.finish()\nmodel.config.use_cache = True","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!zip -r BK-BigAI-Math.zip BK-BigAI-Math","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'BK-BigAI-Math.zip')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evalution","metadata":{}},{"cell_type":"markdown","source":"### Download model","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import hf_hub_download\nhf_hub_download(repo_id=\"hotamago/ZAIC-2023-Model\", filename=\"Hota-Math.zip\", repo_type=\"model\", local_dir=\"/kaggle/working/\", local_dir_use_symlinks=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q -o Hota-Math.zip -d ./","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load model","metadata":{}},{"cell_type":"code","source":"dataset = Dataset.from_dict(dataset)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name_or_path = \"/kaggle/working/BK-BigAI-Math\"\n# bnb_config = BitsAndBytesConfig(  \n#     load_in_4bit= True,\n#     bnb_4bit_quant_type= \"nf4\",\n#     bnb_4bit_compute_dtype= torch.bfloat16,\n#     bnb_4bit_use_double_quant= False,\n# )\n# model = AutoModelForCausalLM.from_pretrained(\n#         model_name_or_path,\n#         load_in_4bit=True,\n#         quantization_config=bnb_config,\n#         torch_dtype=torch.bfloat16,\n#         device_map=\"auto\",\n#         trust_remote_code=True,\n# )\n\n# model = AutoModelForCausalLM.from_pretrained(\n#         model_name_or_path,\n#         torch_dtype=torch.bfloat16,\n#         device_map=\"auto\",\n#         trust_remote_code=True,\n# )\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name_or_path,\n#     torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True,\n    load_in_4bit=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:46:36.640470Z","iopub.execute_input":"2023-11-28T15:46:36.641210Z","iopub.status.idle":"2023-11-28T15:48:00.371110Z","shell.execute_reply.started":"2023-11-28T15:46:36.641174Z","shell.execute_reply":"2023-11-28T15:48:00.369976Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eb9698ad8084406a7b6fff2b0a27c40"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\n    model_name_or_path,\n    model_max_length=512,\n    padding_side=\"right\",\n    use_fast=False,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:48:00.373217Z","iopub.execute_input":"2023-11-28T15:48:00.373553Z","iopub.status.idle":"2023-11-28T15:48:00.489161Z","shell.execute_reply.started":"2023-11-28T15:48:00.373526Z","shell.execute_reply":"2023-11-28T15:48:00.488323Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"# special_tokens_dict = {'additional_special_tokens': ['[INST]','[/INST]']}\n# num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\nmodel.resize_token_embeddings(len(tokenizer))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:48:00.490191Z","iopub.execute_input":"2023-11-28T15:48:00.490505Z","iopub.status.idle":"2023-11-28T15:48:00.626169Z","shell.execute_reply.started":"2023-11-28T15:48:00.490469Z","shell.execute_reply":"2023-11-28T15:48:00.625133Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"Embedding(32003, 4096)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Setup pipeline with auto answer get","metadata":{}},{"cell_type":"code","source":"pipe = pipeline(\n    \"text-generation\",\n    model=model,\n    tokenizer=tokenizer,\n    max_new_tokens=512,\n    do_sample=True,\n    temperature=0.01,\n    top_p=0.3,\n    top_k=5,\n    repetition_penalty=1.1,\n    pad_token_id=tokenizer.eos_token_id\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T17:12:52.367728Z","iopub.execute_input":"2023-11-28T17:12:52.368212Z","iopub.status.idle":"2023-11-28T17:12:52.375703Z","shell.execute_reply.started":"2023-11-28T17:12:52.368173Z","shell.execute_reply":"2023-11-28T17:12:52.374402Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import random\n# globalRegxCompire = \"0-9a-zA-Z\\.\\:\\-\\^\\! \"\ndef niceValueToCompire(x):\n#     x = re.sub(\"[^{0}]\".format(globalRegxCompire), \"\", x)\n    x = re.sub(\"[ \\t\\n]\", \"\", x)\n    return x\ndef autoLLMFormat(question, choises = None, debug=False):\n    prompt_template = ApplyPromptTemplate(question, choises, \"prompt_input_run\")\n    res = pipe(prompt_template)[0]['generated_text']\n    if debug:\n        print(res)\n    x = re.findall(\"### Answer:[\\n ](.+)\", res)\n    \n    if choises == None:\n        return x\n    \n    choises_compare = [niceValueToCompire(choise_pred) for choise_pred in choises]\n\n    if len(x) == 0:\n        return choises[random.randrange(0, len(choises))]\n    \n    x = niceValueToCompire(x[0])\n    \n    if (x not in choises_compare):\n        return choises[random.randrange(0, len(choises))]\n    \n    for i in range(len(choises_compare)):\n        if x == choises_compare[i]:\n            return choises[i]\n    \n    return \"wtf\"","metadata":{"execution":{"iopub.status.busy":"2023-11-28T17:12:53.331838Z","iopub.execute_input":"2023-11-28T17:12:53.332906Z","iopub.status.idle":"2023-11-28T17:12:53.341933Z","shell.execute_reply.started":"2023-11-28T17:12:53.332849Z","shell.execute_reply":"2023-11-28T17:12:53.340959Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":"### Run evalution","metadata":{}},{"cell_type":"code","source":"count_proc_testcase = 0\ncount_pass_testcase = 0","metadata":{"execution":{"iopub.status.busy":"2023-11-28T17:12:55.707622Z","iopub.execute_input":"2023-11-28T17:12:55.708257Z","iopub.status.idle":"2023-11-28T17:12:55.712381Z","shell.execute_reply.started":"2023-11-28T17:12:55.708215Z","shell.execute_reply":"2023-11-28T17:12:55.711342Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"while count_proc_testcase < len(tokenized_val_dataset_raw):\n    tvdo = tokenized_val_dataset_raw[count_proc_testcase]\n    startTime()\n    answer = autoLLMFormat(tvdo['question'], tvdo['choices'], True)\n    deltaTime = getTime()\n\n    if answer == tvdo['answer']:\n        count_pass_testcase += 1\n    \n    count_proc_testcase += 1\n    print(\"Testcase {0}, time: {1}, answer: {2} | {3}, Passed: {4}, IsPass: {5}\".format(\n        count_proc_testcase,\n        deltaTime,\n        answer,\n        tvdo['answer'],\n        count_pass_testcase,\n        (answer == tvdo['answer'])\n    ))","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Run public test dataset","metadata":{}},{"cell_type":"code","source":"result_test = []\nif os.path.exists(os.path.join(\"result\", \"result.txt\")):\n    with open(os.path.join(\"result\", \"result.txt\"), \"r\") as f:\n        result_test = f.read().split(\"\\n\")\ncount_id = len(result_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:50:27.908250Z","iopub.execute_input":"2023-11-28T15:50:27.908643Z","iopub.status.idle":"2023-11-28T15:50:27.914232Z","shell.execute_reply.started":"2023-11-28T15:50:27.908614Z","shell.execute_reply":"2023-11-28T15:50:27.913342Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"!mkdir result","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:50:28.056153Z","iopub.execute_input":"2023-11-28T15:50:28.056891Z","iopub.status.idle":"2023-11-28T15:50:29.112923Z","shell.execute_reply.started":"2023-11-28T15:50:28.056860Z","shell.execute_reply":"2023-11-28T15:50:29.111732Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘result’: File exists\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(test_data))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T15:50:29.115133Z","iopub.execute_input":"2023-11-28T15:50:29.115490Z","iopub.status.idle":"2023-11-28T15:50:29.121190Z","shell.execute_reply.started":"2023-11-28T15:50:29.115459Z","shell.execute_reply":"2023-11-28T15:50:29.120159Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"189\n","output_type":"stream"}]},{"cell_type":"code","source":"while count_id < len(test_data):\n    one_test_data = test_data[count_id]\n    startTime()\n    answer = autoLLMFormat(one_test_data['question'], one_test_data['choices'], False)\n    deltaTime = getTime()\n    result_test.append(\"{0}\".format(answer))\n    count_id += 1\n    if count_id%10 == 0:\n        with open(os.path.join(\"result\", \"result.txt\"), \"w\", encoding='utf-8') as f:\n            f.write(\"\\n\".join(result_test))\n    print(\"Testcase {0}, time: {1}, answer: {2}\".format(count_id, deltaTime, answer))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-11-28T17:15:16.414485Z","iopub.execute_input":"2023-11-28T17:15:16.414893Z","iopub.status.idle":"2023-11-28T20:58:05.420509Z","shell.execute_reply.started":"2023-11-28T17:15:16.414859Z","shell.execute_reply":"2023-11-28T20:58:05.419559Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Testcase 45, time: 617.1695258617401, answer: D. 6dm\nTestcase 46, time: 45.58360052108765, answer: C. 55,017\nTestcase 47, time: 258.9015815258026, answer: B. 60%\nTestcase 48, time: 47.76309680938721, answer: A. \\frac{9}{10}\nTestcase 49, time: 31.940237283706665, answer: D. 2,5\nTestcase 50, time: 247.83676648139954, answer: C. 100 m^{3}\nTestcase 51, time: 52.18727660179138, answer: D. 60\nTestcase 52, time: 138.4821548461914, answer: C. 510 m/phút\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Testcase 53, time: 27.546841859817505, answer: A. 9998\nTestcase 54, time: 74.55208206176758, answer: A. 10\nTestcase 55, time: 54.88587737083435, answer: D. 38,2\nTestcase 56, time: 45.17529511451721, answer: C. 0,2 tạ\nTestcase 57, time: 38.58472728729248, answer: C. 50,24 dm^{2}\nTestcase 58, time: 193.25170469284058, answer: B. 4dm\nTestcase 59, time: 52.594768047332764, answer: B. 55,072\nTestcase 60, time: 40.360626459121704, answer: C. 80%\nTestcase 61, time: 51.55485653877258, answer: C. 100\nTestcase 62, time: 44.879873275756836, answer: C. 55,017\nTestcase 63, time: 47.78270387649536, answer: C. 2 257\nTestcase 64, time: 90.34180045127869, answer: C. 3,5%\nTestcase 65, time: 66.97714304924011, answer: C. =\nTestcase 66, time: 51.14504861831665, answer: C. 0,023\nTestcase 67, time: 44.74071550369263, answer: B. 30046\nTestcase 68, time: 192.76801371574402, answer: D. 0,48 dm^{2}\nTestcase 69, time: 33.13592481613159, answer: C. 0,07\nTestcase 70, time: 47.72169804573059, answer: B. 41,7\nTestcase 71, time: 84.82694840431213, answer: A. 17,13\nTestcase 72, time: 60.32182788848877, answer: A. 45300 m^{2}\nTestcase 73, time: 38.08826398849487, answer: B. 1527,4\nTestcase 74, time: 32.490854263305664, answer: D. Phần trăm\nTestcase 75, time: 30.99665665626526, answer: C. 50 000\nTestcase 76, time: 36.34942269325256, answer: B. 151,07\nTestcase 77, time: 75.03184199333191, answer: C. 62,5%\nTestcase 78, time: 57.140883922576904, answer: A. 136\nTestcase 79, time: 44.62587237358093, answer: B. 2,1\nTestcase 80, time: 52.08157157897949, answer: B. 3,015 tấn\nTestcase 81, time: 48.51059889793396, answer: A. 1821,2\nTestcase 82, time: 42.999613523483276, answer: C. 9,08\nTestcase 83, time: 40.9453706741333, answer: A. 9 \\frac{6}{10}\nTestcase 84, time: 38.614980697631836, answer: C. 7 phần trăm\nTestcase 85, time: 44.01579761505127, answer: C. 4,6\nTestcase 86, time: 29.7089786529541, answer: C. 101,6\nTestcase 87, time: 32.6488881111145, answer: D. 9 phần trăm\nTestcase 88, time: 39.08276677131653, answer: C. \\frac{5}{100}\nTestcase 89, time: 52.818339109420776, answer: D. 0,080\nTestcase 90, time: 58.7487211227417, answer: A. 11002 kg\nTestcase 91, time: 56.61761164665222, answer: C. 908\nTestcase 92, time: 43.29584002494812, answer: D. 8,06\nTestcase 93, time: 51.44995665550232, answer: A. 40,392\nTestcase 94, time: 161.80357384681702, answer: C. 5,5m^{2}\nTestcase 95, time: 59.78127980232239, answer: B. 0,03 kg\nTestcase 96, time: 39.699196100234985, answer: D. 6,27 ha\nTestcase 97, time: 166.83879470825195, answer: B. 7,2m^{2}\nTestcase 98, time: 116.39260840415955, answer: D. 4,23; 4,32; 5,3; 5,7; 6,02\nTestcase 99, time: 50.34958338737488, answer: D. 25%\nTestcase 100, time: 58.99853038787842, answer: D. \\frac{27}{50}\nTestcase 101, time: 54.525529861450195, answer: D. 24900\nTestcase 102, time: 132.81225514411926, answer: B. 0,5\nTestcase 103, time: 76.29388451576233, answer: A. 900cm^{2}\nTestcase 104, time: 29.75329041481018, answer: B. 194254\nTestcase 105, time: 148.1428279876709, answer: C. 3,04\nTestcase 106, time: 85.85546278953552, answer: C. 30000\nTestcase 107, time: 47.18208575248718, answer: C. 23 \\frac{5}{10}\nTestcase 108, time: 106.23543620109558, answer: C. 3,009\nTestcase 109, time: 325.53483271598816, answer: C. \\frac{11}{5}\nTestcase 110, time: 588.0141010284424, answer: B. 375,4\nTestcase 111, time: 77.51864957809448, answer: A. 8; 8,76; 8,093; 8,901\nTestcase 112, time: 83.138920545578, answer: C. 83 000\nTestcase 113, time: 66.06605672836304, answer: B. 3,09\nTestcase 114, time: 35.41368818283081, answer: C. 240m^{2}\nTestcase 115, time: 42.94118595123291, answer: C. 5,002\nTestcase 116, time: 85.24082779884338, answer: A. 4,54375\nTestcase 117, time: 47.302738666534424, answer: C. 356\nTestcase 118, time: 41.1674063205719, answer: B. 7,99\nTestcase 119, time: 45.46734142303467, answer: A. \\frac{23}{5}\nTestcase 120, time: 94.89043283462524, answer: C. Hàng phần trăm\nTestcase 121, time: 50.560473918914795, answer: D. 2,3\nTestcase 122, time: 49.07695412635803, answer: C. 64%\nTestcase 123, time: 42.05060911178589, answer: B. 0,1\nTestcase 124, time: 769.7686460018158, answer: A. 12 kg\nTestcase 125, time: 485.3591663837433, answer: A. 1,12 lần\nTestcase 126, time: 93.47926545143127, answer: D. 1\nTestcase 127, time: 128.48283290863037, answer: B. 60 ngày\nTestcase 128, time: 295.24988412857056, answer: C. 121,5 dm^{3}\nTestcase 129, time: 53.75354337692261, answer: C. 663,64\nTestcase 130, time: 42.80971097946167, answer: C. 55, 017\nTestcase 131, time: 50.34785485267639, answer: C. 30005\nTestcase 132, time: 56.614126443862915, answer: C. 115 giây\nTestcase 133, time: 170.22694373130798, answer: C. 16 cm^{2}\nTestcase 134, time: 116.88090586662292, answer: A. 3,14 cm^{2}\nTestcase 135, time: 43.7325234413147, answer: C. 0,32\nTestcase 136, time: 59.40165185928345, answer: D. 20 000\nTestcase 137, time: 52.891939878463745, answer: B. 18,806\nTestcase 138, time: 55.34849739074707, answer: B. 4,021 m^{3}\nTestcase 139, time: 31.204973220825195, answer: A. 45%\nTestcase 140, time: 69.53489303588867, answer: B. 40%\nTestcase 141, time: 52.15341567993164, answer: C. 3000 m^{2}\nTestcase 142, time: 39.54054617881775, answer: C. 45 km/giờ\nTestcase 143, time: 39.94743299484253, answer: C. 17 016\nTestcase 144, time: 40.36763858795166, answer: C. \\frac{5}{100}\nTestcase 145, time: 22.795703172683716, answer: B. 62,45\nTestcase 146, time: 20.528035640716553, answer: C. 1,7\nTestcase 147, time: 24.10038113594055, answer: A. 1,2\nTestcase 148, time: 39.265841007232666, answer: A. \\frac{8}{100}\nTestcase 149, time: 631.1825702190399, answer: B. 8000m^{2}\nTestcase 150, time: 395.74711441993713, answer: D. \\frac{5}{17}\nTestcase 151, time: 144.07048296928406, answer: C. 75%\nTestcase 152, time: 86.54728746414185, answer: B. 100\nTestcase 153, time: 32.994654417037964, answer: D. 15 hình tam giác\nTestcase 154, time: 51.28333568572998, answer: D. 2,3\nTestcase 155, time: 58.91028571128845, answer: C. 20,03\nTestcase 156, time: 43.30365872383118, answer: B. 3,75\nTestcase 157, time: 41.54293370246887, answer: C. 32%\nTestcase 158, time: 185.78214359283447, answer: B. 315cm^{2}\nTestcase 159, time: 39.0684871673584, answer: B. \\frac{7}{100}\nTestcase 160, time: 69.86183476448059, answer: B. 34,06\nTestcase 161, time: 47.727155447006226, answer: C. 9,952\nTestcase 162, time: 80.47409915924072, answer: D. 7,45\nTestcase 163, time: 40.22053360939026, answer: A. 744m^{2}\nTestcase 164, time: 32.76581144332886, answer: C. 0,001\nTestcase 165, time: 66.0938560962677, answer: C. 8750\nTestcase 166, time: 63.17145752906799, answer: A. \\frac{18}{20}\nTestcase 167, time: 45.59892821311951, answer: C. 1,03\nTestcase 168, time: 52.523855686187744, answer: B. 0,080\nTestcase 169, time: 43.33680844306946, answer: B. 4,321\nTestcase 170, time: 77.6126139163971, answer: B. 95%\nTestcase 171, time: 166.54613375663757, answer: A. 9000 đồng\nTestcase 172, time: 38.21266150474548, answer: A. 20031\nTestcase 173, time: 44.4678795337677, answer: D. 69,91\nTestcase 174, time: 89.51674771308899, answer: D. 157 giờ\nTestcase 175, time: 51.91771221160889, answer: C. 600\nTestcase 176, time: 147.23123478889465, answer: D. 6 km\nTestcase 177, time: 71.34603500366211, answer: A. 100,5\nTestcase 178, time: 47.74756717681885, answer: A. 55,0017\nTestcase 179, time: 37.66716909408569, answer: C. \\frac{8}{10}\nTestcase 180, time: 142.3674967288971, answer: B. 12,05\nTestcase 181, time: 39.09919476509094, answer: C. \\frac{9}{100}\nTestcase 182, time: 58.712223529815674, answer: A. 68,07\nTestcase 183, time: 55.137763261795044, answer: B. 50,789\nTestcase 184, time: 136.72301650047302, answer: B. 60%\nTestcase 185, time: 28.96023964881897, answer: C. 45,1\nTestcase 186, time: 95.1852195262909, answer: B. 37,5 %\nTestcase 187, time: 46.39265561103821, answer: B. 4,562\nTestcase 188, time: 110.84932494163513, answer: D. 3,06\nTestcase 189, time: 38.96697664260864, answer: B. 184 dm^{2}\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(os.path.join(\"result\", \"result.txt\"), \"w\", encoding='utf-8') as f:\n    f.write(\"\\n\".join(result_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:58:05.422115Z","iopub.execute_input":"2023-11-28T20:58:05.422397Z","iopub.status.idle":"2023-11-28T20:58:05.427393Z","shell.execute_reply.started":"2023-11-28T20:58:05.422373Z","shell.execute_reply":"2023-11-28T20:58:05.426485Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(\"\\n\".join(result_test))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T20:58:05.428729Z","iopub.execute_input":"2023-11-28T20:58:05.429392Z","iopub.status.idle":"2023-11-28T20:58:05.441001Z","shell.execute_reply.started":"2023-11-28T20:58:05.429356Z","shell.execute_reply":"2023-11-28T20:58:05.440154Z"},"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"C. 50 000 000 đồng\nD. 8 giờ 24 phút\nD. 8 lần\nC. 25%\nB. 200m\nB. 5,621\nA. 40%\nB. 7 giờ 77 phút\nC. 0,75\nC. 67,919\nB. 24\nD. 39870\nD. \\frac{7}{1000}\nB. 5 phần trăm\nA. 150%\nC. \\frac{1}{2}\nC. 350\nB. 5,019\nC. 0,18 giờ\nC. 369,92\nD. 50 000 000\nD. 37,5\nD. 10,5\nD. 3,05\nC. 90 phút\nC. 36 dm^{2}\nD. 6,14 dm\nC. 6,28 cm^{2}\nA. 1380 dm^{3}\nA. 64%\nD. 3,076\nC. 201,700\nA. 0,79\nD. 40 phút\nB. 0,75\nA. 10 phút\nB. 1,234\nB. 8 phút 36 giây\nA. 3,48\nA. 270 học sinh\nC. \\frac{5}{4}\nC. 8\nA. 7 cm\nC. 663,64\nD. 6dm\nC. 55,017\nB. 60%\nA. \\frac{9}{10}\nD. 2,5\nC. 100 m^{3}\nD. 60\nC. 510 m/phút\nA. 9998\nA. 10\nD. 38,2\nC. 0,2 tạ\nC. 50,24 dm^{2}\nB. 4dm\nB. 55,072\nC. 80%\nC. 100\nC. 55,017\nC. 2 257\nC. 3,5%\nC. =\nC. 0,023\nB. 30046\nD. 0,48 dm^{2}\nC. 0,07\nB. 41,7\nA. 17,13\nA. 45300 m^{2}\nB. 1527,4\nD. Phần trăm\nC. 50 000\nB. 151,07\nC. 62,5%\nA. 136\nB. 2,1\nB. 3,015 tấn\nA. 1821,2\nC. 9,08\nA. 9 \\frac{6}{10}\nC. 7 phần trăm\nC. 4,6\nC. 101,6\nD. 9 phần trăm\nC. \\frac{5}{100}\nD. 0,080\nA. 11002 kg\nC. 908\nD. 8,06\nA. 40,392\nC. 5,5m^{2}\nB. 0,03 kg\nD. 6,27 ha\nB. 7,2m^{2}\nD. 4,23; 4,32; 5,3; 5,7; 6,02\nD. 25%\nD. \\frac{27}{50}\nD. 24900\nB. 0,5\nA. 900cm^{2}\nB. 194254\nC. 3,04\nC. 30000\nC. 23 \\frac{5}{10}\nC. 3,009\nC. \\frac{11}{5}\nB. 375,4\nA. 8; 8,76; 8,093; 8,901\nC. 83 000\nB. 3,09\nC. 240m^{2}\nC. 5,002\nA. 4,54375\nC. 356\nB. 7,99\nA. \\frac{23}{5}\nC. Hàng phần trăm\nD. 2,3\nC. 64%\nB. 0,1\nA. 12 kg\nA. 1,12 lần\nD. 1\nB. 60 ngày\nC. 121,5 dm^{3}\nC. 663,64\nC. 55, 017\nC. 30005\nC. 115 giây\nC. 16 cm^{2}\nA. 3,14 cm^{2}\nC. 0,32\nD. 20 000\nB. 18,806\nB. 4,021 m^{3}\nA. 45%\nB. 40%\nC. 3000 m^{2}\nC. 45 km/giờ\nC. 17 016\nC. \\frac{5}{100}\nB. 62,45\nC. 1,7\nA. 1,2\nA. \\frac{8}{100}\nB. 8000m^{2}\nD. \\frac{5}{17}\nC. 75%\nB. 100\nD. 15 hình tam giác\nD. 2,3\nC. 20,03\nB. 3,75\nC. 32%\nB. 315cm^{2}\nB. \\frac{7}{100}\nB. 34,06\nC. 9,952\nD. 7,45\nA. 744m^{2}\nC. 0,001\nC. 8750\nA. \\frac{18}{20}\nC. 1,03\nB. 0,080\nB. 4,321\nB. 95%\nA. 9000 đồng\nA. 20031\nD. 69,91\nD. 157 giờ\nC. 600\nD. 6 km\nA. 100,5\nA. 55,0017\nC. \\frac{8}{10}\nB. 12,05\nC. \\frac{9}{100}\nA. 68,07\nB. 50,789\nB. 60%\nC. 45,1\nB. 37,5 %\nB. 4,562\nD. 3,06\nB. 184 dm^{2}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Convert json to csv","metadata":{}},{"cell_type":"code","source":"!pip install pandas","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:17.479114Z","iopub.execute_input":"2023-11-28T21:16:17.480110Z","iopub.status.idle":"2023-11-28T21:16:30.385546Z","shell.execute_reply.started":"2023-11-28T21:16:17.480073Z","shell.execute_reply":"2023-11-28T21:16:30.384423Z"},"trusted":true},"execution_count":46,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\nRequirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.24.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:30.387886Z","iopub.execute_input":"2023-11-28T21:16:30.388208Z","iopub.status.idle":"2023-11-28T21:16:30.393205Z","shell.execute_reply.started":"2023-11-28T21:16:30.388179Z","shell.execute_reply":"2023-11-28T21:16:30.392249Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"json_result = []\nfor i in range(len(test_data)):\n    one_test_data = test_data[i]\n    json_result.append({\n        \"id\": one_test_data[\"id\"],\n        \"answer\": result_test[i]\n    })","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:16:30.394505Z","iopub.execute_input":"2023-11-28T21:16:30.394818Z","iopub.status.idle":"2023-11-28T21:16:30.406467Z","shell.execute_reply.started":"2023-11-28T21:16:30.394793Z","shell.execute_reply":"2023-11-28T21:16:30.405561Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import json\njson_result_str = json.dumps(json_result)","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:18:48.579554Z","iopub.execute_input":"2023-11-28T21:18:48.580425Z","iopub.status.idle":"2023-11-28T21:18:48.584781Z","shell.execute_reply.started":"2023-11-28T21:18:48.580388Z","shell.execute_reply":"2023-11-28T21:18:48.583724Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"df = pd.read_json(json_result_str)\ndf.to_csv(os.path.join(\"result\", \"result.csv\"))","metadata":{"execution":{"iopub.status.busy":"2023-11-28T21:19:31.150614Z","iopub.execute_input":"2023-11-28T21:19:31.151016Z","iopub.status.idle":"2023-11-28T21:19:31.163604Z","shell.execute_reply.started":"2023-11-28T21:19:31.150984Z","shell.execute_reply":"2023-11-28T21:19:31.162690Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}